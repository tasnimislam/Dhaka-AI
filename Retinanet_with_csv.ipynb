{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Retinanet_with_csv.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cTTrlhBSYyT",
        "outputId": "e26b92ba-5ec6-4e2b-f7f9-c7d285eae069"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkVTbBD0Szx6",
        "outputId": "0255cf7b-29bd-4a4a-bf96-bf913ae6a61d"
      },
      "source": [
        "%cd \"/content/drive/MyDrive\" \n",
        "!git clone \"https://github.com/yhenon/pytorch-retinanet.git\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "fatal: destination path 'pytorch-retinanet' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33d_I0_gTHwz",
        "outputId": "9a0ec169-94fe-4063-d152-d446c3cc4bb2"
      },
      "source": [
        "!pip install pandas\n",
        "!pip install pycocotools\n",
        "!pip install opencv-python\n",
        "!pip install requests"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (2.0.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (0.29.21)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (50.3.2)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jitu10Xjwq8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e3954e-e7ce-40dc-f562-bb9f81e40284"
      },
      "source": [
        "!apt-get install tk-dev python-tk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tk-dev is already the newest version (8.6.0+9).\n",
            "python-tk is already the newest version (2.7.17-1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5rWY7kvD1It"
      },
      "source": [
        " from six import raise_from"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPh6Ip7VTnrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9fe80a5-9b4e-461e-fe7b-c73ea77da276"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/pytorch-retinanet\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/pytorch-retinanet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xZ2eQxFTbIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5b7941-0841-407d-dac1-8dfd2970bb13"
      },
      "source": [
        "#python train.py --dataset csv --csv_train <path/to/train_annots.csv>  --csv_classes <path/to/train/class_list.csv>  --csv_val <path/to/val_annots.csv>\n",
        "!python train.py --h"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "usage: train.py [-h] [--dataset DATASET] [--coco_path COCO_PATH]\n",
            "                [--csv_train CSV_TRAIN] [--csv_classes CSV_CLASSES]\n",
            "                [--csv_val CSV_VAL] [--depth DEPTH] [--epochs EPOCHS]\n",
            "\n",
            "Simple training script for training a RetinaNet network.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --dataset DATASET     Dataset type, must be one of csv or coco.\n",
            "  --coco_path COCO_PATH\n",
            "                        Path to COCO directory\n",
            "  --csv_train CSV_TRAIN\n",
            "                        Path to file containing training annotations (see\n",
            "                        readme)\n",
            "  --csv_classes CSV_CLASSES\n",
            "                        Path to file containing class list (see readme)\n",
            "  --csv_val CSV_VAL     Path to file containing validation annotations\n",
            "                        (optional, see readme)\n",
            "  --depth DEPTH         Resnet depth, must be one of 18, 34, 50, 101, 152\n",
            "  --epochs EPOCHS       Number of epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q422CR24OQZ_"
      },
      "source": [
        "names = [\"ambulance\", \"auto rickshaw\", \"bicycle\", \"bus\", \"car\", \"garbage van\", \"human hauler\", \"minibus\", \"minivan\", \"motorbike\", \"pickup\", \"army vehicle\", \n",
        "   \"policecar\", \"rickshaw\", \"scooter\", \"suv\", \"taxi\", \"three wheelers (CNG)\", \"truck\", \"van\", \"wheelbarrow\" ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkdiXKECN4iN",
        "outputId": "0a7ea1fb-5c54-4ad9-cd5f-7bde17ceca69"
      },
      "source": [
        "dict_classes = {\n",
        "    'ambulance': 0,\n",
        "    \"auto rickshaw\": 1,\n",
        "    \"bicycle\": 2,\n",
        "    \"bus\": 3,\n",
        "    \"car\": 4,\n",
        "    \"garbage van\": 5,\n",
        "    \"human hauler\": 6,\n",
        "    \"minibus\": 7,\n",
        "    \"minivan\": 8,\n",
        "    \"motorbike\": 9,\n",
        "    \"pickup\": 10,\n",
        "    \"army vehicle\": 11,\n",
        "    \"policecar\": 12,\n",
        "    \"rickshaw\": 13,\n",
        "    \"scooter\": 14,\n",
        "    \"suv\": 15,\n",
        "    \"taxi\": 16,\n",
        "    \"three wheelers (CNG)\": 17,\n",
        "    \"truck\": 18,\n",
        "    \"van\": 19,\n",
        "    \"wheelbarrow\": 20\n",
        "}\n",
        "import csv\n",
        "with open('/content/classes.csv', mode='w') as file:\n",
        "  writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  for key, val in dict_classes.items():  \n",
        "    row = [key, val]\n",
        "    print(row)\n",
        "    writer.writerow(row)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ambulance', 0]\n",
            "['auto rickshaw', 1]\n",
            "['bicycle', 2]\n",
            "['bus', 3]\n",
            "['car', 4]\n",
            "['garbage van', 5]\n",
            "['human hauler', 6]\n",
            "['minibus', 7]\n",
            "['minivan', 8]\n",
            "['motorbike', 9]\n",
            "['pickup', 10]\n",
            "['army vehicle', 11]\n",
            "['policecar', 12]\n",
            "['rickshaw', 13]\n",
            "['scooter', 14]\n",
            "['suv', 15]\n",
            "['taxi', 16]\n",
            "['three wheelers (CNG)', 17]\n",
            "['truck', 18]\n",
            "['van', 19]\n",
            "['wheelbarrow', 20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_koNm8yHBYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7a7368-a8c6-4ad2-d29c-66083676f5fe"
      },
      "source": [
        "!python train.py --dataset \"csv\" --csv_train \"/content/drive/My Drive/train_df_fold_1.csv\" --csv_val \"/content/drive/My Drive/val_df_fold_1.csv\" --depth 101 --epochs 100 --csv_classes \"/content/drive/My Drive/classes.csv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 9 | Iteration: 974 | Classification loss: 0.16921 | Regression loss: 0.37764 | Running loss: 0.36460\n",
            "Epoch: 9 | Iteration: 975 | Classification loss: 0.15037 | Regression loss: 0.28639 | Running loss: 0.36499\n",
            "Epoch: 9 | Iteration: 976 | Classification loss: 0.05734 | Regression loss: 0.14233 | Running loss: 0.36433\n",
            "Epoch: 9 | Iteration: 977 | Classification loss: 0.10948 | Regression loss: 0.16905 | Running loss: 0.36435\n",
            "Epoch: 9 | Iteration: 978 | Classification loss: 0.08578 | Regression loss: 0.18672 | Running loss: 0.36419\n",
            "Epoch: 9 | Iteration: 979 | Classification loss: 0.19795 | Regression loss: 0.31806 | Running loss: 0.36442\n",
            "Epoch: 9 | Iteration: 980 | Classification loss: 0.11237 | Regression loss: 0.23012 | Running loss: 0.36449\n",
            "Epoch: 9 | Iteration: 981 | Classification loss: 0.08233 | Regression loss: 0.14249 | Running loss: 0.36454\n",
            "Epoch: 9 | Iteration: 982 | Classification loss: 0.09947 | Regression loss: 0.17830 | Running loss: 0.36427\n",
            "Epoch: 9 | Iteration: 983 | Classification loss: 0.10675 | Regression loss: 0.28604 | Running loss: 0.36426\n",
            "Epoch: 9 | Iteration: 984 | Classification loss: 0.17831 | Regression loss: 0.32889 | Running loss: 0.36483\n",
            "Epoch: 9 | Iteration: 985 | Classification loss: 0.11488 | Regression loss: 0.32577 | Running loss: 0.36507\n",
            "Epoch: 9 | Iteration: 986 | Classification loss: 0.22260 | Regression loss: 0.38266 | Running loss: 0.36527\n",
            "Epoch: 9 | Iteration: 987 | Classification loss: 0.24178 | Regression loss: 0.48379 | Running loss: 0.36545\n",
            "Epoch: 9 | Iteration: 988 | Classification loss: 0.19344 | Regression loss: 0.33490 | Running loss: 0.36549\n",
            "Epoch: 9 | Iteration: 989 | Classification loss: 0.12972 | Regression loss: 0.21030 | Running loss: 0.36565\n",
            "Epoch: 9 | Iteration: 990 | Classification loss: 0.18845 | Regression loss: 0.26537 | Running loss: 0.36580\n",
            "Epoch: 9 | Iteration: 991 | Classification loss: 0.13437 | Regression loss: 0.37457 | Running loss: 0.36597\n",
            "Epoch: 9 | Iteration: 992 | Classification loss: 0.29282 | Regression loss: 0.40843 | Running loss: 0.36674\n",
            "Epoch: 9 | Iteration: 993 | Classification loss: 0.12613 | Regression loss: 0.33694 | Running loss: 0.36691\n",
            "Epoch: 9 | Iteration: 994 | Classification loss: 0.17617 | Regression loss: 0.36005 | Running loss: 0.36710\n",
            "Epoch: 9 | Iteration: 995 | Classification loss: 0.11153 | Regression loss: 0.33519 | Running loss: 0.36733\n",
            "Epoch: 9 | Iteration: 996 | Classification loss: 0.15088 | Regression loss: 0.26639 | Running loss: 0.36735\n",
            "Epoch: 9 | Iteration: 997 | Classification loss: 0.10649 | Regression loss: 0.26104 | Running loss: 0.36754\n",
            "Epoch: 9 | Iteration: 998 | Classification loss: 0.05663 | Regression loss: 0.18923 | Running loss: 0.36743\n",
            "Epoch: 9 | Iteration: 999 | Classification loss: 0.09446 | Regression loss: 0.18092 | Running loss: 0.36729\n",
            "Epoch: 9 | Iteration: 1000 | Classification loss: 0.08087 | Regression loss: 0.09476 | Running loss: 0.36644\n",
            "Epoch: 9 | Iteration: 1001 | Classification loss: 0.10719 | Regression loss: 0.28788 | Running loss: 0.36650\n",
            "Epoch: 9 | Iteration: 1002 | Classification loss: 0.20947 | Regression loss: 0.34112 | Running loss: 0.36680\n",
            "Epoch: 9 | Iteration: 1003 | Classification loss: 0.08260 | Regression loss: 0.11245 | Running loss: 0.36626\n",
            "Epoch: 9 | Iteration: 1004 | Classification loss: 0.12400 | Regression loss: 0.25858 | Running loss: 0.36631\n",
            "Epoch: 9 | Iteration: 1005 | Classification loss: 0.11037 | Regression loss: 0.29707 | Running loss: 0.36675\n",
            "Epoch: 9 | Iteration: 1006 | Classification loss: 0.13089 | Regression loss: 0.25918 | Running loss: 0.36670\n",
            "Epoch: 9 | Iteration: 1007 | Classification loss: 0.13419 | Regression loss: 0.22051 | Running loss: 0.36706\n",
            "Epoch: 9 | Iteration: 1008 | Classification loss: 0.17752 | Regression loss: 0.22860 | Running loss: 0.36724\n",
            "Epoch: 9 | Iteration: 1009 | Classification loss: 0.12626 | Regression loss: 0.28378 | Running loss: 0.36735\n",
            "Epoch: 9 | Iteration: 1010 | Classification loss: 0.07491 | Regression loss: 0.23676 | Running loss: 0.36688\n",
            "Epoch: 9 | Iteration: 1011 | Classification loss: 0.19536 | Regression loss: 0.32386 | Running loss: 0.36721\n",
            "Epoch: 9 | Iteration: 1012 | Classification loss: 0.13192 | Regression loss: 0.34999 | Running loss: 0.36678\n",
            "Epoch: 9 | Iteration: 1013 | Classification loss: 0.05216 | Regression loss: 0.09291 | Running loss: 0.36627\n",
            "Epoch: 9 | Iteration: 1014 | Classification loss: 0.04766 | Regression loss: 0.13812 | Running loss: 0.36559\n",
            "Epoch: 9 | Iteration: 1015 | Classification loss: 0.07743 | Regression loss: 0.15115 | Running loss: 0.36559\n",
            "Epoch: 9 | Iteration: 1016 | Classification loss: 0.11198 | Regression loss: 0.24531 | Running loss: 0.36560\n",
            "Epoch: 9 | Iteration: 1017 | Classification loss: 0.04247 | Regression loss: 0.13052 | Running loss: 0.36533\n",
            "Epoch: 9 | Iteration: 1018 | Classification loss: 0.12086 | Regression loss: 0.36602 | Running loss: 0.36592\n",
            "Epoch: 9 | Iteration: 1019 | Classification loss: 0.15100 | Regression loss: 0.25080 | Running loss: 0.36600\n",
            "Epoch: 9 | Iteration: 1020 | Classification loss: 0.04540 | Regression loss: 0.22090 | Running loss: 0.36559\n",
            "Epoch: 9 | Iteration: 1021 | Classification loss: 0.10009 | Regression loss: 0.18310 | Running loss: 0.36551\n",
            "Epoch: 9 | Iteration: 1022 | Classification loss: 0.25103 | Regression loss: 0.30775 | Running loss: 0.36581\n",
            "Epoch: 9 | Iteration: 1023 | Classification loss: 0.10391 | Regression loss: 0.23464 | Running loss: 0.36601\n",
            "Epoch: 9 | Iteration: 1024 | Classification loss: 0.18414 | Regression loss: 0.31728 | Running loss: 0.36628\n",
            "Epoch: 9 | Iteration: 1025 | Classification loss: 0.08523 | Regression loss: 0.25396 | Running loss: 0.36568\n",
            "Epoch: 9 | Iteration: 1026 | Classification loss: 0.10898 | Regression loss: 0.31620 | Running loss: 0.36618\n",
            "Epoch: 9 | Iteration: 1027 | Classification loss: 0.03626 | Regression loss: 0.14851 | Running loss: 0.36590\n",
            "Epoch: 9 | Iteration: 1028 | Classification loss: 0.14679 | Regression loss: 0.29256 | Running loss: 0.36560\n",
            "Epoch: 9 | Iteration: 1029 | Classification loss: 0.13018 | Regression loss: 0.28044 | Running loss: 0.36568\n",
            "Epoch: 9 | Iteration: 1030 | Classification loss: 0.03841 | Regression loss: 0.19513 | Running loss: 0.36520\n",
            "Epoch: 9 | Iteration: 1031 | Classification loss: 0.05927 | Regression loss: 0.22007 | Running loss: 0.36504\n",
            "Epoch: 9 | Iteration: 1032 | Classification loss: 0.20716 | Regression loss: 0.51912 | Running loss: 0.36545\n",
            "Epoch: 9 | Iteration: 1033 | Classification loss: 0.07582 | Regression loss: 0.19943 | Running loss: 0.36514\n",
            "Epoch: 9 | Iteration: 1034 | Classification loss: 0.11079 | Regression loss: 0.26668 | Running loss: 0.36531\n",
            "Epoch: 9 | Iteration: 1035 | Classification loss: 0.17101 | Regression loss: 0.40817 | Running loss: 0.36597\n",
            "Epoch: 9 | Iteration: 1036 | Classification loss: 0.18539 | Regression loss: 0.12609 | Running loss: 0.36574\n",
            "Epoch: 9 | Iteration: 1037 | Classification loss: 0.06334 | Regression loss: 0.24648 | Running loss: 0.36565\n",
            "Epoch: 9 | Iteration: 1038 | Classification loss: 0.11564 | Regression loss: 0.19257 | Running loss: 0.36563\n",
            "Epoch: 9 | Iteration: 1039 | Classification loss: 0.10182 | Regression loss: 0.21696 | Running loss: 0.36542\n",
            "Epoch: 9 | Iteration: 1040 | Classification loss: 0.15308 | Regression loss: 0.22421 | Running loss: 0.36549\n",
            "Epoch: 9 | Iteration: 1041 | Classification loss: 0.14736 | Regression loss: 0.36406 | Running loss: 0.36592\n",
            "Epoch: 9 | Iteration: 1042 | Classification loss: 0.12573 | Regression loss: 0.27704 | Running loss: 0.36600\n",
            "Epoch: 9 | Iteration: 1043 | Classification loss: 0.05534 | Regression loss: 0.24749 | Running loss: 0.36617\n",
            "Epoch: 9 | Iteration: 1044 | Classification loss: 0.10398 | Regression loss: 0.39583 | Running loss: 0.36647\n",
            "Epoch: 9 | Iteration: 1045 | Classification loss: 0.14290 | Regression loss: 0.26283 | Running loss: 0.36658\n",
            "Epoch: 9 | Iteration: 1046 | Classification loss: 0.13639 | Regression loss: 0.26754 | Running loss: 0.36684\n",
            "Epoch: 9 | Iteration: 1047 | Classification loss: 0.24169 | Regression loss: 0.20752 | Running loss: 0.36701\n",
            "Epoch: 9 | Iteration: 1048 | Classification loss: 0.06475 | Regression loss: 0.15440 | Running loss: 0.36673\n",
            "Epoch: 9 | Iteration: 1049 | Classification loss: 0.07838 | Regression loss: 0.19515 | Running loss: 0.36643\n",
            "Epoch: 9 | Iteration: 1050 | Classification loss: 0.18699 | Regression loss: 0.44794 | Running loss: 0.36723\n",
            "Epoch: 9 | Iteration: 1051 | Classification loss: 0.15979 | Regression loss: 0.33457 | Running loss: 0.36728\n",
            "Epoch: 9 | Iteration: 1052 | Classification loss: 0.08433 | Regression loss: 0.26260 | Running loss: 0.36737\n",
            "Epoch: 9 | Iteration: 1053 | Classification loss: 0.09502 | Regression loss: 0.20809 | Running loss: 0.36753\n",
            "Epoch: 9 | Iteration: 1054 | Classification loss: 0.06584 | Regression loss: 0.21526 | Running loss: 0.36735\n",
            "Epoch: 9 | Iteration: 1055 | Classification loss: 0.09318 | Regression loss: 0.21502 | Running loss: 0.36715\n",
            "Epoch: 9 | Iteration: 1056 | Classification loss: 0.12397 | Regression loss: 0.23765 | Running loss: 0.36710\n",
            "Epoch: 9 | Iteration: 1057 | Classification loss: 0.15470 | Regression loss: 0.22610 | Running loss: 0.36733\n",
            "Epoch: 9 | Iteration: 1058 | Classification loss: 0.13732 | Regression loss: 0.21524 | Running loss: 0.36736\n",
            "Epoch: 9 | Iteration: 1059 | Classification loss: 0.05949 | Regression loss: 0.20949 | Running loss: 0.36662\n",
            "Epoch: 9 | Iteration: 1060 | Classification loss: 0.15116 | Regression loss: 0.33954 | Running loss: 0.36690\n",
            "Epoch: 9 | Iteration: 1061 | Classification loss: 0.10122 | Regression loss: 0.18740 | Running loss: 0.36679\n",
            "Epoch: 9 | Iteration: 1062 | Classification loss: 0.18778 | Regression loss: 0.44566 | Running loss: 0.36729\n",
            "Epoch: 9 | Iteration: 1063 | Classification loss: 0.09064 | Regression loss: 0.15653 | Running loss: 0.36671\n",
            "Epoch: 9 | Iteration: 1064 | Classification loss: 0.13726 | Regression loss: 0.24352 | Running loss: 0.36694\n",
            "Epoch: 9 | Iteration: 1065 | Classification loss: 0.29063 | Regression loss: 0.29858 | Running loss: 0.36733\n",
            "Epoch: 9 | Iteration: 1066 | Classification loss: 0.11227 | Regression loss: 0.17372 | Running loss: 0.36713\n",
            "Epoch: 9 | Iteration: 1067 | Classification loss: 0.12493 | Regression loss: 0.34921 | Running loss: 0.36736\n",
            "Epoch: 9 | Iteration: 1068 | Classification loss: 0.05953 | Regression loss: 0.12051 | Running loss: 0.36720\n",
            "Epoch: 9 | Iteration: 1069 | Classification loss: 0.10997 | Regression loss: 0.22856 | Running loss: 0.36680\n",
            "Epoch: 9 | Iteration: 1070 | Classification loss: 0.09575 | Regression loss: 0.13875 | Running loss: 0.36687\n",
            "Epoch: 9 | Iteration: 1071 | Classification loss: 0.06434 | Regression loss: 0.14743 | Running loss: 0.36619\n",
            "Epoch: 9 | Iteration: 1072 | Classification loss: 0.05674 | Regression loss: 0.15847 | Running loss: 0.36631\n",
            "Epoch: 9 | Iteration: 1073 | Classification loss: 0.10052 | Regression loss: 0.16923 | Running loss: 0.36616\n",
            "Epoch: 9 | Iteration: 1074 | Classification loss: 0.14043 | Regression loss: 0.26546 | Running loss: 0.36654\n",
            "Epoch: 9 | Iteration: 1075 | Classification loss: 0.10323 | Regression loss: 0.16307 | Running loss: 0.36638\n",
            "Epoch: 9 | Iteration: 1076 | Classification loss: 0.26142 | Regression loss: 0.32008 | Running loss: 0.36689\n",
            "Epoch: 9 | Iteration: 1077 | Classification loss: 0.19756 | Regression loss: 0.35150 | Running loss: 0.36765\n",
            "Epoch: 9 | Iteration: 1078 | Classification loss: 0.09929 | Regression loss: 0.20305 | Running loss: 0.36746\n",
            "Epoch: 9 | Iteration: 1079 | Classification loss: 0.12034 | Regression loss: 0.11967 | Running loss: 0.36753\n",
            "Epoch: 9 | Iteration: 1080 | Classification loss: 0.11154 | Regression loss: 0.23141 | Running loss: 0.36733\n",
            "Epoch: 9 | Iteration: 1081 | Classification loss: 0.19090 | Regression loss: 0.23189 | Running loss: 0.36761\n",
            "Epoch: 9 | Iteration: 1082 | Classification loss: 0.04354 | Regression loss: 0.13945 | Running loss: 0.36717\n",
            "Epoch: 9 | Iteration: 1083 | Classification loss: 0.14387 | Regression loss: 0.20456 | Running loss: 0.36674\n",
            "Epoch: 9 | Iteration: 1084 | Classification loss: 0.12434 | Regression loss: 0.23976 | Running loss: 0.36693\n",
            "Epoch: 9 | Iteration: 1085 | Classification loss: 0.07974 | Regression loss: 0.14224 | Running loss: 0.36609\n",
            "Epoch: 9 | Iteration: 1086 | Classification loss: 0.10469 | Regression loss: 0.23887 | Running loss: 0.36604\n",
            "Epoch: 9 | Iteration: 1087 | Classification loss: 0.06262 | Regression loss: 0.23916 | Running loss: 0.36630\n",
            "Epoch: 9 | Iteration: 1088 | Classification loss: 0.14829 | Regression loss: 0.20671 | Running loss: 0.36557\n",
            "Epoch: 9 | Iteration: 1089 | Classification loss: 0.11360 | Regression loss: 0.22471 | Running loss: 0.36581\n",
            "Epoch: 9 | Iteration: 1090 | Classification loss: 0.13045 | Regression loss: 0.30367 | Running loss: 0.36547\n",
            "Epoch: 9 | Iteration: 1091 | Classification loss: 0.09583 | Regression loss: 0.21362 | Running loss: 0.36559\n",
            "Epoch: 9 | Iteration: 1092 | Classification loss: 0.19594 | Regression loss: 0.36474 | Running loss: 0.36579\n",
            "Epoch: 9 | Iteration: 1093 | Classification loss: 0.18747 | Regression loss: 0.27586 | Running loss: 0.36590\n",
            "Epoch: 9 | Iteration: 1094 | Classification loss: 0.17807 | Regression loss: 0.36485 | Running loss: 0.36592\n",
            "Epoch: 9 | Iteration: 1095 | Classification loss: 0.11037 | Regression loss: 0.16393 | Running loss: 0.36587\n",
            "Epoch: 9 | Iteration: 1096 | Classification loss: 0.13547 | Regression loss: 0.22960 | Running loss: 0.36592\n",
            "Epoch: 9 | Iteration: 1097 | Classification loss: 0.14498 | Regression loss: 0.29556 | Running loss: 0.36601\n",
            "Epoch: 9 | Iteration: 1098 | Classification loss: 0.11180 | Regression loss: 0.21162 | Running loss: 0.36607\n",
            "Epoch: 9 | Iteration: 1099 | Classification loss: 0.16559 | Regression loss: 0.36811 | Running loss: 0.36651\n",
            "Epoch: 9 | Iteration: 1100 | Classification loss: 0.22553 | Regression loss: 0.26128 | Running loss: 0.36712\n",
            "Epoch: 9 | Iteration: 1101 | Classification loss: 0.07279 | Regression loss: 0.15146 | Running loss: 0.36696\n",
            "Epoch: 9 | Iteration: 1102 | Classification loss: 0.09266 | Regression loss: 0.14265 | Running loss: 0.36701\n",
            "Epoch: 9 | Iteration: 1103 | Classification loss: 0.07690 | Regression loss: 0.21897 | Running loss: 0.36654\n",
            "Epoch: 9 | Iteration: 1104 | Classification loss: 0.09477 | Regression loss: 0.31298 | Running loss: 0.36683\n",
            "Epoch: 9 | Iteration: 1105 | Classification loss: 0.10421 | Regression loss: 0.22665 | Running loss: 0.36724\n",
            "Epoch: 9 | Iteration: 1106 | Classification loss: 0.12664 | Regression loss: 0.30840 | Running loss: 0.36750\n",
            "Epoch: 9 | Iteration: 1107 | Classification loss: 0.06849 | Regression loss: 0.18845 | Running loss: 0.36751\n",
            "Epoch: 9 | Iteration: 1108 | Classification loss: 0.10987 | Regression loss: 0.23658 | Running loss: 0.36747\n",
            "Epoch: 9 | Iteration: 1109 | Classification loss: 0.08709 | Regression loss: 0.16442 | Running loss: 0.36746\n",
            "Epoch: 9 | Iteration: 1110 | Classification loss: 0.04582 | Regression loss: 0.17483 | Running loss: 0.36731\n",
            "Epoch: 9 | Iteration: 1111 | Classification loss: 0.05726 | Regression loss: 0.18941 | Running loss: 0.36757\n",
            "Epoch: 9 | Iteration: 1112 | Classification loss: 0.03609 | Regression loss: 0.10185 | Running loss: 0.36718\n",
            "Epoch: 9 | Iteration: 1113 | Classification loss: 0.10723 | Regression loss: 0.18740 | Running loss: 0.36686\n",
            "Epoch: 9 | Iteration: 1114 | Classification loss: 0.10495 | Regression loss: 0.14203 | Running loss: 0.36638\n",
            "Epoch: 9 | Iteration: 1115 | Classification loss: 0.17972 | Regression loss: 0.38785 | Running loss: 0.36631\n",
            "Epoch: 9 | Iteration: 1116 | Classification loss: 0.16246 | Regression loss: 0.33784 | Running loss: 0.36674\n",
            "Epoch: 9 | Iteration: 1117 | Classification loss: 0.11912 | Regression loss: 0.21037 | Running loss: 0.36662\n",
            "Epoch: 9 | Iteration: 1118 | Classification loss: 0.18457 | Regression loss: 0.26964 | Running loss: 0.36692\n",
            "Epoch: 9 | Iteration: 1119 | Classification loss: 0.16797 | Regression loss: 0.28647 | Running loss: 0.36699\n",
            "Epoch: 9 | Iteration: 1120 | Classification loss: 0.12521 | Regression loss: 0.23206 | Running loss: 0.36657\n",
            "Epoch: 9 | Iteration: 1121 | Classification loss: 0.07075 | Regression loss: 0.22052 | Running loss: 0.36672\n",
            "Epoch: 9 | Iteration: 1122 | Classification loss: 0.05460 | Regression loss: 0.18952 | Running loss: 0.36653\n",
            "Epoch: 9 | Iteration: 1123 | Classification loss: 0.06519 | Regression loss: 0.18756 | Running loss: 0.36659\n",
            "Epoch: 9 | Iteration: 1124 | Classification loss: 0.04492 | Regression loss: 0.08960 | Running loss: 0.36639\n",
            "Epoch: 9 | Iteration: 1125 | Classification loss: 0.13678 | Regression loss: 0.12781 | Running loss: 0.36602\n",
            "Epoch: 9 | Iteration: 1126 | Classification loss: 0.13770 | Regression loss: 0.22978 | Running loss: 0.36592\n",
            "Epoch: 9 | Iteration: 1127 | Classification loss: 0.04750 | Regression loss: 0.11438 | Running loss: 0.36576\n",
            "Epoch: 9 | Iteration: 1128 | Classification loss: 0.09823 | Regression loss: 0.20448 | Running loss: 0.36538\n",
            "Epoch: 9 | Iteration: 1129 | Classification loss: 0.07020 | Regression loss: 0.20507 | Running loss: 0.36555\n",
            "Epoch: 9 | Iteration: 1130 | Classification loss: 0.14527 | Regression loss: 0.27360 | Running loss: 0.36559\n",
            "Epoch: 9 | Iteration: 1131 | Classification loss: 0.09053 | Regression loss: 0.17118 | Running loss: 0.36484\n",
            "Epoch: 9 | Iteration: 1132 | Classification loss: 0.12164 | Regression loss: 0.20244 | Running loss: 0.36472\n",
            "Epoch: 9 | Iteration: 1133 | Classification loss: 0.10126 | Regression loss: 0.17102 | Running loss: 0.36491\n",
            "Epoch: 9 | Iteration: 1134 | Classification loss: 0.12934 | Regression loss: 0.25826 | Running loss: 0.36513\n",
            "Epoch: 9 | Iteration: 1135 | Classification loss: 0.29759 | Regression loss: 0.36790 | Running loss: 0.36595\n",
            "Epoch: 9 | Iteration: 1136 | Classification loss: 0.13182 | Regression loss: 0.25863 | Running loss: 0.36618\n",
            "Epoch: 9 | Iteration: 1137 | Classification loss: 0.32779 | Regression loss: 0.48688 | Running loss: 0.36699\n",
            "Epoch: 9 | Iteration: 1138 | Classification loss: 0.05835 | Regression loss: 0.15457 | Running loss: 0.36682\n",
            "Epoch: 9 | Iteration: 1139 | Classification loss: 0.11707 | Regression loss: 0.23544 | Running loss: 0.36659\n",
            "Epoch: 9 | Iteration: 1140 | Classification loss: 0.15468 | Regression loss: 0.22965 | Running loss: 0.36639\n",
            "Epoch: 9 | Iteration: 1141 | Classification loss: 0.09536 | Regression loss: 0.23034 | Running loss: 0.36652\n",
            "Epoch: 9 | Iteration: 1142 | Classification loss: 0.09142 | Regression loss: 0.17911 | Running loss: 0.36632\n",
            "Epoch: 9 | Iteration: 1143 | Classification loss: 0.18313 | Regression loss: 0.39337 | Running loss: 0.36702\n",
            "Epoch: 9 | Iteration: 1144 | Classification loss: 0.09897 | Regression loss: 0.18358 | Running loss: 0.36712\n",
            "Epoch: 9 | Iteration: 1145 | Classification loss: 0.14957 | Regression loss: 0.29414 | Running loss: 0.36731\n",
            "Epoch: 9 | Iteration: 1146 | Classification loss: 0.16048 | Regression loss: 0.27445 | Running loss: 0.36717\n",
            "Epoch: 9 | Iteration: 1147 | Classification loss: 0.16771 | Regression loss: 0.31887 | Running loss: 0.36739\n",
            "Epoch: 9 | Iteration: 1148 | Classification loss: 0.11457 | Regression loss: 0.18250 | Running loss: 0.36742\n",
            "Epoch: 9 | Iteration: 1149 | Classification loss: 0.04021 | Regression loss: 0.13788 | Running loss: 0.36708\n",
            "Epoch: 9 | Iteration: 1150 | Classification loss: 0.15832 | Regression loss: 0.22015 | Running loss: 0.36741\n",
            "Epoch: 9 | Iteration: 1151 | Classification loss: 0.19933 | Regression loss: 0.20871 | Running loss: 0.36729\n",
            "Epoch: 9 | Iteration: 1152 | Classification loss: 0.13233 | Regression loss: 0.28333 | Running loss: 0.36764\n",
            "Epoch: 9 | Iteration: 1153 | Classification loss: 0.08163 | Regression loss: 0.18405 | Running loss: 0.36773\n",
            "Epoch: 9 | Iteration: 1154 | Classification loss: 0.15011 | Regression loss: 0.20330 | Running loss: 0.36766\n",
            "Epoch: 9 | Iteration: 1155 | Classification loss: 0.05079 | Regression loss: 0.09906 | Running loss: 0.36739\n",
            "Epoch: 9 | Iteration: 1156 | Classification loss: 0.13860 | Regression loss: 0.21689 | Running loss: 0.36728\n",
            "Epoch: 9 | Iteration: 1157 | Classification loss: 0.16747 | Regression loss: 0.32674 | Running loss: 0.36777\n",
            "Epoch: 9 | Iteration: 1158 | Classification loss: 0.14480 | Regression loss: 0.17954 | Running loss: 0.36786\n",
            "Epoch: 9 | Iteration: 1159 | Classification loss: 0.09248 | Regression loss: 0.26130 | Running loss: 0.36756\n",
            "Epoch: 9 | Iteration: 1160 | Classification loss: 0.18266 | Regression loss: 0.34726 | Running loss: 0.36794\n",
            "Epoch: 9 | Iteration: 1161 | Classification loss: 0.12694 | Regression loss: 0.20357 | Running loss: 0.36830\n",
            "Epoch: 9 | Iteration: 1162 | Classification loss: 0.05905 | Regression loss: 0.14797 | Running loss: 0.36816\n",
            "Epoch: 9 | Iteration: 1163 | Classification loss: 0.14387 | Regression loss: 0.31396 | Running loss: 0.36877\n",
            "Epoch: 9 | Iteration: 1164 | Classification loss: 0.11492 | Regression loss: 0.16302 | Running loss: 0.36844\n",
            "Epoch: 9 | Iteration: 1165 | Classification loss: 0.08701 | Regression loss: 0.21934 | Running loss: 0.36857\n",
            "Epoch: 9 | Iteration: 1166 | Classification loss: 0.03238 | Regression loss: 0.16864 | Running loss: 0.36838\n",
            "Epoch: 9 | Iteration: 1167 | Classification loss: 0.13958 | Regression loss: 0.25070 | Running loss: 0.36859\n",
            "Epoch: 9 | Iteration: 1168 | Classification loss: 0.18044 | Regression loss: 0.22666 | Running loss: 0.36806\n",
            "Epoch: 9 | Iteration: 1169 | Classification loss: 0.21242 | Regression loss: 0.42556 | Running loss: 0.36886\n",
            "Epoch: 9 | Iteration: 1170 | Classification loss: 0.08568 | Regression loss: 0.27155 | Running loss: 0.36851\n",
            "Epoch: 9 | Iteration: 1171 | Classification loss: 0.08656 | Regression loss: 0.22803 | Running loss: 0.36834\n",
            "Epoch: 9 | Iteration: 1172 | Classification loss: 0.15769 | Regression loss: 0.22543 | Running loss: 0.36852\n",
            "Epoch: 9 | Iteration: 1173 | Classification loss: 0.07776 | Regression loss: 0.14851 | Running loss: 0.36809\n",
            "Epoch: 9 | Iteration: 1174 | Classification loss: 0.06651 | Regression loss: 0.14702 | Running loss: 0.36738\n",
            "Epoch: 9 | Iteration: 1175 | Classification loss: 0.06114 | Regression loss: 0.11507 | Running loss: 0.36694\n",
            "Epoch: 9 | Iteration: 1176 | Classification loss: 0.03926 | Regression loss: 0.12018 | Running loss: 0.36602\n",
            "Epoch: 9 | Iteration: 1177 | Classification loss: 0.21057 | Regression loss: 0.33831 | Running loss: 0.36645\n",
            "Epoch: 9 | Iteration: 1178 | Classification loss: 0.13310 | Regression loss: 0.33073 | Running loss: 0.36657\n",
            "Epoch: 9 | Iteration: 1179 | Classification loss: 0.07102 | Regression loss: 0.21229 | Running loss: 0.36650\n",
            "Epoch: 9 | Iteration: 1180 | Classification loss: 0.28901 | Regression loss: 0.43924 | Running loss: 0.36705\n",
            "Epoch: 9 | Iteration: 1181 | Classification loss: 0.10367 | Regression loss: 0.19952 | Running loss: 0.36708\n",
            "Epoch: 9 | Iteration: 1182 | Classification loss: 0.05996 | Regression loss: 0.14976 | Running loss: 0.36699\n",
            "Epoch: 9 | Iteration: 1183 | Classification loss: 0.05325 | Regression loss: 0.18161 | Running loss: 0.36675\n",
            "Epoch: 9 | Iteration: 1184 | Classification loss: 0.09690 | Regression loss: 0.29787 | Running loss: 0.36663\n",
            "Epoch: 9 | Iteration: 1185 | Classification loss: 0.13182 | Regression loss: 0.34382 | Running loss: 0.36663\n",
            "Epoch: 9 | Iteration: 1186 | Classification loss: 0.06639 | Regression loss: 0.16420 | Running loss: 0.36646\n",
            "Epoch: 9 | Iteration: 1187 | Classification loss: 0.16538 | Regression loss: 0.27246 | Running loss: 0.36645\n",
            "Epoch: 9 | Iteration: 1188 | Classification loss: 0.08328 | Regression loss: 0.32057 | Running loss: 0.36605\n",
            "Epoch: 9 | Iteration: 1189 | Classification loss: 0.08720 | Regression loss: 0.13422 | Running loss: 0.36546\n",
            "Epoch: 9 | Iteration: 1190 | Classification loss: 0.06947 | Regression loss: 0.17322 | Running loss: 0.36521\n",
            "Epoch: 9 | Iteration: 1191 | Classification loss: 0.15841 | Regression loss: 0.29512 | Running loss: 0.36551\n",
            "Epoch: 9 | Iteration: 1192 | Classification loss: 0.16227 | Regression loss: 0.26139 | Running loss: 0.36586\n",
            "Epoch: 9 | Iteration: 1193 | Classification loss: 0.17795 | Regression loss: 0.44533 | Running loss: 0.36611\n",
            "Epoch: 9 | Iteration: 1194 | Classification loss: 0.09664 | Regression loss: 0.29526 | Running loss: 0.36651\n",
            "Epoch: 9 | Iteration: 1195 | Classification loss: 0.11812 | Regression loss: 0.19818 | Running loss: 0.36618\n",
            "Epoch: 9 | Iteration: 1196 | Classification loss: 0.11978 | Regression loss: 0.21935 | Running loss: 0.36613\n",
            "Epoch: 9 | Iteration: 1197 | Classification loss: 0.14464 | Regression loss: 0.32286 | Running loss: 0.36639\n",
            "Epoch: 9 | Iteration: 1198 | Classification loss: 0.10496 | Regression loss: 0.25602 | Running loss: 0.36618\n",
            "Epoch: 9 | Iteration: 1199 | Classification loss: 0.13615 | Regression loss: 0.34691 | Running loss: 0.36684\n",
            "Evaluating dataset\n",
            "\n",
            "mAP:\n",
            "ambulance: 0.035395189003436425\n",
            "auto rickshaw: 0.3048135270414572\n",
            "bicycle: 0.29756914763993325\n",
            "bus: 0.6569383615132092\n",
            "car: 0.6193007135551771\n",
            "garbage van: 0\n",
            "human hauler: 0.16127098861252326\n",
            "minibus: 0.028729574400795394\n",
            "minivan: 0.26194965814884424\n",
            "motorbike: 0.5514842353282138\n",
            "pickup: 0.33169447467528546\n",
            "army vehicle: 0.6398635477582846\n",
            "policecar: 0.0\n",
            "rickshaw: 0.5146058437179595\n",
            "scooter: 0.05\n",
            "suv: 0.20880813493438452\n",
            "taxi: 0.3645833333333333\n",
            "three wheelers (CNG): 0.5787556225140511\n",
            "truck: 0.6307819012989313\n",
            "van: 0.18521627714137454\n",
            "wheelbarrow: 0.03693422170048116\n",
            "Epoch: 10 | Iteration: 0 | Classification loss: 0.11389 | Regression loss: 0.29444 | Running loss: 0.36700\n",
            "Epoch: 10 | Iteration: 1 | Classification loss: 0.10670 | Regression loss: 0.14992 | Running loss: 0.36721\n",
            "Epoch: 10 | Iteration: 2 | Classification loss: 0.10266 | Regression loss: 0.25458 | Running loss: 0.36728\n",
            "Epoch: 10 | Iteration: 3 | Classification loss: 0.03149 | Regression loss: 0.11595 | Running loss: 0.36691\n",
            "Epoch: 10 | Iteration: 4 | Classification loss: 0.14525 | Regression loss: 0.29577 | Running loss: 0.36711\n",
            "Epoch: 10 | Iteration: 5 | Classification loss: 0.12538 | Regression loss: 0.28481 | Running loss: 0.36726\n",
            "Epoch: 10 | Iteration: 6 | Classification loss: 0.02179 | Regression loss: 0.12654 | Running loss: 0.36670\n",
            "Epoch: 10 | Iteration: 7 | Classification loss: 0.04314 | Regression loss: 0.13985 | Running loss: 0.36642\n",
            "Epoch: 10 | Iteration: 8 | Classification loss: 0.12199 | Regression loss: 0.25464 | Running loss: 0.36619\n",
            "Epoch: 10 | Iteration: 9 | Classification loss: 0.04559 | Regression loss: 0.12162 | Running loss: 0.36597\n",
            "Epoch: 10 | Iteration: 10 | Classification loss: 0.18765 | Regression loss: 0.38161 | Running loss: 0.36670\n",
            "Epoch: 10 | Iteration: 11 | Classification loss: 0.14275 | Regression loss: 0.29762 | Running loss: 0.36680\n",
            "Epoch: 10 | Iteration: 12 | Classification loss: 0.08576 | Regression loss: 0.17763 | Running loss: 0.36623\n",
            "Epoch: 10 | Iteration: 13 | Classification loss: 0.28099 | Regression loss: 0.28059 | Running loss: 0.36637\n",
            "Epoch: 10 | Iteration: 14 | Classification loss: 0.07941 | Regression loss: 0.12901 | Running loss: 0.36584\n",
            "Epoch: 10 | Iteration: 15 | Classification loss: 0.10681 | Regression loss: 0.19193 | Running loss: 0.36514\n",
            "Epoch: 10 | Iteration: 16 | Classification loss: 0.09297 | Regression loss: 0.20329 | Running loss: 0.36487\n",
            "Epoch: 10 | Iteration: 17 | Classification loss: 0.08060 | Regression loss: 0.23460 | Running loss: 0.36473\n",
            "Epoch: 10 | Iteration: 18 | Classification loss: 0.06703 | Regression loss: 0.18963 | Running loss: 0.36449\n",
            "Epoch: 10 | Iteration: 19 | Classification loss: 0.11829 | Regression loss: 0.16940 | Running loss: 0.36410\n",
            "Epoch: 10 | Iteration: 20 | Classification loss: 0.06869 | Regression loss: 0.16980 | Running loss: 0.36375\n",
            "Epoch: 10 | Iteration: 21 | Classification loss: 0.03911 | Regression loss: 0.11484 | Running loss: 0.36348\n",
            "Epoch: 10 | Iteration: 22 | Classification loss: 0.08535 | Regression loss: 0.26969 | Running loss: 0.36339\n",
            "Epoch: 10 | Iteration: 23 | Classification loss: 0.17433 | Regression loss: 0.32871 | Running loss: 0.36377\n",
            "Epoch: 10 | Iteration: 24 | Classification loss: 0.13787 | Regression loss: 0.26723 | Running loss: 0.36386\n",
            "Epoch: 10 | Iteration: 25 | Classification loss: 0.02053 | Regression loss: 0.17496 | Running loss: 0.36358\n",
            "Epoch: 10 | Iteration: 26 | Classification loss: 0.03548 | Regression loss: 0.18726 | Running loss: 0.36354\n",
            "Epoch: 10 | Iteration: 27 | Classification loss: 0.08530 | Regression loss: 0.24722 | Running loss: 0.36327\n",
            "Epoch: 10 | Iteration: 28 | Classification loss: 0.10006 | Regression loss: 0.09982 | Running loss: 0.36296\n",
            "Epoch: 10 | Iteration: 29 | Classification loss: 0.09316 | Regression loss: 0.16529 | Running loss: 0.36303\n",
            "Epoch: 10 | Iteration: 30 | Classification loss: 0.06631 | Regression loss: 0.21099 | Running loss: 0.36315\n",
            "Epoch: 10 | Iteration: 31 | Classification loss: 0.08931 | Regression loss: 0.25853 | Running loss: 0.36300\n",
            "Epoch: 10 | Iteration: 32 | Classification loss: 0.13270 | Regression loss: 0.23159 | Running loss: 0.36343\n",
            "Epoch: 10 | Iteration: 33 | Classification loss: 0.12364 | Regression loss: 0.26736 | Running loss: 0.36369\n",
            "Epoch: 10 | Iteration: 34 | Classification loss: 0.07014 | Regression loss: 0.19369 | Running loss: 0.36381\n",
            "Epoch: 10 | Iteration: 35 | Classification loss: 0.17244 | Regression loss: 0.38467 | Running loss: 0.36390\n",
            "Epoch: 10 | Iteration: 36 | Classification loss: 0.08235 | Regression loss: 0.13087 | Running loss: 0.36366\n",
            "Epoch: 10 | Iteration: 37 | Classification loss: 0.05763 | Regression loss: 0.15017 | Running loss: 0.36352\n",
            "Epoch: 10 | Iteration: 38 | Classification loss: 0.09514 | Regression loss: 0.28950 | Running loss: 0.36361\n",
            "Epoch: 10 | Iteration: 39 | Classification loss: 0.06866 | Regression loss: 0.18005 | Running loss: 0.36349\n",
            "Epoch: 10 | Iteration: 40 | Classification loss: 0.14595 | Regression loss: 0.22932 | Running loss: 0.36371\n",
            "Epoch: 10 | Iteration: 41 | Classification loss: 0.09504 | Regression loss: 0.17718 | Running loss: 0.36379\n",
            "Epoch: 10 | Iteration: 42 | Classification loss: 0.13377 | Regression loss: 0.15709 | Running loss: 0.36363\n",
            "Epoch: 10 | Iteration: 43 | Classification loss: 0.14090 | Regression loss: 0.29380 | Running loss: 0.36395\n",
            "Epoch: 10 | Iteration: 44 | Classification loss: 0.10566 | Regression loss: 0.15452 | Running loss: 0.36372\n",
            "Epoch: 10 | Iteration: 45 | Classification loss: 0.27489 | Regression loss: 0.52922 | Running loss: 0.36472\n",
            "Epoch: 10 | Iteration: 46 | Classification loss: 0.15202 | Regression loss: 0.19789 | Running loss: 0.36490\n",
            "Epoch: 10 | Iteration: 47 | Classification loss: 0.06175 | Regression loss: 0.17454 | Running loss: 0.36505\n",
            "Epoch: 10 | Iteration: 48 | Classification loss: 0.13702 | Regression loss: 0.28846 | Running loss: 0.36506\n",
            "Epoch: 10 | Iteration: 49 | Classification loss: 0.05816 | Regression loss: 0.24252 | Running loss: 0.36500\n",
            "Epoch: 10 | Iteration: 50 | Classification loss: 0.20467 | Regression loss: 0.38198 | Running loss: 0.36575\n",
            "Epoch: 10 | Iteration: 51 | Classification loss: 0.03407 | Regression loss: 0.18687 | Running loss: 0.36530\n",
            "Epoch: 10 | Iteration: 52 | Classification loss: 0.12134 | Regression loss: 0.30982 | Running loss: 0.36543\n",
            "Epoch: 10 | Iteration: 53 | Classification loss: 0.08345 | Regression loss: 0.17612 | Running loss: 0.36491\n",
            "Epoch: 10 | Iteration: 54 | Classification loss: 0.12771 | Regression loss: 0.31825 | Running loss: 0.36497\n",
            "Epoch: 10 | Iteration: 55 | Classification loss: 0.18744 | Regression loss: 0.27165 | Running loss: 0.36537\n",
            "Epoch: 10 | Iteration: 56 | Classification loss: 0.09899 | Regression loss: 0.15644 | Running loss: 0.36482\n",
            "Epoch: 10 | Iteration: 57 | Classification loss: 0.11154 | Regression loss: 0.13875 | Running loss: 0.36460\n",
            "Epoch: 10 | Iteration: 58 | Classification loss: 0.10217 | Regression loss: 0.21913 | Running loss: 0.36442\n",
            "Epoch: 10 | Iteration: 59 | Classification loss: 0.20495 | Regression loss: 0.39349 | Running loss: 0.36451\n",
            "Epoch: 10 | Iteration: 60 | Classification loss: 0.08232 | Regression loss: 0.25906 | Running loss: 0.36427\n",
            "Epoch: 10 | Iteration: 61 | Classification loss: 0.05981 | Regression loss: 0.15815 | Running loss: 0.36401\n",
            "Epoch: 10 | Iteration: 62 | Classification loss: 0.12152 | Regression loss: 0.32269 | Running loss: 0.36444\n",
            "Epoch: 10 | Iteration: 63 | Classification loss: 0.13932 | Regression loss: 0.25077 | Running loss: 0.36443\n",
            "Epoch: 10 | Iteration: 64 | Classification loss: 0.02642 | Regression loss: 0.09329 | Running loss: 0.36401\n",
            "Epoch: 10 | Iteration: 65 | Classification loss: 0.11930 | Regression loss: 0.24143 | Running loss: 0.36415\n",
            "Epoch: 10 | Iteration: 66 | Classification loss: 0.11794 | Regression loss: 0.31927 | Running loss: 0.36435\n",
            "Epoch: 10 | Iteration: 67 | Classification loss: 0.08196 | Regression loss: 0.19004 | Running loss: 0.36409\n",
            "Epoch: 10 | Iteration: 68 | Classification loss: 0.12371 | Regression loss: 0.21705 | Running loss: 0.36428\n",
            "Epoch: 10 | Iteration: 69 | Classification loss: 0.10499 | Regression loss: 0.25653 | Running loss: 0.36420\n",
            "Epoch: 10 | Iteration: 70 | Classification loss: 0.05479 | Regression loss: 0.20573 | Running loss: 0.36372\n",
            "Epoch: 10 | Iteration: 71 | Classification loss: 0.07494 | Regression loss: 0.22844 | Running loss: 0.36400\n",
            "Epoch: 10 | Iteration: 72 | Classification loss: 0.08025 | Regression loss: 0.17581 | Running loss: 0.36344\n",
            "Epoch: 10 | Iteration: 73 | Classification loss: 0.04566 | Regression loss: 0.16063 | Running loss: 0.36332\n",
            "Epoch: 10 | Iteration: 74 | Classification loss: 0.13720 | Regression loss: 0.30917 | Running loss: 0.36311\n",
            "Epoch: 10 | Iteration: 75 | Classification loss: 0.15581 | Regression loss: 0.10549 | Running loss: 0.36266\n",
            "Epoch: 10 | Iteration: 76 | Classification loss: 0.11825 | Regression loss: 0.23757 | Running loss: 0.36199\n",
            "Epoch: 10 | Iteration: 77 | Classification loss: 0.12766 | Regression loss: 0.24593 | Running loss: 0.36180\n",
            "Epoch: 10 | Iteration: 78 | Classification loss: 0.10096 | Regression loss: 0.16755 | Running loss: 0.36200\n",
            "Epoch: 10 | Iteration: 79 | Classification loss: 0.02789 | Regression loss: 0.14576 | Running loss: 0.36094\n",
            "Epoch: 10 | Iteration: 80 | Classification loss: 0.14064 | Regression loss: 0.22878 | Running loss: 0.36095\n",
            "Epoch: 10 | Iteration: 81 | Classification loss: 0.14942 | Regression loss: 0.25742 | Running loss: 0.36132\n",
            "Epoch: 10 | Iteration: 82 | Classification loss: 0.12246 | Regression loss: 0.31660 | Running loss: 0.36165\n",
            "Epoch: 10 | Iteration: 83 | Classification loss: 0.09017 | Regression loss: 0.18317 | Running loss: 0.36171\n",
            "Epoch: 10 | Iteration: 84 | Classification loss: 0.05220 | Regression loss: 0.13937 | Running loss: 0.36168\n",
            "Epoch: 10 | Iteration: 85 | Classification loss: 0.04927 | Regression loss: 0.14999 | Running loss: 0.36159\n",
            "Epoch: 10 | Iteration: 86 | Classification loss: 0.24575 | Regression loss: 0.34901 | Running loss: 0.36226\n",
            "Epoch: 10 | Iteration: 87 | Classification loss: 0.12040 | Regression loss: 0.23281 | Running loss: 0.36245\n",
            "Epoch: 10 | Iteration: 88 | Classification loss: 0.08253 | Regression loss: 0.18670 | Running loss: 0.36139\n",
            "Epoch: 10 | Iteration: 89 | Classification loss: 0.14708 | Regression loss: 0.22073 | Running loss: 0.36138\n",
            "Epoch: 10 | Iteration: 90 | Classification loss: 0.09080 | Regression loss: 0.13114 | Running loss: 0.36098\n",
            "Epoch: 10 | Iteration: 91 | Classification loss: 0.10471 | Regression loss: 0.25302 | Running loss: 0.36119\n",
            "Epoch: 10 | Iteration: 92 | Classification loss: 0.17752 | Regression loss: 0.28005 | Running loss: 0.36166\n",
            "Epoch: 10 | Iteration: 93 | Classification loss: 0.11326 | Regression loss: 0.16544 | Running loss: 0.36139\n",
            "Epoch: 10 | Iteration: 94 | Classification loss: 0.10556 | Regression loss: 0.13406 | Running loss: 0.36119\n",
            "Epoch: 10 | Iteration: 95 | Classification loss: 0.01207 | Regression loss: 0.09079 | Running loss: 0.36081\n",
            "Epoch: 10 | Iteration: 96 | Classification loss: 0.10114 | Regression loss: 0.18589 | Running loss: 0.36074\n",
            "Epoch: 10 | Iteration: 97 | Classification loss: 0.18921 | Regression loss: 0.17565 | Running loss: 0.36081\n",
            "Epoch: 10 | Iteration: 98 | Classification loss: 0.16096 | Regression loss: 0.19198 | Running loss: 0.36077\n",
            "Epoch: 10 | Iteration: 99 | Classification loss: 0.17740 | Regression loss: 0.34041 | Running loss: 0.36098\n",
            "Epoch: 10 | Iteration: 100 | Classification loss: 0.07044 | Regression loss: 0.05406 | Running loss: 0.36086\n",
            "Epoch: 10 | Iteration: 101 | Classification loss: 0.11143 | Regression loss: 0.23310 | Running loss: 0.36052\n",
            "Epoch: 10 | Iteration: 102 | Classification loss: 0.17319 | Regression loss: 0.28287 | Running loss: 0.36063\n",
            "Epoch: 10 | Iteration: 103 | Classification loss: 0.04675 | Regression loss: 0.16627 | Running loss: 0.36026\n",
            "Epoch: 10 | Iteration: 104 | Classification loss: 0.19888 | Regression loss: 0.34667 | Running loss: 0.36049\n",
            "Epoch: 10 | Iteration: 105 | Classification loss: 0.11088 | Regression loss: 0.29443 | Running loss: 0.36068\n",
            "Epoch: 10 | Iteration: 106 | Classification loss: 0.07936 | Regression loss: 0.23605 | Running loss: 0.36082\n",
            "Epoch: 10 | Iteration: 107 | Classification loss: 0.04230 | Regression loss: 0.12337 | Running loss: 0.36065\n",
            "Epoch: 10 | Iteration: 108 | Classification loss: 0.18755 | Regression loss: 0.35396 | Running loss: 0.36107\n",
            "Epoch: 10 | Iteration: 109 | Classification loss: 0.05557 | Regression loss: 0.22297 | Running loss: 0.36126\n",
            "Epoch: 10 | Iteration: 110 | Classification loss: 0.02711 | Regression loss: 0.08258 | Running loss: 0.36114\n",
            "Epoch: 10 | Iteration: 111 | Classification loss: 0.10166 | Regression loss: 0.23682 | Running loss: 0.36074\n",
            "Epoch: 10 | Iteration: 112 | Classification loss: 0.08387 | Regression loss: 0.18548 | Running loss: 0.36010\n",
            "Epoch: 10 | Iteration: 113 | Classification loss: 0.19084 | Regression loss: 0.39574 | Running loss: 0.36032\n",
            "Epoch: 10 | Iteration: 114 | Classification loss: 0.11333 | Regression loss: 0.23966 | Running loss: 0.36025\n",
            "Epoch: 10 | Iteration: 115 | Classification loss: 0.09007 | Regression loss: 0.22486 | Running loss: 0.36024\n",
            "Epoch: 10 | Iteration: 116 | Classification loss: 0.22730 | Regression loss: 0.22229 | Running loss: 0.36000\n",
            "Epoch: 10 | Iteration: 117 | Classification loss: 0.11456 | Regression loss: 0.12413 | Running loss: 0.35997\n",
            "Epoch: 10 | Iteration: 118 | Classification loss: 0.22802 | Regression loss: 0.36518 | Running loss: 0.36027\n",
            "Epoch: 10 | Iteration: 119 | Classification loss: 0.05741 | Regression loss: 0.13041 | Running loss: 0.36005\n",
            "Epoch: 10 | Iteration: 120 | Classification loss: 0.08198 | Regression loss: 0.14659 | Running loss: 0.35956\n",
            "Epoch: 10 | Iteration: 121 | Classification loss: 0.07338 | Regression loss: 0.18902 | Running loss: 0.35908\n",
            "Epoch: 10 | Iteration: 122 | Classification loss: 0.03411 | Regression loss: 0.06844 | Running loss: 0.35803\n",
            "Epoch: 10 | Iteration: 123 | Classification loss: 0.09864 | Regression loss: 0.26654 | Running loss: 0.35818\n",
            "Epoch: 10 | Iteration: 124 | Classification loss: 0.08355 | Regression loss: 0.13815 | Running loss: 0.35782\n",
            "Epoch: 10 | Iteration: 125 | Classification loss: 0.09303 | Regression loss: 0.20811 | Running loss: 0.35788\n",
            "Epoch: 10 | Iteration: 126 | Classification loss: 0.16535 | Regression loss: 0.27262 | Running loss: 0.35827\n",
            "Epoch: 10 | Iteration: 127 | Classification loss: 0.07571 | Regression loss: 0.10547 | Running loss: 0.35781\n",
            "Epoch: 10 | Iteration: 128 | Classification loss: 0.06918 | Regression loss: 0.22929 | Running loss: 0.35764\n",
            "Epoch: 10 | Iteration: 129 | Classification loss: 0.11610 | Regression loss: 0.16545 | Running loss: 0.35758\n",
            "Epoch: 10 | Iteration: 130 | Classification loss: 0.07867 | Regression loss: 0.10972 | Running loss: 0.35734\n",
            "Epoch: 10 | Iteration: 131 | Classification loss: 0.14093 | Regression loss: 0.29277 | Running loss: 0.35746\n",
            "Epoch: 10 | Iteration: 132 | Classification loss: 0.17112 | Regression loss: 0.37302 | Running loss: 0.35799\n",
            "Epoch: 10 | Iteration: 133 | Classification loss: 0.17615 | Regression loss: 0.36000 | Running loss: 0.35854\n",
            "Epoch: 10 | Iteration: 134 | Classification loss: 0.15886 | Regression loss: 0.23270 | Running loss: 0.35856\n",
            "Epoch: 10 | Iteration: 135 | Classification loss: 0.10296 | Regression loss: 0.22114 | Running loss: 0.35849\n",
            "Epoch: 10 | Iteration: 136 | Classification loss: 0.08608 | Regression loss: 0.23660 | Running loss: 0.35820\n",
            "Epoch: 10 | Iteration: 137 | Classification loss: 0.04617 | Regression loss: 0.11587 | Running loss: 0.35728\n",
            "Epoch: 10 | Iteration: 138 | Classification loss: 0.10334 | Regression loss: 0.15804 | Running loss: 0.35692\n",
            "Epoch: 10 | Iteration: 139 | Classification loss: 0.11775 | Regression loss: 0.16933 | Running loss: 0.35657\n",
            "Epoch: 10 | Iteration: 140 | Classification loss: 0.02735 | Regression loss: 0.10730 | Running loss: 0.35631\n",
            "Epoch: 10 | Iteration: 141 | Classification loss: 0.05444 | Regression loss: 0.09856 | Running loss: 0.35562\n",
            "Epoch: 10 | Iteration: 142 | Classification loss: 0.03703 | Regression loss: 0.15275 | Running loss: 0.35469\n",
            "Epoch: 10 | Iteration: 143 | Classification loss: 0.18677 | Regression loss: 0.28904 | Running loss: 0.35455\n",
            "Epoch: 10 | Iteration: 144 | Classification loss: 0.10302 | Regression loss: 0.18376 | Running loss: 0.35428\n",
            "Epoch: 10 | Iteration: 145 | Classification loss: 0.04726 | Regression loss: 0.04932 | Running loss: 0.35385\n",
            "Epoch: 10 | Iteration: 146 | Classification loss: 0.15748 | Regression loss: 0.32753 | Running loss: 0.35442\n",
            "Epoch: 10 | Iteration: 147 | Classification loss: 0.13588 | Regression loss: 0.32854 | Running loss: 0.35461\n",
            "Epoch: 10 | Iteration: 148 | Classification loss: 0.18139 | Regression loss: 0.36931 | Running loss: 0.35447\n",
            "Epoch: 10 | Iteration: 149 | Classification loss: 0.17803 | Regression loss: 0.17458 | Running loss: 0.35411\n",
            "Epoch: 10 | Iteration: 150 | Classification loss: 0.13799 | Regression loss: 0.23600 | Running loss: 0.35436\n",
            "Epoch: 10 | Iteration: 151 | Classification loss: 0.09682 | Regression loss: 0.17353 | Running loss: 0.35379\n",
            "Epoch: 10 | Iteration: 152 | Classification loss: 0.09690 | Regression loss: 0.23749 | Running loss: 0.35366\n",
            "Epoch: 10 | Iteration: 153 | Classification loss: 0.07677 | Regression loss: 0.15940 | Running loss: 0.35344\n",
            "Epoch: 10 | Iteration: 154 | Classification loss: 0.14979 | Regression loss: 0.24156 | Running loss: 0.35376\n",
            "Epoch: 10 | Iteration: 155 | Classification loss: 0.05714 | Regression loss: 0.08087 | Running loss: 0.35295\n",
            "Epoch: 10 | Iteration: 156 | Classification loss: 0.11957 | Regression loss: 0.26053 | Running loss: 0.35310\n",
            "Epoch: 10 | Iteration: 157 | Classification loss: 0.06903 | Regression loss: 0.17505 | Running loss: 0.35303\n",
            "Epoch: 10 | Iteration: 158 | Classification loss: 0.11001 | Regression loss: 0.34631 | Running loss: 0.35304\n",
            "Epoch: 10 | Iteration: 159 | Classification loss: 0.37787 | Regression loss: 0.36331 | Running loss: 0.35346\n",
            "Epoch: 10 | Iteration: 160 | Classification loss: 0.07352 | Regression loss: 0.22896 | Running loss: 0.35354\n",
            "Epoch: 10 | Iteration: 161 | Classification loss: 0.06562 | Regression loss: 0.13547 | Running loss: 0.35319\n",
            "Epoch: 10 | Iteration: 162 | Classification loss: 0.22608 | Regression loss: 0.26490 | Running loss: 0.35354\n",
            "Epoch: 10 | Iteration: 163 | Classification loss: 0.07172 | Regression loss: 0.19745 | Running loss: 0.35347\n",
            "Epoch: 10 | Iteration: 164 | Classification loss: 0.15133 | Regression loss: 0.26283 | Running loss: 0.35335\n",
            "Epoch: 10 | Iteration: 165 | Classification loss: 0.05942 | Regression loss: 0.15731 | Running loss: 0.35276\n",
            "Epoch: 10 | Iteration: 166 | Classification loss: 0.18680 | Regression loss: 0.38993 | Running loss: 0.35341\n",
            "Epoch: 10 | Iteration: 167 | Classification loss: 0.09214 | Regression loss: 0.18840 | Running loss: 0.35324\n",
            "Epoch: 10 | Iteration: 168 | Classification loss: 0.15387 | Regression loss: 0.19818 | Running loss: 0.35338\n",
            "Epoch: 10 | Iteration: 169 | Classification loss: 0.11937 | Regression loss: 0.22515 | Running loss: 0.35308\n",
            "Epoch: 10 | Iteration: 170 | Classification loss: 0.11997 | Regression loss: 0.27575 | Running loss: 0.35341\n",
            "Epoch: 10 | Iteration: 171 | Classification loss: 0.08761 | Regression loss: 0.15050 | Running loss: 0.35350\n",
            "Epoch: 10 | Iteration: 172 | Classification loss: 0.11376 | Regression loss: 0.27755 | Running loss: 0.35376\n",
            "Epoch: 10 | Iteration: 173 | Classification loss: 0.11958 | Regression loss: 0.24155 | Running loss: 0.35362\n",
            "Epoch: 10 | Iteration: 174 | Classification loss: 0.05118 | Regression loss: 0.12257 | Running loss: 0.35290\n",
            "Epoch: 10 | Iteration: 175 | Classification loss: 0.16702 | Regression loss: 0.29405 | Running loss: 0.35310\n",
            "Epoch: 10 | Iteration: 176 | Classification loss: 0.10093 | Regression loss: 0.32336 | Running loss: 0.35370\n",
            "Epoch: 10 | Iteration: 177 | Classification loss: 0.20359 | Regression loss: 0.14561 | Running loss: 0.35353\n",
            "Epoch: 10 | Iteration: 178 | Classification loss: 0.09282 | Regression loss: 0.17018 | Running loss: 0.35342\n",
            "Epoch: 10 | Iteration: 179 | Classification loss: 0.04051 | Regression loss: 0.14807 | Running loss: 0.35291\n",
            "Epoch: 10 | Iteration: 180 | Classification loss: 0.07239 | Regression loss: 0.20727 | Running loss: 0.35301\n",
            "Epoch: 10 | Iteration: 181 | Classification loss: 0.12203 | Regression loss: 0.12902 | Running loss: 0.35238\n",
            "Epoch: 10 | Iteration: 182 | Classification loss: 0.12473 | Regression loss: 0.30432 | Running loss: 0.35279\n",
            "Epoch: 10 | Iteration: 183 | Classification loss: 0.03594 | Regression loss: 0.16091 | Running loss: 0.35275\n",
            "Epoch: 10 | Iteration: 184 | Classification loss: 0.08913 | Regression loss: 0.10758 | Running loss: 0.35270\n",
            "Epoch: 10 | Iteration: 185 | Classification loss: 0.05656 | Regression loss: 0.14230 | Running loss: 0.35257\n",
            "Epoch: 10 | Iteration: 186 | Classification loss: 0.14331 | Regression loss: 0.21973 | Running loss: 0.35265\n",
            "Epoch: 10 | Iteration: 187 | Classification loss: 0.08870 | Regression loss: 0.21044 | Running loss: 0.35294\n",
            "Epoch: 10 | Iteration: 188 | Classification loss: 0.09243 | Regression loss: 0.25678 | Running loss: 0.35299\n",
            "Epoch: 10 | Iteration: 189 | Classification loss: 0.15219 | Regression loss: 0.25670 | Running loss: 0.35274\n",
            "Epoch: 10 | Iteration: 190 | Classification loss: 0.05629 | Regression loss: 0.09567 | Running loss: 0.35189\n",
            "Epoch: 10 | Iteration: 191 | Classification loss: 0.21575 | Regression loss: 0.33872 | Running loss: 0.35235\n",
            "Epoch: 10 | Iteration: 192 | Classification loss: 0.09218 | Regression loss: 0.23289 | Running loss: 0.35231\n",
            "Epoch: 10 | Iteration: 193 | Classification loss: 0.12433 | Regression loss: 0.19494 | Running loss: 0.35198\n",
            "Epoch: 10 | Iteration: 194 | Classification loss: 0.09536 | Regression loss: 0.21746 | Running loss: 0.35171\n",
            "Epoch: 10 | Iteration: 195 | Classification loss: 0.13427 | Regression loss: 0.30929 | Running loss: 0.35192\n",
            "Epoch: 10 | Iteration: 196 | Classification loss: 0.14845 | Regression loss: 0.18394 | Running loss: 0.35199\n",
            "Epoch: 10 | Iteration: 197 | Classification loss: 0.14271 | Regression loss: 0.32067 | Running loss: 0.35241\n",
            "Epoch: 10 | Iteration: 198 | Classification loss: 0.06999 | Regression loss: 0.21787 | Running loss: 0.35215\n",
            "Epoch: 10 | Iteration: 199 | Classification loss: 0.08641 | Regression loss: 0.19009 | Running loss: 0.35219\n",
            "Epoch: 10 | Iteration: 200 | Classification loss: 0.07892 | Regression loss: 0.23462 | Running loss: 0.35240\n",
            "Epoch: 10 | Iteration: 201 | Classification loss: 0.02379 | Regression loss: 0.09639 | Running loss: 0.35126\n",
            "Epoch: 10 | Iteration: 202 | Classification loss: 0.15575 | Regression loss: 0.24839 | Running loss: 0.35180\n",
            "Epoch: 10 | Iteration: 203 | Classification loss: 0.08975 | Regression loss: 0.20798 | Running loss: 0.35107\n",
            "Epoch: 10 | Iteration: 204 | Classification loss: 0.09962 | Regression loss: 0.18775 | Running loss: 0.35109\n",
            "Epoch: 10 | Iteration: 205 | Classification loss: 0.06897 | Regression loss: 0.20233 | Running loss: 0.35114\n",
            "Epoch: 10 | Iteration: 206 | Classification loss: 0.10743 | Regression loss: 0.19010 | Running loss: 0.35093\n",
            "Epoch: 10 | Iteration: 207 | Classification loss: 0.12845 | Regression loss: 0.22812 | Running loss: 0.35098\n",
            "Epoch: 10 | Iteration: 208 | Classification loss: 0.12019 | Regression loss: 0.38884 | Running loss: 0.35078\n",
            "Epoch: 10 | Iteration: 209 | Classification loss: 0.05644 | Regression loss: 0.16825 | Running loss: 0.35016\n",
            "Epoch: 10 | Iteration: 210 | Classification loss: 0.04698 | Regression loss: 0.20713 | Running loss: 0.34918\n",
            "Epoch: 10 | Iteration: 211 | Classification loss: 0.07380 | Regression loss: 0.23528 | Running loss: 0.34912\n",
            "Epoch: 10 | Iteration: 212 | Classification loss: 0.05893 | Regression loss: 0.18424 | Running loss: 0.34834\n",
            "Epoch: 10 | Iteration: 213 | Classification loss: 0.02702 | Regression loss: 0.12300 | Running loss: 0.34767\n",
            "Epoch: 10 | Iteration: 214 | Classification loss: 0.17249 | Regression loss: 0.39080 | Running loss: 0.34759\n",
            "Epoch: 10 | Iteration: 215 | Classification loss: 0.07820 | Regression loss: 0.24184 | Running loss: 0.34776\n",
            "Epoch: 10 | Iteration: 216 | Classification loss: 0.09006 | Regression loss: 0.28462 | Running loss: 0.34827\n",
            "Epoch: 10 | Iteration: 217 | Classification loss: 0.03821 | Regression loss: 0.14581 | Running loss: 0.34766\n",
            "Epoch: 10 | Iteration: 218 | Classification loss: 0.18647 | Regression loss: 0.30424 | Running loss: 0.34796\n",
            "Epoch: 10 | Iteration: 219 | Classification loss: 0.10359 | Regression loss: 0.24377 | Running loss: 0.34790\n",
            "Epoch: 10 | Iteration: 220 | Classification loss: 0.13829 | Regression loss: 0.27357 | Running loss: 0.34796\n",
            "Epoch: 10 | Iteration: 221 | Classification loss: 0.07395 | Regression loss: 0.23595 | Running loss: 0.34780\n",
            "Epoch: 10 | Iteration: 222 | Classification loss: 0.08764 | Regression loss: 0.23133 | Running loss: 0.34795\n",
            "Epoch: 10 | Iteration: 223 | Classification loss: 0.11274 | Regression loss: 0.20971 | Running loss: 0.34748\n",
            "Epoch: 10 | Iteration: 224 | Classification loss: 0.10064 | Regression loss: 0.12281 | Running loss: 0.34723\n",
            "Epoch: 10 | Iteration: 225 | Classification loss: 0.11668 | Regression loss: 0.17938 | Running loss: 0.34661\n",
            "Epoch: 10 | Iteration: 226 | Classification loss: 0.07396 | Regression loss: 0.17123 | Running loss: 0.34650\n",
            "Epoch: 10 | Iteration: 227 | Classification loss: 0.04587 | Regression loss: 0.15571 | Running loss: 0.34618\n",
            "Epoch: 10 | Iteration: 228 | Classification loss: 0.10433 | Regression loss: 0.21142 | Running loss: 0.34593\n",
            "Epoch: 10 | Iteration: 229 | Classification loss: 0.14275 | Regression loss: 0.16313 | Running loss: 0.34615\n",
            "Epoch: 10 | Iteration: 230 | Classification loss: 0.09659 | Regression loss: 0.31483 | Running loss: 0.34621\n",
            "Epoch: 10 | Iteration: 231 | Classification loss: 0.09196 | Regression loss: 0.35383 | Running loss: 0.34650\n",
            "Epoch: 10 | Iteration: 232 | Classification loss: 0.04385 | Regression loss: 0.17178 | Running loss: 0.34646\n",
            "Epoch: 10 | Iteration: 233 | Classification loss: 0.05181 | Regression loss: 0.23372 | Running loss: 0.34669\n",
            "Epoch: 10 | Iteration: 234 | Classification loss: 0.06140 | Regression loss: 0.20949 | Running loss: 0.34657\n",
            "Epoch: 10 | Iteration: 235 | Classification loss: 0.05801 | Regression loss: 0.13356 | Running loss: 0.34631\n",
            "Epoch: 10 | Iteration: 236 | Classification loss: 0.12288 | Regression loss: 0.24081 | Running loss: 0.34634\n",
            "Epoch: 10 | Iteration: 237 | Classification loss: 0.10111 | Regression loss: 0.18765 | Running loss: 0.34635\n",
            "Epoch: 10 | Iteration: 238 | Classification loss: 0.04506 | Regression loss: 0.14469 | Running loss: 0.34637\n",
            "Epoch: 10 | Iteration: 239 | Classification loss: 0.05354 | Regression loss: 0.19340 | Running loss: 0.34591\n",
            "Epoch: 10 | Iteration: 240 | Classification loss: 0.06191 | Regression loss: 0.23744 | Running loss: 0.34533\n",
            "Epoch: 10 | Iteration: 241 | Classification loss: 0.09641 | Regression loss: 0.20043 | Running loss: 0.34584\n",
            "Epoch: 10 | Iteration: 242 | Classification loss: 0.08155 | Regression loss: 0.16547 | Running loss: 0.34594\n",
            "Epoch: 10 | Iteration: 243 | Classification loss: 0.06547 | Regression loss: 0.18074 | Running loss: 0.34587\n",
            "Epoch: 10 | Iteration: 244 | Classification loss: 0.14289 | Regression loss: 0.31266 | Running loss: 0.34624\n",
            "Epoch: 10 | Iteration: 245 | Classification loss: 0.28319 | Regression loss: 0.33554 | Running loss: 0.34711\n",
            "Epoch: 10 | Iteration: 246 | Classification loss: 0.09883 | Regression loss: 0.24566 | Running loss: 0.34733\n",
            "Epoch: 10 | Iteration: 247 | Classification loss: 0.04077 | Regression loss: 0.13196 | Running loss: 0.34680\n",
            "Epoch: 10 | Iteration: 248 | Classification loss: 0.06827 | Regression loss: 0.18449 | Running loss: 0.34655\n",
            "Epoch: 10 | Iteration: 249 | Classification loss: 0.08695 | Regression loss: 0.21665 | Running loss: 0.34607\n",
            "Epoch: 10 | Iteration: 250 | Classification loss: 0.02137 | Regression loss: 0.13300 | Running loss: 0.34606\n",
            "Epoch: 10 | Iteration: 251 | Classification loss: 0.15794 | Regression loss: 0.28516 | Running loss: 0.34647\n",
            "Epoch: 10 | Iteration: 252 | Classification loss: 0.28504 | Regression loss: 0.45163 | Running loss: 0.34643\n",
            "Epoch: 10 | Iteration: 253 | Classification loss: 0.18486 | Regression loss: 0.28483 | Running loss: 0.34658\n",
            "Epoch: 10 | Iteration: 254 | Classification loss: 0.02487 | Regression loss: 0.11145 | Running loss: 0.34602\n",
            "Epoch: 10 | Iteration: 255 | Classification loss: 0.15664 | Regression loss: 0.30726 | Running loss: 0.34604\n",
            "Epoch: 10 | Iteration: 256 | Classification loss: 0.08783 | Regression loss: 0.33217 | Running loss: 0.34620\n",
            "Epoch: 10 | Iteration: 257 | Classification loss: 0.12915 | Regression loss: 0.25699 | Running loss: 0.34644\n",
            "Epoch: 10 | Iteration: 258 | Classification loss: 0.04253 | Regression loss: 0.12702 | Running loss: 0.34629\n",
            "Epoch: 10 | Iteration: 259 | Classification loss: 0.65545 | Regression loss: 0.30885 | Running loss: 0.34742\n",
            "Epoch: 10 | Iteration: 260 | Classification loss: 0.05847 | Regression loss: 0.17889 | Running loss: 0.34693\n",
            "Epoch: 10 | Iteration: 261 | Classification loss: 0.13242 | Regression loss: 0.32257 | Running loss: 0.34710\n",
            "Epoch: 10 | Iteration: 262 | Classification loss: 0.04827 | Regression loss: 0.20437 | Running loss: 0.34700\n",
            "Epoch: 10 | Iteration: 263 | Classification loss: 0.10957 | Regression loss: 0.18376 | Running loss: 0.34682\n",
            "Epoch: 10 | Iteration: 264 | Classification loss: 0.14344 | Regression loss: 0.27546 | Running loss: 0.34711\n",
            "Epoch: 10 | Iteration: 265 | Classification loss: 0.19112 | Regression loss: 0.31675 | Running loss: 0.34753\n",
            "Epoch: 10 | Iteration: 266 | Classification loss: 0.16935 | Regression loss: 0.29149 | Running loss: 0.34753\n",
            "Epoch: 10 | Iteration: 267 | Classification loss: 0.26004 | Regression loss: 0.38920 | Running loss: 0.34794\n",
            "Epoch: 10 | Iteration: 268 | Classification loss: 0.07019 | Regression loss: 0.17692 | Running loss: 0.34793\n",
            "Epoch: 10 | Iteration: 269 | Classification loss: 0.03783 | Regression loss: 0.13566 | Running loss: 0.34798\n",
            "Epoch: 10 | Iteration: 270 | Classification loss: 0.05617 | Regression loss: 0.10700 | Running loss: 0.34755\n",
            "Epoch: 10 | Iteration: 271 | Classification loss: 0.10374 | Regression loss: 0.18978 | Running loss: 0.34724\n",
            "Epoch: 10 | Iteration: 272 | Classification loss: 0.11108 | Regression loss: 0.18346 | Running loss: 0.34703\n",
            "Epoch: 10 | Iteration: 273 | Classification loss: 0.10536 | Regression loss: 0.19243 | Running loss: 0.34653\n",
            "Epoch: 10 | Iteration: 274 | Classification loss: 0.28687 | Regression loss: 0.22168 | Running loss: 0.34646\n",
            "Epoch: 10 | Iteration: 275 | Classification loss: 0.10671 | Regression loss: 0.22534 | Running loss: 0.34625\n",
            "Epoch: 10 | Iteration: 276 | Classification loss: 0.16214 | Regression loss: 0.33627 | Running loss: 0.34684\n",
            "Epoch: 10 | Iteration: 277 | Classification loss: 0.20058 | Regression loss: 0.31389 | Running loss: 0.34732\n",
            "Epoch: 10 | Iteration: 278 | Classification loss: 0.02859 | Regression loss: 0.10900 | Running loss: 0.34705\n",
            "Epoch: 10 | Iteration: 279 | Classification loss: 0.09719 | Regression loss: 0.18526 | Running loss: 0.34658\n",
            "Epoch: 10 | Iteration: 280 | Classification loss: 0.05743 | Regression loss: 0.23479 | Running loss: 0.34648\n",
            "Epoch: 10 | Iteration: 281 | Classification loss: 0.04983 | Regression loss: 0.17781 | Running loss: 0.34648\n",
            "Epoch: 10 | Iteration: 282 | Classification loss: 0.07910 | Regression loss: 0.25497 | Running loss: 0.34660\n",
            "Epoch: 10 | Iteration: 283 | Classification loss: 0.03437 | Regression loss: 0.12733 | Running loss: 0.34613\n",
            "Epoch: 10 | Iteration: 284 | Classification loss: 0.16799 | Regression loss: 0.28792 | Running loss: 0.34603\n",
            "Epoch: 10 | Iteration: 285 | Classification loss: 0.05372 | Regression loss: 0.14153 | Running loss: 0.34554\n",
            "Epoch: 10 | Iteration: 286 | Classification loss: 0.09702 | Regression loss: 0.14134 | Running loss: 0.34481\n",
            "Epoch: 10 | Iteration: 287 | Classification loss: 0.11913 | Regression loss: 0.28278 | Running loss: 0.34416\n",
            "Epoch: 10 | Iteration: 288 | Classification loss: 0.23240 | Regression loss: 0.17579 | Running loss: 0.34392\n",
            "Epoch: 10 | Iteration: 289 | Classification loss: 0.09021 | Regression loss: 0.19007 | Running loss: 0.34380\n",
            "Epoch: 10 | Iteration: 290 | Classification loss: 0.14781 | Regression loss: 0.18652 | Running loss: 0.34356\n",
            "Epoch: 10 | Iteration: 291 | Classification loss: 0.10084 | Regression loss: 0.13753 | Running loss: 0.34302\n",
            "Epoch: 10 | Iteration: 292 | Classification loss: 0.06003 | Regression loss: 0.14556 | Running loss: 0.34203\n",
            "Epoch: 10 | Iteration: 293 | Classification loss: 0.14665 | Regression loss: 0.31592 | Running loss: 0.34203\n",
            "Epoch: 10 | Iteration: 294 | Classification loss: 0.10610 | Regression loss: 0.23212 | Running loss: 0.34163\n",
            "Epoch: 10 | Iteration: 295 | Classification loss: 0.16042 | Regression loss: 0.33625 | Running loss: 0.34173\n",
            "Epoch: 10 | Iteration: 296 | Classification loss: 0.10751 | Regression loss: 0.28218 | Running loss: 0.34168\n",
            "Epoch: 10 | Iteration: 297 | Classification loss: 0.10405 | Regression loss: 0.18333 | Running loss: 0.34152\n",
            "Epoch: 10 | Iteration: 298 | Classification loss: 0.11476 | Regression loss: 0.13408 | Running loss: 0.34152\n",
            "Epoch: 10 | Iteration: 299 | Classification loss: 0.16363 | Regression loss: 0.44247 | Running loss: 0.34218\n",
            "Epoch: 10 | Iteration: 300 | Classification loss: 0.06855 | Regression loss: 0.21311 | Running loss: 0.34240\n",
            "Epoch: 10 | Iteration: 301 | Classification loss: 0.16104 | Regression loss: 0.34786 | Running loss: 0.34262\n",
            "Epoch: 10 | Iteration: 302 | Classification loss: 0.14668 | Regression loss: 0.27479 | Running loss: 0.34237\n",
            "Epoch: 10 | Iteration: 303 | Classification loss: 0.14443 | Regression loss: 0.40428 | Running loss: 0.34307\n",
            "Epoch: 10 | Iteration: 304 | Classification loss: 0.03199 | Regression loss: 0.11724 | Running loss: 0.34261\n",
            "Epoch: 10 | Iteration: 305 | Classification loss: 0.27572 | Regression loss: 0.48001 | Running loss: 0.34330\n",
            "Epoch: 10 | Iteration: 306 | Classification loss: 0.14558 | Regression loss: 0.24176 | Running loss: 0.34330\n",
            "Epoch: 10 | Iteration: 307 | Classification loss: 0.06026 | Regression loss: 0.16695 | Running loss: 0.34304\n",
            "Epoch: 10 | Iteration: 308 | Classification loss: 0.04852 | Regression loss: 0.20699 | Running loss: 0.34274\n",
            "Epoch: 10 | Iteration: 309 | Classification loss: 0.15613 | Regression loss: 0.31534 | Running loss: 0.34286\n",
            "Epoch: 10 | Iteration: 310 | Classification loss: 0.14861 | Regression loss: 0.28576 | Running loss: 0.34311\n",
            "Epoch: 10 | Iteration: 311 | Classification loss: 0.04551 | Regression loss: 0.16519 | Running loss: 0.34249\n",
            "Epoch: 10 | Iteration: 312 | Classification loss: 0.10717 | Regression loss: 0.18923 | Running loss: 0.34212\n",
            "Epoch: 10 | Iteration: 313 | Classification loss: 0.05535 | Regression loss: 0.20077 | Running loss: 0.34234\n",
            "Epoch: 10 | Iteration: 314 | Classification loss: 0.04985 | Regression loss: 0.11918 | Running loss: 0.34231\n",
            "Epoch: 10 | Iteration: 315 | Classification loss: 0.19379 | Regression loss: 0.37238 | Running loss: 0.34298\n",
            "Epoch: 10 | Iteration: 316 | Classification loss: 0.22748 | Regression loss: 0.23581 | Running loss: 0.34320\n",
            "Epoch: 10 | Iteration: 317 | Classification loss: 0.06778 | Regression loss: 0.21407 | Running loss: 0.34341\n",
            "Epoch: 10 | Iteration: 318 | Classification loss: 0.13711 | Regression loss: 0.14666 | Running loss: 0.34301\n",
            "Epoch: 10 | Iteration: 319 | Classification loss: 0.13374 | Regression loss: 0.11422 | Running loss: 0.34270\n",
            "Epoch: 10 | Iteration: 320 | Classification loss: 0.23527 | Regression loss: 0.24720 | Running loss: 0.34313\n",
            "Epoch: 10 | Iteration: 321 | Classification loss: 0.08806 | Regression loss: 0.24104 | Running loss: 0.34322\n",
            "Epoch: 10 | Iteration: 322 | Classification loss: 0.08192 | Regression loss: 0.16104 | Running loss: 0.34259\n",
            "Epoch: 10 | Iteration: 323 | Classification loss: 0.08454 | Regression loss: 0.26064 | Running loss: 0.34261\n",
            "Epoch: 10 | Iteration: 324 | Classification loss: 0.10290 | Regression loss: 0.18808 | Running loss: 0.34219\n",
            "Epoch: 10 | Iteration: 325 | Classification loss: 0.15357 | Regression loss: 0.25923 | Running loss: 0.34233\n",
            "Epoch: 10 | Iteration: 326 | Classification loss: 0.03297 | Regression loss: 0.17653 | Running loss: 0.34190\n",
            "Epoch: 10 | Iteration: 327 | Classification loss: 0.08384 | Regression loss: 0.11898 | Running loss: 0.34194\n",
            "Epoch: 10 | Iteration: 328 | Classification loss: 0.18022 | Regression loss: 0.35853 | Running loss: 0.34214\n",
            "Epoch: 10 | Iteration: 329 | Classification loss: 0.13667 | Regression loss: 0.23715 | Running loss: 0.34206\n",
            "Epoch: 10 | Iteration: 330 | Classification loss: 0.09814 | Regression loss: 0.23734 | Running loss: 0.34227\n",
            "Epoch: 10 | Iteration: 331 | Classification loss: 0.14618 | Regression loss: 0.23474 | Running loss: 0.34247\n",
            "Epoch: 10 | Iteration: 332 | Classification loss: 0.08894 | Regression loss: 0.21228 | Running loss: 0.34162\n",
            "Epoch: 10 | Iteration: 333 | Classification loss: 0.05023 | Regression loss: 0.19785 | Running loss: 0.34157\n",
            "Epoch: 10 | Iteration: 334 | Classification loss: 0.19013 | Regression loss: 0.31678 | Running loss: 0.34182\n",
            "Epoch: 10 | Iteration: 335 | Classification loss: 0.09681 | Regression loss: 0.15965 | Running loss: 0.34118\n",
            "Epoch: 10 | Iteration: 336 | Classification loss: 0.04746 | Regression loss: 0.16245 | Running loss: 0.34098\n",
            "Epoch: 10 | Iteration: 337 | Classification loss: 0.11290 | Regression loss: 0.25514 | Running loss: 0.34109\n",
            "Epoch: 10 | Iteration: 338 | Classification loss: 0.08276 | Regression loss: 0.21829 | Running loss: 0.34108\n",
            "Epoch: 10 | Iteration: 339 | Classification loss: 0.05613 | Regression loss: 0.16936 | Running loss: 0.34089\n",
            "Epoch: 10 | Iteration: 340 | Classification loss: 0.06477 | Regression loss: 0.21385 | Running loss: 0.34069\n",
            "Epoch: 10 | Iteration: 341 | Classification loss: 0.08363 | Regression loss: 0.15825 | Running loss: 0.34015\n",
            "Epoch: 10 | Iteration: 342 | Classification loss: 0.09357 | Regression loss: 0.12065 | Running loss: 0.33978\n",
            "Epoch: 10 | Iteration: 343 | Classification loss: 0.07430 | Regression loss: 0.18003 | Running loss: 0.33968\n",
            "Epoch: 10 | Iteration: 344 | Classification loss: 0.07510 | Regression loss: 0.19922 | Running loss: 0.33923\n",
            "Epoch: 10 | Iteration: 345 | Classification loss: 0.13444 | Regression loss: 0.28827 | Running loss: 0.33926\n",
            "Epoch: 10 | Iteration: 346 | Classification loss: 0.15429 | Regression loss: 0.20663 | Running loss: 0.33918\n",
            "Epoch: 10 | Iteration: 347 | Classification loss: 0.17780 | Regression loss: 0.28535 | Running loss: 0.33921\n",
            "Epoch: 10 | Iteration: 348 | Classification loss: 0.05602 | Regression loss: 0.17873 | Running loss: 0.33924\n",
            "Epoch: 10 | Iteration: 349 | Classification loss: 0.04940 | Regression loss: 0.18353 | Running loss: 0.33916\n",
            "Epoch: 10 | Iteration: 350 | Classification loss: 0.11602 | Regression loss: 0.19972 | Running loss: 0.33852\n",
            "Epoch: 10 | Iteration: 351 | Classification loss: 0.08403 | Regression loss: 0.20034 | Running loss: 0.33810\n",
            "Epoch: 10 | Iteration: 352 | Classification loss: 0.07129 | Regression loss: 0.20015 | Running loss: 0.33795\n",
            "Epoch: 10 | Iteration: 353 | Classification loss: 0.02890 | Regression loss: 0.14452 | Running loss: 0.33769\n",
            "Epoch: 10 | Iteration: 354 | Classification loss: 0.08925 | Regression loss: 0.23114 | Running loss: 0.33777\n",
            "Epoch: 10 | Iteration: 355 | Classification loss: 0.25341 | Regression loss: 0.38116 | Running loss: 0.33842\n",
            "Epoch: 10 | Iteration: 356 | Classification loss: 0.15425 | Regression loss: 0.26511 | Running loss: 0.33853\n",
            "Epoch: 10 | Iteration: 357 | Classification loss: 0.10267 | Regression loss: 0.14435 | Running loss: 0.33827\n",
            "Epoch: 10 | Iteration: 358 | Classification loss: 0.19487 | Regression loss: 0.32195 | Running loss: 0.33859\n",
            "Epoch: 10 | Iteration: 359 | Classification loss: 0.06636 | Regression loss: 0.17330 | Running loss: 0.33854\n",
            "Epoch: 10 | Iteration: 360 | Classification loss: 0.12790 | Regression loss: 0.19287 | Running loss: 0.33820\n",
            "Epoch: 10 | Iteration: 361 | Classification loss: 0.13856 | Regression loss: 0.25097 | Running loss: 0.33840\n",
            "Epoch: 10 | Iteration: 362 | Classification loss: 0.09143 | Regression loss: 0.25352 | Running loss: 0.33782\n",
            "Epoch: 10 | Iteration: 363 | Classification loss: 0.06724 | Regression loss: 0.09120 | Running loss: 0.33764\n",
            "Epoch: 10 | Iteration: 364 | Classification loss: 0.09648 | Regression loss: 0.13174 | Running loss: 0.33734\n",
            "Epoch: 10 | Iteration: 365 | Classification loss: 0.08814 | Regression loss: 0.16976 | Running loss: 0.33668\n",
            "Epoch: 10 | Iteration: 366 | Classification loss: 0.08672 | Regression loss: 0.14456 | Running loss: 0.33657\n",
            "Epoch: 10 | Iteration: 367 | Classification loss: 0.18696 | Regression loss: 0.37282 | Running loss: 0.33674\n",
            "Epoch: 10 | Iteration: 368 | Classification loss: 0.09242 | Regression loss: 0.16078 | Running loss: 0.33688\n",
            "Epoch: 10 | Iteration: 369 | Classification loss: 0.11182 | Regression loss: 0.27014 | Running loss: 0.33697\n",
            "Epoch: 10 | Iteration: 370 | Classification loss: 0.14224 | Regression loss: 0.22223 | Running loss: 0.33723\n",
            "Epoch: 10 | Iteration: 371 | Classification loss: 0.16060 | Regression loss: 0.23390 | Running loss: 0.33760\n",
            "Epoch: 10 | Iteration: 372 | Classification loss: 0.11667 | Regression loss: 0.16888 | Running loss: 0.33774\n",
            "Epoch: 10 | Iteration: 373 | Classification loss: 0.11456 | Regression loss: 0.19085 | Running loss: 0.33781\n",
            "Epoch: 10 | Iteration: 374 | Classification loss: 0.06178 | Regression loss: 0.17301 | Running loss: 0.33747\n",
            "Epoch: 10 | Iteration: 375 | Classification loss: 0.08967 | Regression loss: 0.20587 | Running loss: 0.33752\n",
            "Epoch: 10 | Iteration: 376 | Classification loss: 0.11733 | Regression loss: 0.19887 | Running loss: 0.33699\n",
            "Epoch: 10 | Iteration: 377 | Classification loss: 0.06901 | Regression loss: 0.22448 | Running loss: 0.33648\n",
            "Epoch: 10 | Iteration: 378 | Classification loss: 0.17304 | Regression loss: 0.28985 | Running loss: 0.33680\n",
            "Epoch: 10 | Iteration: 379 | Classification loss: 0.09499 | Regression loss: 0.16875 | Running loss: 0.33685\n",
            "Epoch: 10 | Iteration: 380 | Classification loss: 0.13083 | Regression loss: 0.24894 | Running loss: 0.33692\n",
            "Epoch: 10 | Iteration: 381 | Classification loss: 0.03774 | Regression loss: 0.13689 | Running loss: 0.33643\n",
            "Epoch: 10 | Iteration: 382 | Classification loss: 0.04210 | Regression loss: 0.13382 | Running loss: 0.33641\n",
            "Epoch: 10 | Iteration: 383 | Classification loss: 0.10720 | Regression loss: 0.19617 | Running loss: 0.33632\n",
            "Epoch: 10 | Iteration: 384 | Classification loss: 0.06412 | Regression loss: 0.16892 | Running loss: 0.33606\n",
            "Epoch: 10 | Iteration: 385 | Classification loss: 0.11967 | Regression loss: 0.25294 | Running loss: 0.33636\n",
            "Epoch: 10 | Iteration: 386 | Classification loss: 0.14637 | Regression loss: 0.29917 | Running loss: 0.33657\n",
            "Epoch: 10 | Iteration: 387 | Classification loss: 0.14792 | Regression loss: 0.28153 | Running loss: 0.33682\n",
            "Epoch: 10 | Iteration: 388 | Classification loss: 0.10295 | Regression loss: 0.28135 | Running loss: 0.33688\n",
            "Epoch: 10 | Iteration: 389 | Classification loss: 0.10274 | Regression loss: 0.27451 | Running loss: 0.33696\n",
            "Epoch: 10 | Iteration: 390 | Classification loss: 0.04915 | Regression loss: 0.15315 | Running loss: 0.33650\n",
            "Epoch: 10 | Iteration: 391 | Classification loss: 0.17640 | Regression loss: 0.25150 | Running loss: 0.33673\n",
            "Epoch: 10 | Iteration: 392 | Classification loss: 0.06019 | Regression loss: 0.19198 | Running loss: 0.33612\n",
            "Epoch: 10 | Iteration: 393 | Classification loss: 0.15132 | Regression loss: 0.33755 | Running loss: 0.33617\n",
            "Epoch: 10 | Iteration: 394 | Classification loss: 0.25675 | Regression loss: 0.37033 | Running loss: 0.33633\n",
            "Epoch: 10 | Iteration: 395 | Classification loss: 0.06736 | Regression loss: 0.13498 | Running loss: 0.33619\n",
            "Epoch: 10 | Iteration: 396 | Classification loss: 0.05760 | Regression loss: 0.15467 | Running loss: 0.33589\n",
            "Epoch: 10 | Iteration: 397 | Classification loss: 0.04578 | Regression loss: 0.14674 | Running loss: 0.33539\n",
            "Epoch: 10 | Iteration: 398 | Classification loss: 0.11049 | Regression loss: 0.24687 | Running loss: 0.33546\n",
            "Epoch: 10 | Iteration: 399 | Classification loss: 0.12120 | Regression loss: 0.34001 | Running loss: 0.33531\n",
            "Epoch: 10 | Iteration: 400 | Classification loss: 0.10560 | Regression loss: 0.24249 | Running loss: 0.33503\n",
            "Epoch: 10 | Iteration: 401 | Classification loss: 0.02612 | Regression loss: 0.09344 | Running loss: 0.33483\n",
            "Epoch: 10 | Iteration: 402 | Classification loss: 0.06690 | Regression loss: 0.26685 | Running loss: 0.33502\n",
            "Epoch: 10 | Iteration: 403 | Classification loss: 0.08345 | Regression loss: 0.18272 | Running loss: 0.33496\n",
            "Epoch: 10 | Iteration: 404 | Classification loss: 0.02720 | Regression loss: 0.11915 | Running loss: 0.33444\n",
            "Epoch: 10 | Iteration: 405 | Classification loss: 0.07888 | Regression loss: 0.17537 | Running loss: 0.33429\n",
            "Epoch: 10 | Iteration: 406 | Classification loss: 0.05776 | Regression loss: 0.10965 | Running loss: 0.33375\n",
            "Epoch: 10 | Iteration: 407 | Classification loss: 0.08169 | Regression loss: 0.14707 | Running loss: 0.33370\n",
            "Epoch: 10 | Iteration: 408 | Classification loss: 0.05409 | Regression loss: 0.10620 | Running loss: 0.33332\n",
            "Epoch: 10 | Iteration: 409 | Classification loss: 0.04760 | Regression loss: 0.13148 | Running loss: 0.33318\n",
            "Epoch: 10 | Iteration: 410 | Classification loss: 0.06942 | Regression loss: 0.22700 | Running loss: 0.33333\n",
            "Epoch: 10 | Iteration: 411 | Classification loss: 0.06095 | Regression loss: 0.15964 | Running loss: 0.33328\n",
            "Epoch: 10 | Iteration: 412 | Classification loss: 0.02737 | Regression loss: 0.19223 | Running loss: 0.33344\n",
            "Epoch: 10 | Iteration: 413 | Classification loss: 0.08114 | Regression loss: 0.18554 | Running loss: 0.33338\n",
            "Epoch: 10 | Iteration: 414 | Classification loss: 0.12657 | Regression loss: 0.20724 | Running loss: 0.33356\n",
            "Epoch: 10 | Iteration: 415 | Classification loss: 0.13461 | Regression loss: 0.27501 | Running loss: 0.33324\n",
            "Epoch: 10 | Iteration: 416 | Classification loss: 0.09320 | Regression loss: 0.24324 | Running loss: 0.33291\n",
            "Epoch: 10 | Iteration: 417 | Classification loss: 0.06978 | Regression loss: 0.17858 | Running loss: 0.33275\n",
            "Epoch: 10 | Iteration: 418 | Classification loss: 0.27621 | Regression loss: 0.31214 | Running loss: 0.33302\n",
            "Epoch: 10 | Iteration: 419 | Classification loss: 0.04845 | Regression loss: 0.11960 | Running loss: 0.33245\n",
            "Epoch: 10 | Iteration: 420 | Classification loss: 0.08351 | Regression loss: 0.23622 | Running loss: 0.33237\n",
            "Epoch: 10 | Iteration: 421 | Classification loss: 0.20524 | Regression loss: 0.41674 | Running loss: 0.33303\n",
            "Epoch: 10 | Iteration: 422 | Classification loss: 0.10302 | Regression loss: 0.20733 | Running loss: 0.33317\n",
            "Epoch: 10 | Iteration: 423 | Classification loss: 0.12832 | Regression loss: 0.25534 | Running loss: 0.33343\n",
            "Epoch: 10 | Iteration: 424 | Classification loss: 0.15355 | Regression loss: 0.20992 | Running loss: 0.33389\n",
            "Epoch: 10 | Iteration: 425 | Classification loss: 0.13301 | Regression loss: 0.29000 | Running loss: 0.33420\n",
            "Epoch: 10 | Iteration: 426 | Classification loss: 0.07307 | Regression loss: 0.13360 | Running loss: 0.33388\n",
            "Epoch: 10 | Iteration: 427 | Classification loss: 0.08957 | Regression loss: 0.17049 | Running loss: 0.33408\n",
            "Epoch: 10 | Iteration: 428 | Classification loss: 0.07299 | Regression loss: 0.23177 | Running loss: 0.33408\n",
            "Epoch: 10 | Iteration: 429 | Classification loss: 0.05127 | Regression loss: 0.18694 | Running loss: 0.33401\n",
            "Epoch: 10 | Iteration: 430 | Classification loss: 0.12702 | Regression loss: 0.23014 | Running loss: 0.33388\n",
            "Epoch: 10 | Iteration: 431 | Classification loss: 0.10839 | Regression loss: 0.21983 | Running loss: 0.33402\n",
            "Epoch: 10 | Iteration: 432 | Classification loss: 0.03734 | Regression loss: 0.15572 | Running loss: 0.33376\n",
            "Epoch: 10 | Iteration: 433 | Classification loss: 0.03546 | Regression loss: 0.09012 | Running loss: 0.33346\n",
            "Epoch: 10 | Iteration: 434 | Classification loss: 0.11302 | Regression loss: 0.25489 | Running loss: 0.33342\n",
            "Epoch: 10 | Iteration: 435 | Classification loss: 0.03789 | Regression loss: 0.12663 | Running loss: 0.33242\n",
            "Epoch: 10 | Iteration: 436 | Classification loss: 0.11884 | Regression loss: 0.28431 | Running loss: 0.33245\n",
            "Epoch: 10 | Iteration: 437 | Classification loss: 0.05493 | Regression loss: 0.16802 | Running loss: 0.33126\n",
            "Epoch: 10 | Iteration: 438 | Classification loss: 0.07595 | Regression loss: 0.13655 | Running loss: 0.33126\n",
            "Epoch: 10 | Iteration: 439 | Classification loss: 0.12561 | Regression loss: 0.27638 | Running loss: 0.33136\n",
            "Epoch: 10 | Iteration: 440 | Classification loss: 0.02954 | Regression loss: 0.06759 | Running loss: 0.33079\n",
            "Epoch: 10 | Iteration: 441 | Classification loss: 0.07051 | Regression loss: 0.25395 | Running loss: 0.33078\n",
            "Epoch: 10 | Iteration: 442 | Classification loss: 0.19834 | Regression loss: 0.38947 | Running loss: 0.33142\n",
            "Epoch: 10 | Iteration: 443 | Classification loss: 0.11590 | Regression loss: 0.22841 | Running loss: 0.33095\n",
            "Epoch: 10 | Iteration: 444 | Classification loss: 0.05697 | Regression loss: 0.14973 | Running loss: 0.33080\n",
            "Epoch: 10 | Iteration: 445 | Classification loss: 0.06248 | Regression loss: 0.16788 | Running loss: 0.33038\n",
            "Epoch: 10 | Iteration: 446 | Classification loss: 0.17625 | Regression loss: 0.31152 | Running loss: 0.33048\n",
            "Epoch: 10 | Iteration: 447 | Classification loss: 0.07991 | Regression loss: 0.24086 | Running loss: 0.33015\n",
            "Epoch: 10 | Iteration: 448 | Classification loss: 0.08518 | Regression loss: 0.21333 | Running loss: 0.33015\n",
            "Epoch: 10 | Iteration: 449 | Classification loss: 0.14969 | Regression loss: 0.23407 | Running loss: 0.33056\n",
            "Epoch: 10 | Iteration: 450 | Classification loss: 0.13125 | Regression loss: 0.18015 | Running loss: 0.33043\n",
            "Epoch: 10 | Iteration: 451 | Classification loss: 0.13696 | Regression loss: 0.26567 | Running loss: 0.33042\n",
            "Epoch: 10 | Iteration: 452 | Classification loss: 0.11898 | Regression loss: 0.26656 | Running loss: 0.33036\n",
            "Epoch: 10 | Iteration: 453 | Classification loss: 0.08084 | Regression loss: 0.12538 | Running loss: 0.33024\n",
            "Epoch: 10 | Iteration: 454 | Classification loss: 0.09811 | Regression loss: 0.19832 | Running loss: 0.33013\n",
            "Epoch: 10 | Iteration: 455 | Classification loss: 0.07722 | Regression loss: 0.16229 | Running loss: 0.33031\n",
            "Epoch: 10 | Iteration: 456 | Classification loss: 0.07492 | Regression loss: 0.13395 | Running loss: 0.33001\n",
            "Epoch: 10 | Iteration: 457 | Classification loss: 0.07291 | Regression loss: 0.16367 | Running loss: 0.32950\n",
            "Epoch: 10 | Iteration: 458 | Classification loss: 0.09576 | Regression loss: 0.18691 | Running loss: 0.32941\n",
            "Epoch: 10 | Iteration: 459 | Classification loss: 0.10274 | Regression loss: 0.31558 | Running loss: 0.32954\n",
            "Epoch: 10 | Iteration: 460 | Classification loss: 0.10112 | Regression loss: 0.18159 | Running loss: 0.32905\n",
            "Epoch: 10 | Iteration: 461 | Classification loss: 0.06231 | Regression loss: 0.18308 | Running loss: 0.32888\n",
            "Epoch: 10 | Iteration: 462 | Classification loss: 0.07086 | Regression loss: 0.21945 | Running loss: 0.32904\n",
            "Epoch: 10 | Iteration: 463 | Classification loss: 0.17213 | Regression loss: 0.34899 | Running loss: 0.32917\n",
            "Epoch: 10 | Iteration: 464 | Classification loss: 0.06343 | Regression loss: 0.23242 | Running loss: 0.32921\n",
            "Epoch: 10 | Iteration: 465 | Classification loss: 0.10053 | Regression loss: 0.20448 | Running loss: 0.32920\n",
            "Epoch: 10 | Iteration: 466 | Classification loss: 0.15709 | Regression loss: 0.27131 | Running loss: 0.32966\n",
            "Epoch: 10 | Iteration: 467 | Classification loss: 0.16165 | Regression loss: 0.33518 | Running loss: 0.32987\n",
            "Epoch: 10 | Iteration: 468 | Classification loss: 0.07801 | Regression loss: 0.21721 | Running loss: 0.32965\n",
            "Epoch: 10 | Iteration: 469 | Classification loss: 0.15006 | Regression loss: 0.23444 | Running loss: 0.32914\n",
            "Epoch: 10 | Iteration: 470 | Classification loss: 0.10950 | Regression loss: 0.28429 | Running loss: 0.32921\n",
            "Epoch: 10 | Iteration: 471 | Classification loss: 0.26049 | Regression loss: 0.33350 | Running loss: 0.32977\n",
            "Epoch: 10 | Iteration: 472 | Classification loss: 0.09634 | Regression loss: 0.22577 | Running loss: 0.32965\n",
            "Epoch: 10 | Iteration: 473 | Classification loss: 0.27285 | Regression loss: 0.39543 | Running loss: 0.33054\n",
            "Epoch: 10 | Iteration: 474 | Classification loss: 0.10537 | Regression loss: 0.26376 | Running loss: 0.33085\n",
            "Epoch: 10 | Iteration: 475 | Classification loss: 0.16402 | Regression loss: 0.36983 | Running loss: 0.33156\n",
            "Epoch: 10 | Iteration: 476 | Classification loss: 0.11550 | Regression loss: 0.19923 | Running loss: 0.33187\n",
            "Epoch: 10 | Iteration: 477 | Classification loss: 0.07503 | Regression loss: 0.22882 | Running loss: 0.33138\n",
            "Epoch: 10 | Iteration: 478 | Classification loss: 0.22388 | Regression loss: 0.42329 | Running loss: 0.33175\n",
            "Epoch: 10 | Iteration: 479 | Classification loss: 0.05228 | Regression loss: 0.20610 | Running loss: 0.33170\n",
            "Epoch: 10 | Iteration: 480 | Classification loss: 0.07048 | Regression loss: 0.14291 | Running loss: 0.33067\n",
            "Epoch: 10 | Iteration: 481 | Classification loss: 0.08789 | Regression loss: 0.23437 | Running loss: 0.33071\n",
            "Epoch: 10 | Iteration: 482 | Classification loss: 0.12294 | Regression loss: 0.31482 | Running loss: 0.33116\n",
            "Epoch: 10 | Iteration: 483 | Classification loss: 0.10021 | Regression loss: 0.28308 | Running loss: 0.33146\n",
            "Epoch: 10 | Iteration: 484 | Classification loss: 0.16231 | Regression loss: 0.23698 | Running loss: 0.33147\n",
            "Epoch: 10 | Iteration: 485 | Classification loss: 0.16226 | Regression loss: 0.27976 | Running loss: 0.33140\n",
            "Epoch: 10 | Iteration: 486 | Classification loss: 0.14153 | Regression loss: 0.29134 | Running loss: 0.33181\n",
            "Epoch: 10 | Iteration: 487 | Classification loss: 0.09339 | Regression loss: 0.24129 | Running loss: 0.33160\n",
            "Epoch: 10 | Iteration: 488 | Classification loss: 0.03053 | Regression loss: 0.16542 | Running loss: 0.33119\n",
            "Epoch: 10 | Iteration: 489 | Classification loss: 0.14495 | Regression loss: 0.16335 | Running loss: 0.33136\n",
            "Epoch: 10 | Iteration: 490 | Classification loss: 0.14529 | Regression loss: 0.31889 | Running loss: 0.33180\n",
            "Epoch: 10 | Iteration: 491 | Classification loss: 0.12677 | Regression loss: 0.24309 | Running loss: 0.33163\n",
            "Epoch: 10 | Iteration: 492 | Classification loss: 0.04334 | Regression loss: 0.12813 | Running loss: 0.33113\n",
            "Epoch: 10 | Iteration: 493 | Classification loss: 0.04700 | Regression loss: 0.15400 | Running loss: 0.33029\n",
            "Epoch: 10 | Iteration: 494 | Classification loss: 0.12101 | Regression loss: 0.24855 | Running loss: 0.33024\n",
            "Epoch: 10 | Iteration: 495 | Classification loss: 0.06050 | Regression loss: 0.15451 | Running loss: 0.33004\n",
            "Epoch: 10 | Iteration: 496 | Classification loss: 0.03975 | Regression loss: 0.16262 | Running loss: 0.32976\n",
            "Epoch: 10 | Iteration: 497 | Classification loss: 0.07702 | Regression loss: 0.23849 | Running loss: 0.32946\n",
            "Epoch: 10 | Iteration: 498 | Classification loss: 0.05822 | Regression loss: 0.18870 | Running loss: 0.32923\n",
            "Epoch: 10 | Iteration: 499 | Classification loss: 0.06887 | Regression loss: 0.15551 | Running loss: 0.32872\n",
            "Epoch: 10 | Iteration: 500 | Classification loss: 0.05257 | Regression loss: 0.21856 | Running loss: 0.32844\n",
            "Epoch: 10 | Iteration: 501 | Classification loss: 0.15914 | Regression loss: 0.22969 | Running loss: 0.32871\n",
            "Epoch: 10 | Iteration: 502 | Classification loss: 0.18201 | Regression loss: 0.22606 | Running loss: 0.32881\n",
            "Epoch: 10 | Iteration: 503 | Classification loss: 0.06293 | Regression loss: 0.16851 | Running loss: 0.32898\n",
            "Epoch: 10 | Iteration: 504 | Classification loss: 0.06711 | Regression loss: 0.19868 | Running loss: 0.32862\n",
            "Epoch: 10 | Iteration: 505 | Classification loss: 0.17893 | Regression loss: 0.18808 | Running loss: 0.32854\n",
            "Epoch: 10 | Iteration: 506 | Classification loss: 0.09263 | Regression loss: 0.22707 | Running loss: 0.32888\n",
            "Epoch: 10 | Iteration: 507 | Classification loss: 0.06009 | Regression loss: 0.14790 | Running loss: 0.32893\n",
            "Epoch: 10 | Iteration: 508 | Classification loss: 0.06163 | Regression loss: 0.19895 | Running loss: 0.32870\n",
            "Epoch: 10 | Iteration: 509 | Classification loss: 0.06831 | Regression loss: 0.21021 | Running loss: 0.32892\n",
            "Epoch: 10 | Iteration: 510 | Classification loss: 0.09086 | Regression loss: 0.15090 | Running loss: 0.32827\n",
            "Epoch: 10 | Iteration: 511 | Classification loss: 0.03412 | Regression loss: 0.17771 | Running loss: 0.32781\n",
            "Epoch: 10 | Iteration: 512 | Classification loss: 0.09301 | Regression loss: 0.26719 | Running loss: 0.32800\n",
            "Epoch: 10 | Iteration: 513 | Classification loss: 0.31847 | Regression loss: 0.31264 | Running loss: 0.32814\n",
            "Epoch: 10 | Iteration: 514 | Classification loss: 0.14816 | Regression loss: 0.28998 | Running loss: 0.32860\n",
            "Epoch: 10 | Iteration: 515 | Classification loss: 0.10712 | Regression loss: 0.28534 | Running loss: 0.32879\n",
            "Epoch: 10 | Iteration: 516 | Classification loss: 0.16629 | Regression loss: 0.27422 | Running loss: 0.32908\n",
            "Epoch: 10 | Iteration: 517 | Classification loss: 0.22520 | Regression loss: 0.19736 | Running loss: 0.32929\n",
            "Epoch: 10 | Iteration: 518 | Classification loss: 0.12044 | Regression loss: 0.19062 | Running loss: 0.32940\n",
            "Epoch: 10 | Iteration: 519 | Classification loss: 0.09980 | Regression loss: 0.23110 | Running loss: 0.32949\n",
            "Epoch: 10 | Iteration: 520 | Classification loss: 0.07347 | Regression loss: 0.22486 | Running loss: 0.32961\n",
            "Epoch: 10 | Iteration: 521 | Classification loss: 0.05138 | Regression loss: 0.20742 | Running loss: 0.32982\n",
            "Epoch: 10 | Iteration: 522 | Classification loss: 0.19638 | Regression loss: 0.36399 | Running loss: 0.33023\n",
            "Epoch: 10 | Iteration: 523 | Classification loss: 0.19682 | Regression loss: 0.21025 | Running loss: 0.33004\n",
            "Epoch: 10 | Iteration: 524 | Classification loss: 0.11090 | Regression loss: 0.21240 | Running loss: 0.32987\n",
            "Epoch: 10 | Iteration: 525 | Classification loss: 0.08440 | Regression loss: 0.17595 | Running loss: 0.33000\n",
            "Epoch: 10 | Iteration: 526 | Classification loss: 0.14271 | Regression loss: 0.21632 | Running loss: 0.33027\n",
            "Epoch: 10 | Iteration: 527 | Classification loss: 0.14742 | Regression loss: 0.24374 | Running loss: 0.33039\n",
            "Epoch: 10 | Iteration: 528 | Classification loss: 0.17680 | Regression loss: 0.22175 | Running loss: 0.33079\n",
            "Epoch: 10 | Iteration: 529 | Classification loss: 0.08230 | Regression loss: 0.15353 | Running loss: 0.33074\n",
            "Epoch: 10 | Iteration: 530 | Classification loss: 0.05629 | Regression loss: 0.16396 | Running loss: 0.33063\n",
            "Epoch: 10 | Iteration: 531 | Classification loss: 0.13845 | Regression loss: 0.30282 | Running loss: 0.33082\n",
            "Epoch: 10 | Iteration: 532 | Classification loss: 0.19266 | Regression loss: 0.32333 | Running loss: 0.33112\n",
            "Epoch: 10 | Iteration: 533 | Classification loss: 0.23719 | Regression loss: 0.27051 | Running loss: 0.33135\n",
            "Epoch: 10 | Iteration: 534 | Classification loss: 0.08294 | Regression loss: 0.11949 | Running loss: 0.33123\n",
            "Epoch: 10 | Iteration: 535 | Classification loss: 0.22917 | Regression loss: 0.39672 | Running loss: 0.33137\n",
            "Epoch: 10 | Iteration: 536 | Classification loss: 0.14655 | Regression loss: 0.14237 | Running loss: 0.33152\n",
            "Epoch: 10 | Iteration: 537 | Classification loss: 0.16570 | Regression loss: 0.21784 | Running loss: 0.33187\n",
            "Epoch: 10 | Iteration: 538 | Classification loss: 0.18887 | Regression loss: 0.42469 | Running loss: 0.33233\n",
            "Epoch: 10 | Iteration: 539 | Classification loss: 0.04226 | Regression loss: 0.15946 | Running loss: 0.33223\n",
            "Epoch: 10 | Iteration: 540 | Classification loss: 0.12080 | Regression loss: 0.24006 | Running loss: 0.33221\n",
            "Epoch: 10 | Iteration: 541 | Classification loss: 0.12348 | Regression loss: 0.17987 | Running loss: 0.33227\n",
            "Epoch: 10 | Iteration: 542 | Classification loss: 0.11504 | Regression loss: 0.31761 | Running loss: 0.33255\n",
            "Epoch: 10 | Iteration: 543 | Classification loss: 0.04691 | Regression loss: 0.10831 | Running loss: 0.33199\n",
            "Epoch: 10 | Iteration: 544 | Classification loss: 0.20894 | Regression loss: 0.38279 | Running loss: 0.33266\n",
            "Epoch: 10 | Iteration: 545 | Classification loss: 0.16135 | Regression loss: 0.26062 | Running loss: 0.33189\n",
            "Epoch: 10 | Iteration: 546 | Classification loss: 0.07666 | Regression loss: 0.25051 | Running loss: 0.33185\n",
            "Epoch: 10 | Iteration: 547 | Classification loss: 0.08677 | Regression loss: 0.16668 | Running loss: 0.33188\n",
            "Epoch: 10 | Iteration: 548 | Classification loss: 0.04001 | Regression loss: 0.18128 | Running loss: 0.33147\n",
            "Epoch: 10 | Iteration: 549 | Classification loss: 0.14471 | Regression loss: 0.13219 | Running loss: 0.33142\n",
            "Epoch: 10 | Iteration: 550 | Classification loss: 0.15762 | Regression loss: 0.23540 | Running loss: 0.33104\n",
            "Epoch: 10 | Iteration: 551 | Classification loss: 0.10325 | Regression loss: 0.17035 | Running loss: 0.33114\n",
            "Epoch: 10 | Iteration: 552 | Classification loss: 0.10789 | Regression loss: 0.28615 | Running loss: 0.33107\n",
            "Epoch: 10 | Iteration: 553 | Classification loss: 0.03180 | Regression loss: 0.14377 | Running loss: 0.33090\n",
            "Epoch: 10 | Iteration: 554 | Classification loss: 0.14743 | Regression loss: 0.26875 | Running loss: 0.33084\n",
            "Epoch: 10 | Iteration: 555 | Classification loss: 0.10973 | Regression loss: 0.30840 | Running loss: 0.33076\n",
            "Epoch: 10 | Iteration: 556 | Classification loss: 0.09592 | Regression loss: 0.24588 | Running loss: 0.33093\n",
            "Epoch: 10 | Iteration: 557 | Classification loss: 0.03835 | Regression loss: 0.14188 | Running loss: 0.33079\n",
            "Epoch: 10 | Iteration: 558 | Classification loss: 0.06672 | Regression loss: 0.18825 | Running loss: 0.33066\n",
            "Epoch: 10 | Iteration: 559 | Classification loss: 0.18804 | Regression loss: 0.37302 | Running loss: 0.33058\n",
            "Epoch: 10 | Iteration: 560 | Classification loss: 0.17387 | Regression loss: 0.25502 | Running loss: 0.33076\n",
            "Epoch: 10 | Iteration: 561 | Classification loss: 0.13527 | Regression loss: 0.22728 | Running loss: 0.33105\n",
            "Epoch: 10 | Iteration: 562 | Classification loss: 0.07086 | Regression loss: 0.15062 | Running loss: 0.33060\n",
            "Epoch: 10 | Iteration: 563 | Classification loss: 0.09123 | Regression loss: 0.16908 | Running loss: 0.33034\n",
            "Epoch: 10 | Iteration: 564 | Classification loss: 0.07453 | Regression loss: 0.17893 | Running loss: 0.33061\n",
            "Epoch: 10 | Iteration: 565 | Classification loss: 0.03756 | Regression loss: 0.13100 | Running loss: 0.33023\n",
            "Epoch: 10 | Iteration: 566 | Classification loss: 0.22054 | Regression loss: 0.37956 | Running loss: 0.33055\n",
            "Epoch: 10 | Iteration: 567 | Classification loss: 0.14805 | Regression loss: 0.24379 | Running loss: 0.33079\n",
            "Epoch: 10 | Iteration: 568 | Classification loss: 0.16662 | Regression loss: 0.23342 | Running loss: 0.33091\n",
            "Epoch: 10 | Iteration: 569 | Classification loss: 0.23668 | Regression loss: 0.31768 | Running loss: 0.33130\n",
            "Epoch: 10 | Iteration: 570 | Classification loss: 0.07468 | Regression loss: 0.28705 | Running loss: 0.33150\n",
            "Epoch: 10 | Iteration: 571 | Classification loss: 0.13818 | Regression loss: 0.29681 | Running loss: 0.33176\n",
            "Epoch: 10 | Iteration: 572 | Classification loss: 0.11465 | Regression loss: 0.22258 | Running loss: 0.33192\n",
            "Epoch: 10 | Iteration: 573 | Classification loss: 0.02674 | Regression loss: 0.13746 | Running loss: 0.33184\n",
            "Epoch: 10 | Iteration: 574 | Classification loss: 0.13900 | Regression loss: 0.32313 | Running loss: 0.33187\n",
            "Epoch: 10 | Iteration: 575 | Classification loss: 0.03004 | Regression loss: 0.19882 | Running loss: 0.33181\n",
            "Epoch: 10 | Iteration: 576 | Classification loss: 0.05122 | Regression loss: 0.11541 | Running loss: 0.33143\n",
            "Epoch: 10 | Iteration: 577 | Classification loss: 0.21585 | Regression loss: 0.37225 | Running loss: 0.33186\n",
            "Epoch: 10 | Iteration: 578 | Classification loss: 0.07543 | Regression loss: 0.22564 | Running loss: 0.33192\n",
            "Epoch: 10 | Iteration: 579 | Classification loss: 0.09094 | Regression loss: 0.15701 | Running loss: 0.33207\n",
            "Epoch: 10 | Iteration: 580 | Classification loss: 0.07029 | Regression loss: 0.09493 | Running loss: 0.33166\n",
            "Epoch: 10 | Iteration: 581 | Classification loss: 0.11018 | Regression loss: 0.14431 | Running loss: 0.33136\n",
            "Epoch: 10 | Iteration: 582 | Classification loss: 0.09571 | Regression loss: 0.20879 | Running loss: 0.33109\n",
            "Epoch: 10 | Iteration: 583 | Classification loss: 0.07899 | Regression loss: 0.25528 | Running loss: 0.33121\n",
            "Epoch: 10 | Iteration: 584 | Classification loss: 0.05646 | Regression loss: 0.16432 | Running loss: 0.33127\n",
            "Epoch: 10 | Iteration: 585 | Classification loss: 0.04781 | Regression loss: 0.15209 | Running loss: 0.33127\n",
            "Epoch: 10 | Iteration: 586 | Classification loss: 0.09772 | Regression loss: 0.21949 | Running loss: 0.33072\n",
            "Epoch: 10 | Iteration: 587 | Classification loss: 0.15242 | Regression loss: 0.20415 | Running loss: 0.33072\n",
            "Epoch: 10 | Iteration: 588 | Classification loss: 0.13185 | Regression loss: 0.24545 | Running loss: 0.33094\n",
            "Epoch: 10 | Iteration: 589 | Classification loss: 0.06011 | Regression loss: 0.22494 | Running loss: 0.33077\n",
            "Epoch: 10 | Iteration: 590 | Classification loss: 0.05343 | Regression loss: 0.19199 | Running loss: 0.33082\n",
            "Epoch: 10 | Iteration: 591 | Classification loss: 0.15275 | Regression loss: 0.30378 | Running loss: 0.33102\n",
            "Epoch: 10 | Iteration: 592 | Classification loss: 0.17578 | Regression loss: 0.33376 | Running loss: 0.33112\n",
            "Epoch: 10 | Iteration: 593 | Classification loss: 0.13779 | Regression loss: 0.24197 | Running loss: 0.33132\n",
            "Epoch: 10 | Iteration: 594 | Classification loss: 0.07626 | Regression loss: 0.14796 | Running loss: 0.33129\n",
            "Epoch: 10 | Iteration: 595 | Classification loss: 0.09975 | Regression loss: 0.29831 | Running loss: 0.33188\n",
            "Epoch: 10 | Iteration: 596 | Classification loss: 0.10309 | Regression loss: 0.32506 | Running loss: 0.33216\n",
            "Epoch: 10 | Iteration: 597 | Classification loss: 0.10311 | Regression loss: 0.19354 | Running loss: 0.33203\n",
            "Epoch: 10 | Iteration: 598 | Classification loss: 0.09549 | Regression loss: 0.16778 | Running loss: 0.33185\n",
            "Epoch: 10 | Iteration: 599 | Classification loss: 0.12428 | Regression loss: 0.30874 | Running loss: 0.33168\n",
            "Epoch: 10 | Iteration: 600 | Classification loss: 0.06342 | Regression loss: 0.21697 | Running loss: 0.33199\n",
            "Epoch: 10 | Iteration: 601 | Classification loss: 0.08449 | Regression loss: 0.20709 | Running loss: 0.33189\n",
            "Epoch: 10 | Iteration: 602 | Classification loss: 0.05633 | Regression loss: 0.14940 | Running loss: 0.33138\n",
            "Epoch: 10 | Iteration: 603 | Classification loss: 0.14337 | Regression loss: 0.31367 | Running loss: 0.33187\n",
            "Epoch: 10 | Iteration: 604 | Classification loss: 0.04996 | Regression loss: 0.19541 | Running loss: 0.33127\n",
            "Epoch: 10 | Iteration: 605 | Classification loss: 0.11987 | Regression loss: 0.14804 | Running loss: 0.33100\n",
            "Epoch: 10 | Iteration: 606 | Classification loss: 0.12460 | Regression loss: 0.24090 | Running loss: 0.33110\n",
            "Epoch: 10 | Iteration: 607 | Classification loss: 0.09313 | Regression loss: 0.22225 | Running loss: 0.33140\n",
            "Epoch: 10 | Iteration: 608 | Classification loss: 0.07799 | Regression loss: 0.15600 | Running loss: 0.33078\n",
            "Epoch: 10 | Iteration: 609 | Classification loss: 0.13567 | Regression loss: 0.27890 | Running loss: 0.33105\n",
            "Epoch: 10 | Iteration: 610 | Classification loss: 0.12803 | Regression loss: 0.33199 | Running loss: 0.33175\n",
            "Epoch: 10 | Iteration: 611 | Classification loss: 0.03704 | Regression loss: 0.09426 | Running loss: 0.33134\n",
            "Epoch: 10 | Iteration: 612 | Classification loss: 0.12646 | Regression loss: 0.27761 | Running loss: 0.33161\n",
            "Epoch: 10 | Iteration: 613 | Classification loss: 0.17645 | Regression loss: 0.39507 | Running loss: 0.33158\n",
            "Epoch: 10 | Iteration: 614 | Classification loss: 0.13779 | Regression loss: 0.21888 | Running loss: 0.33159\n",
            "Epoch: 10 | Iteration: 615 | Classification loss: 0.21098 | Regression loss: 0.34425 | Running loss: 0.33207\n",
            "Epoch: 10 | Iteration: 616 | Classification loss: 0.20519 | Regression loss: 0.36460 | Running loss: 0.33231\n",
            "Epoch: 10 | Iteration: 617 | Classification loss: 0.11374 | Regression loss: 0.29320 | Running loss: 0.33264\n",
            "Epoch: 10 | Iteration: 618 | Classification loss: 0.07973 | Regression loss: 0.17160 | Running loss: 0.33196\n",
            "Epoch: 10 | Iteration: 619 | Classification loss: 0.12950 | Regression loss: 0.15409 | Running loss: 0.33215\n",
            "Epoch: 10 | Iteration: 620 | Classification loss: 0.15630 | Regression loss: 0.28072 | Running loss: 0.33257\n",
            "Epoch: 10 | Iteration: 621 | Classification loss: 0.13838 | Regression loss: 0.25392 | Running loss: 0.33283\n",
            "Epoch: 10 | Iteration: 622 | Classification loss: 0.21789 | Regression loss: 0.38875 | Running loss: 0.33384\n",
            "Epoch: 10 | Iteration: 623 | Classification loss: 0.15896 | Regression loss: 0.37272 | Running loss: 0.33417\n",
            "Epoch: 10 | Iteration: 624 | Classification loss: 0.13330 | Regression loss: 0.29916 | Running loss: 0.33459\n",
            "Epoch: 10 | Iteration: 625 | Classification loss: 0.08214 | Regression loss: 0.18142 | Running loss: 0.33452\n",
            "Epoch: 10 | Iteration: 626 | Classification loss: 0.03106 | Regression loss: 0.09579 | Running loss: 0.33389\n",
            "Epoch: 10 | Iteration: 627 | Classification loss: 0.10259 | Regression loss: 0.20734 | Running loss: 0.33415\n",
            "Epoch: 10 | Iteration: 628 | Classification loss: 0.11069 | Regression loss: 0.16722 | Running loss: 0.33411\n",
            "Epoch: 10 | Iteration: 629 | Classification loss: 0.09414 | Regression loss: 0.24968 | Running loss: 0.33424\n",
            "Epoch: 10 | Iteration: 630 | Classification loss: 0.26310 | Regression loss: 0.44878 | Running loss: 0.33528\n",
            "Epoch: 10 | Iteration: 631 | Classification loss: 0.07429 | Regression loss: 0.24330 | Running loss: 0.33505\n",
            "Epoch: 10 | Iteration: 632 | Classification loss: 0.14970 | Regression loss: 0.28062 | Running loss: 0.33482\n",
            "Epoch: 10 | Iteration: 633 | Classification loss: 0.14352 | Regression loss: 0.31746 | Running loss: 0.33467\n",
            "Epoch: 10 | Iteration: 634 | Classification loss: 0.10256 | Regression loss: 0.24018 | Running loss: 0.33457\n",
            "Epoch: 10 | Iteration: 635 | Classification loss: 0.18174 | Regression loss: 0.33622 | Running loss: 0.33496\n",
            "Epoch: 10 | Iteration: 636 | Classification loss: 0.25002 | Regression loss: 0.36227 | Running loss: 0.33554\n",
            "Epoch: 10 | Iteration: 637 | Classification loss: 0.11735 | Regression loss: 0.19957 | Running loss: 0.33585\n",
            "Epoch: 10 | Iteration: 638 | Classification loss: 0.11743 | Regression loss: 0.18420 | Running loss: 0.33593\n",
            "Epoch: 10 | Iteration: 639 | Classification loss: 0.04925 | Regression loss: 0.18136 | Running loss: 0.33582\n",
            "Epoch: 10 | Iteration: 640 | Classification loss: 0.14054 | Regression loss: 0.21494 | Running loss: 0.33626\n",
            "Epoch: 10 | Iteration: 641 | Classification loss: 0.13639 | Regression loss: 0.26321 | Running loss: 0.33675\n",
            "Epoch: 10 | Iteration: 642 | Classification loss: 0.13928 | Regression loss: 0.17704 | Running loss: 0.33701\n",
            "Epoch: 10 | Iteration: 643 | Classification loss: 0.11277 | Regression loss: 0.19936 | Running loss: 0.33668\n",
            "Epoch: 10 | Iteration: 644 | Classification loss: 0.13273 | Regression loss: 0.26148 | Running loss: 0.33689\n",
            "Epoch: 10 | Iteration: 645 | Classification loss: 0.20442 | Regression loss: 0.37923 | Running loss: 0.33787\n",
            "Epoch: 10 | Iteration: 646 | Classification loss: 0.08638 | Regression loss: 0.21356 | Running loss: 0.33750\n",
            "Epoch: 10 | Iteration: 647 | Classification loss: 0.07843 | Regression loss: 0.16191 | Running loss: 0.33705\n",
            "Epoch: 10 | Iteration: 648 | Classification loss: 0.10264 | Regression loss: 0.26427 | Running loss: 0.33668\n",
            "Epoch: 10 | Iteration: 649 | Classification loss: 0.07149 | Regression loss: 0.17807 | Running loss: 0.33648\n",
            "Epoch: 10 | Iteration: 650 | Classification loss: 0.03917 | Regression loss: 0.12901 | Running loss: 0.33606\n",
            "Epoch: 10 | Iteration: 651 | Classification loss: 0.17669 | Regression loss: 0.09865 | Running loss: 0.33607\n",
            "Epoch: 10 | Iteration: 652 | Classification loss: 0.15444 | Regression loss: 0.26113 | Running loss: 0.33624\n",
            "Epoch: 10 | Iteration: 653 | Classification loss: 0.10635 | Regression loss: 0.17294 | Running loss: 0.33632\n",
            "Epoch: 10 | Iteration: 654 | Classification loss: 0.11145 | Regression loss: 0.20984 | Running loss: 0.33618\n",
            "Epoch: 10 | Iteration: 655 | Classification loss: 0.12160 | Regression loss: 0.22906 | Running loss: 0.33661\n",
            "Epoch: 10 | Iteration: 656 | Classification loss: 0.12728 | Regression loss: 0.19482 | Running loss: 0.33649\n",
            "Epoch: 10 | Iteration: 657 | Classification loss: 0.21680 | Regression loss: 0.33515 | Running loss: 0.33711\n",
            "Epoch: 10 | Iteration: 658 | Classification loss: 0.11010 | Regression loss: 0.27392 | Running loss: 0.33696\n",
            "Epoch: 10 | Iteration: 659 | Classification loss: 0.05858 | Regression loss: 0.14789 | Running loss: 0.33589\n",
            "Epoch: 10 | Iteration: 660 | Classification loss: 0.11180 | Regression loss: 0.17013 | Running loss: 0.33585\n",
            "Epoch: 10 | Iteration: 661 | Classification loss: 0.04085 | Regression loss: 0.15418 | Running loss: 0.33584\n",
            "Epoch: 10 | Iteration: 662 | Classification loss: 0.10732 | Regression loss: 0.30872 | Running loss: 0.33569\n",
            "Epoch: 10 | Iteration: 663 | Classification loss: 0.09043 | Regression loss: 0.24834 | Running loss: 0.33583\n",
            "Epoch: 10 | Iteration: 664 | Classification loss: 0.16750 | Regression loss: 0.30516 | Running loss: 0.33595\n",
            "Epoch: 10 | Iteration: 665 | Classification loss: 0.12800 | Regression loss: 0.28811 | Running loss: 0.33635\n",
            "Epoch: 10 | Iteration: 666 | Classification loss: 0.07173 | Regression loss: 0.10541 | Running loss: 0.33555\n",
            "Epoch: 10 | Iteration: 667 | Classification loss: 0.05562 | Regression loss: 0.24800 | Running loss: 0.33559\n",
            "Epoch: 10 | Iteration: 668 | Classification loss: 0.07932 | Regression loss: 0.12268 | Running loss: 0.33529\n",
            "Epoch: 10 | Iteration: 669 | Classification loss: 0.07951 | Regression loss: 0.22036 | Running loss: 0.33520\n",
            "Epoch: 10 | Iteration: 670 | Classification loss: 0.06807 | Regression loss: 0.17325 | Running loss: 0.33489\n",
            "Epoch: 10 | Iteration: 671 | Classification loss: 0.07554 | Regression loss: 0.14849 | Running loss: 0.33487\n",
            "Epoch: 10 | Iteration: 672 | Classification loss: 0.08977 | Regression loss: 0.32715 | Running loss: 0.33492\n",
            "Epoch: 10 | Iteration: 673 | Classification loss: 0.14629 | Regression loss: 0.29373 | Running loss: 0.33508\n",
            "Epoch: 10 | Iteration: 674 | Classification loss: 0.15498 | Regression loss: 0.32408 | Running loss: 0.33569\n",
            "Epoch: 10 | Iteration: 675 | Classification loss: 0.06996 | Regression loss: 0.21245 | Running loss: 0.33533\n",
            "Epoch: 10 | Iteration: 676 | Classification loss: 0.06112 | Regression loss: 0.18917 | Running loss: 0.33498\n",
            "Epoch: 10 | Iteration: 677 | Classification loss: 0.05749 | Regression loss: 0.20675 | Running loss: 0.33481\n",
            "Epoch: 10 | Iteration: 678 | Classification loss: 0.08712 | Regression loss: 0.10652 | Running loss: 0.33467\n",
            "Epoch: 10 | Iteration: 679 | Classification loss: 0.14006 | Regression loss: 0.18717 | Running loss: 0.33495\n",
            "Epoch: 10 | Iteration: 680 | Classification loss: 0.22782 | Regression loss: 0.37089 | Running loss: 0.33559\n",
            "Epoch: 10 | Iteration: 681 | Classification loss: 0.13463 | Regression loss: 0.39572 | Running loss: 0.33615\n",
            "Epoch: 10 | Iteration: 682 | Classification loss: 0.10463 | Regression loss: 0.19519 | Running loss: 0.33589\n",
            "Epoch: 10 | Iteration: 683 | Classification loss: 0.08528 | Regression loss: 0.23340 | Running loss: 0.33613\n",
            "Epoch: 10 | Iteration: 684 | Classification loss: 0.04074 | Regression loss: 0.14018 | Running loss: 0.33610\n",
            "Epoch: 10 | Iteration: 685 | Classification loss: 0.07863 | Regression loss: 0.08416 | Running loss: 0.33603\n",
            "Epoch: 10 | Iteration: 686 | Classification loss: 0.06643 | Regression loss: 0.14036 | Running loss: 0.33572\n",
            "Epoch: 10 | Iteration: 687 | Classification loss: 0.13568 | Regression loss: 0.31955 | Running loss: 0.33603\n",
            "Epoch: 10 | Iteration: 688 | Classification loss: 0.15468 | Regression loss: 0.33387 | Running loss: 0.33631\n",
            "Epoch: 10 | Iteration: 689 | Classification loss: 0.11740 | Regression loss: 0.23668 | Running loss: 0.33620\n",
            "Epoch: 10 | Iteration: 690 | Classification loss: 0.10705 | Regression loss: 0.25993 | Running loss: 0.33663\n",
            "Epoch: 10 | Iteration: 691 | Classification loss: 0.10808 | Regression loss: 0.21169 | Running loss: 0.33616\n",
            "Epoch: 10 | Iteration: 692 | Classification loss: 0.16854 | Regression loss: 0.33646 | Running loss: 0.33652\n",
            "Epoch: 10 | Iteration: 693 | Classification loss: 0.08037 | Regression loss: 0.24484 | Running loss: 0.33653\n",
            "Epoch: 10 | Iteration: 694 | Classification loss: 0.03863 | Regression loss: 0.13622 | Running loss: 0.33625\n",
            "Epoch: 10 | Iteration: 695 | Classification loss: 0.15903 | Regression loss: 0.27238 | Running loss: 0.33623\n",
            "Epoch: 10 | Iteration: 696 | Classification loss: 0.08580 | Regression loss: 0.14277 | Running loss: 0.33602\n",
            "Epoch: 10 | Iteration: 697 | Classification loss: 0.16284 | Regression loss: 0.34614 | Running loss: 0.33611\n",
            "Epoch: 10 | Iteration: 698 | Classification loss: 0.06089 | Regression loss: 0.20461 | Running loss: 0.33607\n",
            "Epoch: 10 | Iteration: 699 | Classification loss: 0.12569 | Regression loss: 0.22590 | Running loss: 0.33622\n",
            "Epoch: 10 | Iteration: 700 | Classification loss: 0.06338 | Regression loss: 0.14476 | Running loss: 0.33601\n",
            "Epoch: 10 | Iteration: 701 | Classification loss: 0.02516 | Regression loss: 0.10997 | Running loss: 0.33604\n",
            "Epoch: 10 | Iteration: 702 | Classification loss: 0.07584 | Regression loss: 0.22275 | Running loss: 0.33583\n",
            "Epoch: 10 | Iteration: 703 | Classification loss: 0.07599 | Regression loss: 0.23018 | Running loss: 0.33584\n",
            "Epoch: 10 | Iteration: 704 | Classification loss: 0.12469 | Regression loss: 0.23912 | Running loss: 0.33600\n",
            "Epoch: 10 | Iteration: 705 | Classification loss: 0.03150 | Regression loss: 0.12341 | Running loss: 0.33576\n",
            "Epoch: 10 | Iteration: 706 | Classification loss: 0.14420 | Regression loss: 0.29965 | Running loss: 0.33606\n",
            "Epoch: 10 | Iteration: 707 | Classification loss: 0.05589 | Regression loss: 0.13535 | Running loss: 0.33572\n",
            "Epoch: 10 | Iteration: 708 | Classification loss: 0.10016 | Regression loss: 0.24217 | Running loss: 0.33539\n",
            "Epoch: 10 | Iteration: 709 | Classification loss: 0.13278 | Regression loss: 0.38886 | Running loss: 0.33599\n",
            "Epoch: 10 | Iteration: 710 | Classification loss: 0.25691 | Regression loss: 0.35221 | Running loss: 0.33670\n",
            "Epoch: 10 | Iteration: 711 | Classification loss: 0.12872 | Regression loss: 0.24575 | Running loss: 0.33683\n",
            "Epoch: 10 | Iteration: 712 | Classification loss: 0.09303 | Regression loss: 0.20151 | Running loss: 0.33693\n",
            "Epoch: 10 | Iteration: 713 | Classification loss: 0.14510 | Regression loss: 0.28634 | Running loss: 0.33749\n",
            "Epoch: 10 | Iteration: 714 | Classification loss: 0.14152 | Regression loss: 0.22549 | Running loss: 0.33710\n",
            "Epoch: 10 | Iteration: 715 | Classification loss: 0.15686 | Regression loss: 0.27473 | Running loss: 0.33732\n",
            "Epoch: 10 | Iteration: 716 | Classification loss: 0.10095 | Regression loss: 0.17780 | Running loss: 0.33713\n",
            "Epoch: 10 | Iteration: 717 | Classification loss: 0.07729 | Regression loss: 0.20872 | Running loss: 0.33733\n",
            "Epoch: 10 | Iteration: 718 | Classification loss: 0.12403 | Regression loss: 0.26449 | Running loss: 0.33713\n",
            "Epoch: 10 | Iteration: 719 | Classification loss: 0.13401 | Regression loss: 0.20177 | Running loss: 0.33711\n",
            "Epoch: 10 | Iteration: 720 | Classification loss: 0.09168 | Regression loss: 0.25702 | Running loss: 0.33698\n",
            "Epoch: 10 | Iteration: 721 | Classification loss: 0.07869 | Regression loss: 0.23701 | Running loss: 0.33699\n",
            "Epoch: 10 | Iteration: 722 | Classification loss: 0.16535 | Regression loss: 0.35664 | Running loss: 0.33740\n",
            "Epoch: 10 | Iteration: 723 | Classification loss: 0.08394 | Regression loss: 0.22115 | Running loss: 0.33736\n",
            "Epoch: 10 | Iteration: 724 | Classification loss: 0.06961 | Regression loss: 0.16989 | Running loss: 0.33740\n",
            "Epoch: 10 | Iteration: 725 | Classification loss: 0.13376 | Regression loss: 0.27189 | Running loss: 0.33761\n",
            "Epoch: 10 | Iteration: 726 | Classification loss: 0.15111 | Regression loss: 0.30360 | Running loss: 0.33803\n",
            "Epoch: 10 | Iteration: 727 | Classification loss: 0.11035 | Regression loss: 0.15980 | Running loss: 0.33817\n",
            "Epoch: 10 | Iteration: 728 | Classification loss: 0.08884 | Regression loss: 0.21270 | Running loss: 0.33814\n",
            "Epoch: 10 | Iteration: 729 | Classification loss: 0.08192 | Regression loss: 0.21033 | Running loss: 0.33812\n",
            "Epoch: 10 | Iteration: 730 | Classification loss: 0.05184 | Regression loss: 0.15555 | Running loss: 0.33771\n",
            "Epoch: 10 | Iteration: 731 | Classification loss: 0.11253 | Regression loss: 0.23821 | Running loss: 0.33752\n",
            "Epoch: 10 | Iteration: 732 | Classification loss: 0.07468 | Regression loss: 0.19940 | Running loss: 0.33763\n",
            "Epoch: 10 | Iteration: 733 | Classification loss: 0.07951 | Regression loss: 0.25191 | Running loss: 0.33773\n",
            "Epoch: 10 | Iteration: 734 | Classification loss: 0.13123 | Regression loss: 0.23375 | Running loss: 0.33791\n",
            "Epoch: 10 | Iteration: 735 | Classification loss: 0.08641 | Regression loss: 0.20701 | Running loss: 0.33812\n",
            "Epoch: 10 | Iteration: 736 | Classification loss: 0.08535 | Regression loss: 0.13699 | Running loss: 0.33783\n",
            "Epoch: 10 | Iteration: 737 | Classification loss: 0.17842 | Regression loss: 0.31711 | Running loss: 0.33825\n",
            "Epoch: 10 | Iteration: 738 | Classification loss: 0.01823 | Regression loss: 0.06432 | Running loss: 0.33803\n",
            "Epoch: 10 | Iteration: 739 | Classification loss: 0.16548 | Regression loss: 0.18219 | Running loss: 0.33824\n",
            "Epoch: 10 | Iteration: 740 | Classification loss: 0.09243 | Regression loss: 0.29037 | Running loss: 0.33840\n",
            "Epoch: 10 | Iteration: 741 | Classification loss: 0.04462 | Regression loss: 0.15663 | Running loss: 0.33821\n",
            "Epoch: 10 | Iteration: 742 | Classification loss: 0.08464 | Regression loss: 0.18667 | Running loss: 0.33826\n",
            "Epoch: 10 | Iteration: 743 | Classification loss: 0.12724 | Regression loss: 0.32874 | Running loss: 0.33868\n",
            "Epoch: 10 | Iteration: 744 | Classification loss: 0.10748 | Regression loss: 0.21146 | Running loss: 0.33841\n",
            "Epoch: 10 | Iteration: 745 | Classification loss: 0.07870 | Regression loss: 0.19329 | Running loss: 0.33771\n",
            "Epoch: 10 | Iteration: 746 | Classification loss: 0.17402 | Regression loss: 0.36275 | Running loss: 0.33810\n",
            "Epoch: 10 | Iteration: 747 | Classification loss: 0.07598 | Regression loss: 0.17244 | Running loss: 0.33825\n",
            "Epoch: 10 | Iteration: 748 | Classification loss: 0.11194 | Regression loss: 0.30980 | Running loss: 0.33859\n",
            "Epoch: 10 | Iteration: 749 | Classification loss: 0.09360 | Regression loss: 0.17987 | Running loss: 0.33853\n",
            "Epoch: 10 | Iteration: 750 | Classification loss: 0.05307 | Regression loss: 0.15127 | Running loss: 0.33863\n",
            "Epoch: 10 | Iteration: 751 | Classification loss: 0.05251 | Regression loss: 0.15404 | Running loss: 0.33815\n",
            "Epoch: 10 | Iteration: 752 | Classification loss: 0.03815 | Regression loss: 0.10126 | Running loss: 0.33696\n",
            "Epoch: 10 | Iteration: 753 | Classification loss: 0.12599 | Regression loss: 0.34488 | Running loss: 0.33696\n",
            "Epoch: 10 | Iteration: 754 | Classification loss: 0.05736 | Regression loss: 0.24406 | Running loss: 0.33729\n",
            "Epoch: 10 | Iteration: 755 | Classification loss: 0.16319 | Regression loss: 0.24461 | Running loss: 0.33718\n",
            "Epoch: 10 | Iteration: 756 | Classification loss: 0.14284 | Regression loss: 0.22073 | Running loss: 0.33707\n",
            "Epoch: 10 | Iteration: 757 | Classification loss: 0.04783 | Regression loss: 0.16124 | Running loss: 0.33671\n",
            "Epoch: 10 | Iteration: 758 | Classification loss: 0.10699 | Regression loss: 0.26307 | Running loss: 0.33711\n",
            "Epoch: 10 | Iteration: 759 | Classification loss: 0.12832 | Regression loss: 0.20041 | Running loss: 0.33584\n",
            "Epoch: 10 | Iteration: 760 | Classification loss: 0.11928 | Regression loss: 0.29186 | Running loss: 0.33619\n",
            "Epoch: 10 | Iteration: 761 | Classification loss: 0.04669 | Regression loss: 0.08806 | Running loss: 0.33555\n",
            "Epoch: 10 | Iteration: 762 | Classification loss: 0.11329 | Regression loss: 0.18572 | Running loss: 0.33564\n",
            "Epoch: 10 | Iteration: 763 | Classification loss: 0.15711 | Regression loss: 0.34035 | Running loss: 0.33605\n",
            "Epoch: 10 | Iteration: 764 | Classification loss: 0.15180 | Regression loss: 0.26160 | Running loss: 0.33604\n",
            "Epoch: 10 | Iteration: 765 | Classification loss: 0.19004 | Regression loss: 0.40933 | Running loss: 0.33622\n",
            "Epoch: 10 | Iteration: 766 | Classification loss: 0.13273 | Regression loss: 0.21567 | Running loss: 0.33600\n",
            "Epoch: 10 | Iteration: 767 | Classification loss: 0.03697 | Regression loss: 0.15222 | Running loss: 0.33508\n",
            "Epoch: 10 | Iteration: 768 | Classification loss: 0.26664 | Regression loss: 0.28865 | Running loss: 0.33569\n",
            "Epoch: 10 | Iteration: 769 | Classification loss: 0.22056 | Regression loss: 0.39287 | Running loss: 0.33657\n",
            "Epoch: 10 | Iteration: 770 | Classification loss: 0.08427 | Regression loss: 0.26220 | Running loss: 0.33694\n",
            "Epoch: 10 | Iteration: 771 | Classification loss: 0.04309 | Regression loss: 0.13173 | Running loss: 0.33670\n",
            "Epoch: 10 | Iteration: 772 | Classification loss: 0.09945 | Regression loss: 0.15805 | Running loss: 0.33663\n",
            "Epoch: 10 | Iteration: 773 | Classification loss: 0.05045 | Regression loss: 0.18834 | Running loss: 0.33651\n",
            "Epoch: 10 | Iteration: 774 | Classification loss: 0.07382 | Regression loss: 0.18145 | Running loss: 0.33600\n",
            "Epoch: 10 | Iteration: 775 | Classification loss: 0.04540 | Regression loss: 0.15514 | Running loss: 0.33574\n",
            "Epoch: 10 | Iteration: 776 | Classification loss: 0.07040 | Regression loss: 0.14110 | Running loss: 0.33517\n",
            "Epoch: 10 | Iteration: 777 | Classification loss: 0.20218 | Regression loss: 0.32306 | Running loss: 0.33519\n",
            "Epoch: 10 | Iteration: 778 | Classification loss: 0.09528 | Regression loss: 0.22021 | Running loss: 0.33554\n",
            "Epoch: 10 | Iteration: 779 | Classification loss: 0.06429 | Regression loss: 0.13967 | Running loss: 0.33539\n",
            "Epoch: 10 | Iteration: 780 | Classification loss: 0.08141 | Regression loss: 0.15501 | Running loss: 0.33528\n",
            "Epoch: 10 | Iteration: 781 | Classification loss: 0.08781 | Regression loss: 0.20691 | Running loss: 0.33541\n",
            "Epoch: 10 | Iteration: 782 | Classification loss: 0.05269 | Regression loss: 0.15320 | Running loss: 0.33515\n",
            "Epoch: 10 | Iteration: 783 | Classification loss: 0.11724 | Regression loss: 0.35905 | Running loss: 0.33578\n",
            "Epoch: 10 | Iteration: 784 | Classification loss: 0.10473 | Regression loss: 0.26232 | Running loss: 0.33560\n",
            "Epoch: 10 | Iteration: 785 | Classification loss: 0.16170 | Regression loss: 0.31675 | Running loss: 0.33617\n",
            "Epoch: 10 | Iteration: 786 | Classification loss: 0.12347 | Regression loss: 0.15438 | Running loss: 0.33625\n",
            "Epoch: 10 | Iteration: 787 | Classification loss: 0.09390 | Regression loss: 0.20931 | Running loss: 0.33605\n",
            "Epoch: 10 | Iteration: 788 | Classification loss: 0.10966 | Regression loss: 0.20734 | Running loss: 0.33587\n",
            "Epoch: 10 | Iteration: 789 | Classification loss: 0.09907 | Regression loss: 0.10455 | Running loss: 0.33572\n",
            "Epoch: 10 | Iteration: 790 | Classification loss: 0.25716 | Regression loss: 0.32631 | Running loss: 0.33622\n",
            "Epoch: 10 | Iteration: 791 | Classification loss: 0.07916 | Regression loss: 0.22651 | Running loss: 0.33635\n",
            "Epoch: 10 | Iteration: 792 | Classification loss: 0.08145 | Regression loss: 0.22825 | Running loss: 0.33656\n",
            "Epoch: 10 | Iteration: 793 | Classification loss: 0.12222 | Regression loss: 0.22752 | Running loss: 0.33633\n",
            "Epoch: 10 | Iteration: 794 | Classification loss: 0.16722 | Regression loss: 0.27317 | Running loss: 0.33654\n",
            "Epoch: 10 | Iteration: 795 | Classification loss: 0.05055 | Regression loss: 0.14260 | Running loss: 0.33593\n",
            "Epoch: 10 | Iteration: 796 | Classification loss: 0.11726 | Regression loss: 0.27923 | Running loss: 0.33594\n",
            "Epoch: 10 | Iteration: 797 | Classification loss: 0.16228 | Regression loss: 0.31741 | Running loss: 0.33633\n",
            "Epoch: 10 | Iteration: 798 | Classification loss: 0.18497 | Regression loss: 0.25286 | Running loss: 0.33671\n",
            "Epoch: 10 | Iteration: 799 | Classification loss: 0.19856 | Regression loss: 0.25374 | Running loss: 0.33640\n",
            "Epoch: 10 | Iteration: 800 | Classification loss: 0.08451 | Regression loss: 0.27604 | Running loss: 0.33656\n",
            "Epoch: 10 | Iteration: 801 | Classification loss: 0.07155 | Regression loss: 0.19609 | Running loss: 0.33607\n",
            "Epoch: 10 | Iteration: 802 | Classification loss: 0.15529 | Regression loss: 0.26576 | Running loss: 0.33607\n",
            "Epoch: 10 | Iteration: 803 | Classification loss: 0.06827 | Regression loss: 0.19461 | Running loss: 0.33550\n",
            "Epoch: 10 | Iteration: 804 | Classification loss: 0.08125 | Regression loss: 0.21973 | Running loss: 0.33580\n",
            "Epoch: 10 | Iteration: 805 | Classification loss: 0.07742 | Regression loss: 0.27583 | Running loss: 0.33500\n",
            "Epoch: 10 | Iteration: 806 | Classification loss: 0.13264 | Regression loss: 0.29559 | Running loss: 0.33508\n",
            "Epoch: 10 | Iteration: 807 | Classification loss: 0.14333 | Regression loss: 0.30653 | Running loss: 0.33553\n",
            "Epoch: 10 | Iteration: 808 | Classification loss: 0.17969 | Regression loss: 0.28655 | Running loss: 0.33595\n",
            "Epoch: 10 | Iteration: 809 | Classification loss: 0.14647 | Regression loss: 0.32986 | Running loss: 0.33596\n",
            "Epoch: 10 | Iteration: 810 | Classification loss: 0.14812 | Regression loss: 0.29833 | Running loss: 0.33598\n",
            "Epoch: 10 | Iteration: 811 | Classification loss: 0.08225 | Regression loss: 0.14649 | Running loss: 0.33602\n",
            "Epoch: 10 | Iteration: 812 | Classification loss: 0.15675 | Regression loss: 0.36144 | Running loss: 0.33646\n",
            "Epoch: 10 | Iteration: 813 | Classification loss: 0.10339 | Regression loss: 0.17218 | Running loss: 0.33650\n",
            "Epoch: 10 | Iteration: 814 | Classification loss: 0.10433 | Regression loss: 0.24506 | Running loss: 0.33686\n",
            "Epoch: 10 | Iteration: 815 | Classification loss: 0.17564 | Regression loss: 0.31111 | Running loss: 0.33670\n",
            "Epoch: 10 | Iteration: 816 | Classification loss: 0.15244 | Regression loss: 0.22013 | Running loss: 0.33652\n",
            "Epoch: 10 | Iteration: 817 | Classification loss: 0.15273 | Regression loss: 0.23370 | Running loss: 0.33673\n",
            "Epoch: 10 | Iteration: 818 | Classification loss: 0.10657 | Regression loss: 0.24899 | Running loss: 0.33687\n",
            "Epoch: 10 | Iteration: 819 | Classification loss: 0.12256 | Regression loss: 0.23691 | Running loss: 0.33710\n",
            "Epoch: 10 | Iteration: 820 | Classification loss: 0.12708 | Regression loss: 0.21541 | Running loss: 0.33682\n",
            "Epoch: 10 | Iteration: 821 | Classification loss: 0.08257 | Regression loss: 0.16517 | Running loss: 0.33665\n",
            "Epoch: 10 | Iteration: 822 | Classification loss: 0.13190 | Regression loss: 0.30042 | Running loss: 0.33703\n",
            "Epoch: 10 | Iteration: 823 | Classification loss: 0.10808 | Regression loss: 0.21641 | Running loss: 0.33699\n",
            "Epoch: 10 | Iteration: 824 | Classification loss: 0.09257 | Regression loss: 0.25431 | Running loss: 0.33710\n",
            "Epoch: 10 | Iteration: 825 | Classification loss: 0.10209 | Regression loss: 0.17348 | Running loss: 0.33683\n",
            "Epoch: 10 | Iteration: 826 | Classification loss: 0.18921 | Regression loss: 0.35867 | Running loss: 0.33751\n",
            "Epoch: 10 | Iteration: 827 | Classification loss: 0.17950 | Regression loss: 0.31087 | Running loss: 0.33808\n",
            "Epoch: 10 | Iteration: 828 | Classification loss: 0.06936 | Regression loss: 0.14401 | Running loss: 0.33743\n",
            "Epoch: 10 | Iteration: 829 | Classification loss: 0.11007 | Regression loss: 0.18634 | Running loss: 0.33728\n",
            "Epoch: 10 | Iteration: 830 | Classification loss: 0.06462 | Regression loss: 0.16508 | Running loss: 0.33706\n",
            "Epoch: 10 | Iteration: 831 | Classification loss: 0.09803 | Regression loss: 0.26267 | Running loss: 0.33702\n",
            "Epoch: 10 | Iteration: 832 | Classification loss: 0.08414 | Regression loss: 0.21011 | Running loss: 0.33701\n",
            "Epoch: 10 | Iteration: 833 | Classification loss: 0.06507 | Regression loss: 0.20233 | Running loss: 0.33705\n",
            "Epoch: 10 | Iteration: 834 | Classification loss: 0.02747 | Regression loss: 0.08408 | Running loss: 0.33626\n",
            "Epoch: 10 | Iteration: 835 | Classification loss: 0.14990 | Regression loss: 0.30994 | Running loss: 0.33666\n",
            "Epoch: 10 | Iteration: 836 | Classification loss: 0.03737 | Regression loss: 0.13486 | Running loss: 0.33659\n",
            "Epoch: 10 | Iteration: 837 | Classification loss: 0.08301 | Regression loss: 0.18582 | Running loss: 0.33639\n",
            "Epoch: 10 | Iteration: 838 | Classification loss: 0.15325 | Regression loss: 0.20884 | Running loss: 0.33651\n",
            "Epoch: 10 | Iteration: 839 | Classification loss: 0.06067 | Regression loss: 0.13922 | Running loss: 0.33646\n",
            "Epoch: 10 | Iteration: 840 | Classification loss: 0.09256 | Regression loss: 0.19016 | Running loss: 0.33647\n",
            "Epoch: 10 | Iteration: 841 | Classification loss: 0.14230 | Regression loss: 0.22715 | Running loss: 0.33672\n",
            "Epoch: 10 | Iteration: 842 | Classification loss: 0.07398 | Regression loss: 0.15076 | Running loss: 0.33675\n",
            "Epoch: 10 | Iteration: 843 | Classification loss: 0.10659 | Regression loss: 0.25908 | Running loss: 0.33697\n",
            "Epoch: 10 | Iteration: 844 | Classification loss: 0.09097 | Regression loss: 0.23669 | Running loss: 0.33707\n",
            "Epoch: 10 | Iteration: 845 | Classification loss: 0.05667 | Regression loss: 0.14120 | Running loss: 0.33663\n",
            "Epoch: 10 | Iteration: 846 | Classification loss: 0.27535 | Regression loss: 0.32786 | Running loss: 0.33711\n",
            "Epoch: 10 | Iteration: 847 | Classification loss: 0.04461 | Regression loss: 0.12730 | Running loss: 0.33653\n",
            "Epoch: 10 | Iteration: 848 | Classification loss: 0.15894 | Regression loss: 0.27122 | Running loss: 0.33692\n",
            "Epoch: 10 | Iteration: 849 | Classification loss: 0.11528 | Regression loss: 0.31321 | Running loss: 0.33731\n",
            "Epoch: 10 | Iteration: 850 | Classification loss: 0.16035 | Regression loss: 0.33805 | Running loss: 0.33767\n",
            "Epoch: 10 | Iteration: 851 | Classification loss: 0.04940 | Regression loss: 0.16268 | Running loss: 0.33753\n",
            "Epoch: 10 | Iteration: 852 | Classification loss: 0.19320 | Regression loss: 0.31143 | Running loss: 0.33800\n",
            "Epoch: 10 | Iteration: 853 | Classification loss: 0.18238 | Regression loss: 0.29039 | Running loss: 0.33860\n",
            "Epoch: 10 | Iteration: 854 | Classification loss: 0.13774 | Regression loss: 0.39977 | Running loss: 0.33903\n",
            "Epoch: 10 | Iteration: 855 | Classification loss: 0.13240 | Regression loss: 0.20349 | Running loss: 0.33843\n",
            "Epoch: 10 | Iteration: 856 | Classification loss: 0.11054 | Regression loss: 0.35631 | Running loss: 0.33853\n",
            "Epoch: 10 | Iteration: 857 | Classification loss: 0.15295 | Regression loss: 0.24863 | Running loss: 0.33884\n",
            "Epoch: 10 | Iteration: 858 | Classification loss: 0.06489 | Regression loss: 0.23827 | Running loss: 0.33841\n",
            "Epoch: 10 | Iteration: 859 | Classification loss: 0.12429 | Regression loss: 0.20983 | Running loss: 0.33860\n",
            "Epoch: 10 | Iteration: 860 | Classification loss: 0.20423 | Regression loss: 0.27642 | Running loss: 0.33892\n",
            "Epoch: 10 | Iteration: 861 | Classification loss: 0.06309 | Regression loss: 0.23037 | Running loss: 0.33873\n",
            "Epoch: 10 | Iteration: 862 | Classification loss: 0.05535 | Regression loss: 0.10885 | Running loss: 0.33836\n",
            "Epoch: 10 | Iteration: 863 | Classification loss: 0.02804 | Regression loss: 0.14954 | Running loss: 0.33840\n",
            "Epoch: 10 | Iteration: 864 | Classification loss: 0.10199 | Regression loss: 0.26222 | Running loss: 0.33867\n",
            "Epoch: 10 | Iteration: 865 | Classification loss: 0.15251 | Regression loss: 0.33700 | Running loss: 0.33914\n",
            "Epoch: 10 | Iteration: 866 | Classification loss: 0.10002 | Regression loss: 0.22130 | Running loss: 0.33932\n",
            "Epoch: 10 | Iteration: 867 | Classification loss: 0.10587 | Regression loss: 0.27490 | Running loss: 0.33896\n",
            "Epoch: 10 | Iteration: 868 | Classification loss: 0.12077 | Regression loss: 0.17245 | Running loss: 0.33904\n",
            "Epoch: 10 | Iteration: 869 | Classification loss: 0.02672 | Regression loss: 0.09863 | Running loss: 0.33853\n",
            "Epoch: 10 | Iteration: 870 | Classification loss: 0.13152 | Regression loss: 0.29432 | Running loss: 0.33865\n",
            "Epoch: 10 | Iteration: 871 | Classification loss: 0.12906 | Regression loss: 0.24212 | Running loss: 0.33860\n",
            "Epoch: 10 | Iteration: 872 | Classification loss: 0.20782 | Regression loss: 0.27001 | Running loss: 0.33899\n",
            "Epoch: 10 | Iteration: 873 | Classification loss: 0.10656 | Regression loss: 0.31371 | Running loss: 0.33922\n",
            "Epoch: 10 | Iteration: 874 | Classification loss: 0.12499 | Regression loss: 0.21831 | Running loss: 0.33943\n",
            "Epoch: 10 | Iteration: 875 | Classification loss: 0.04117 | Regression loss: 0.09789 | Running loss: 0.33912\n",
            "Epoch: 10 | Iteration: 876 | Classification loss: 0.09707 | Regression loss: 0.17175 | Running loss: 0.33903\n",
            "Epoch: 10 | Iteration: 877 | Classification loss: 0.06629 | Regression loss: 0.20491 | Running loss: 0.33898\n",
            "Epoch: 10 | Iteration: 878 | Classification loss: 0.01584 | Regression loss: 0.06322 | Running loss: 0.33821\n",
            "Epoch: 10 | Iteration: 879 | Classification loss: 0.15706 | Regression loss: 0.10356 | Running loss: 0.33821\n",
            "Epoch: 10 | Iteration: 880 | Classification loss: 0.11709 | Regression loss: 0.34288 | Running loss: 0.33837\n",
            "Epoch: 10 | Iteration: 881 | Classification loss: 0.01627 | Regression loss: 0.07114 | Running loss: 0.33819\n",
            "Epoch: 10 | Iteration: 882 | Classification loss: 0.05224 | Regression loss: 0.15812 | Running loss: 0.33826\n",
            "Epoch: 10 | Iteration: 883 | Classification loss: 0.13080 | Regression loss: 0.18715 | Running loss: 0.33829\n",
            "Epoch: 10 | Iteration: 884 | Classification loss: 0.11351 | Regression loss: 0.20234 | Running loss: 0.33846\n",
            "Epoch: 10 | Iteration: 885 | Classification loss: 0.15404 | Regression loss: 0.22661 | Running loss: 0.33847\n",
            "Epoch: 10 | Iteration: 886 | Classification loss: 0.14223 | Regression loss: 0.29360 | Running loss: 0.33845\n",
            "Epoch: 10 | Iteration: 887 | Classification loss: 0.14627 | Regression loss: 0.27861 | Running loss: 0.33844\n",
            "Epoch: 10 | Iteration: 888 | Classification loss: 0.01936 | Regression loss: 0.07691 | Running loss: 0.33787\n",
            "Epoch: 10 | Iteration: 889 | Classification loss: 0.06808 | Regression loss: 0.13561 | Running loss: 0.33752\n",
            "Epoch: 10 | Iteration: 890 | Classification loss: 0.10750 | Regression loss: 0.19569 | Running loss: 0.33772\n",
            "Epoch: 10 | Iteration: 891 | Classification loss: 0.09809 | Regression loss: 0.18928 | Running loss: 0.33744\n",
            "Epoch: 10 | Iteration: 892 | Classification loss: 0.08136 | Regression loss: 0.17250 | Running loss: 0.33745\n",
            "Epoch: 10 | Iteration: 893 | Classification loss: 0.08945 | Regression loss: 0.24913 | Running loss: 0.33714\n",
            "Epoch: 10 | Iteration: 894 | Classification loss: 0.24858 | Regression loss: 0.25664 | Running loss: 0.33690\n",
            "Epoch: 10 | Iteration: 895 | Classification loss: 0.10280 | Regression loss: 0.19413 | Running loss: 0.33709\n",
            "Epoch: 10 | Iteration: 896 | Classification loss: 0.19176 | Regression loss: 0.29872 | Running loss: 0.33765\n",
            "Epoch: 10 | Iteration: 897 | Classification loss: 0.17160 | Regression loss: 0.28733 | Running loss: 0.33818\n",
            "Epoch: 10 | Iteration: 898 | Classification loss: 0.10129 | Regression loss: 0.11614 | Running loss: 0.33790\n",
            "Epoch: 10 | Iteration: 899 | Classification loss: 0.11337 | Regression loss: 0.30109 | Running loss: 0.33781\n",
            "Epoch: 10 | Iteration: 900 | Classification loss: 0.15416 | Regression loss: 0.34934 | Running loss: 0.33812\n",
            "Epoch: 10 | Iteration: 901 | Classification loss: 0.14129 | Regression loss: 0.36269 | Running loss: 0.33889\n",
            "Epoch: 10 | Iteration: 902 | Classification loss: 0.06087 | Regression loss: 0.17591 | Running loss: 0.33869\n",
            "Epoch: 10 | Iteration: 903 | Classification loss: 0.21291 | Regression loss: 0.36872 | Running loss: 0.33932\n",
            "Epoch: 10 | Iteration: 904 | Classification loss: 0.08113 | Regression loss: 0.14661 | Running loss: 0.33949\n",
            "Epoch: 10 | Iteration: 905 | Classification loss: 0.07233 | Regression loss: 0.18953 | Running loss: 0.33950\n",
            "Epoch: 10 | Iteration: 906 | Classification loss: 0.12171 | Regression loss: 0.29231 | Running loss: 0.33999\n",
            "Epoch: 10 | Iteration: 907 | Classification loss: 0.09622 | Regression loss: 0.17027 | Running loss: 0.34007\n",
            "Epoch: 10 | Iteration: 908 | Classification loss: 0.17358 | Regression loss: 0.30271 | Running loss: 0.34070\n",
            "Epoch: 10 | Iteration: 909 | Classification loss: 0.12642 | Regression loss: 0.26694 | Running loss: 0.34113\n",
            "Epoch: 10 | Iteration: 910 | Classification loss: 0.06447 | Regression loss: 0.18669 | Running loss: 0.34104\n",
            "Epoch: 10 | Iteration: 911 | Classification loss: 0.12050 | Regression loss: 0.24285 | Running loss: 0.34132\n",
            "Epoch: 10 | Iteration: 912 | Classification loss: 0.12118 | Regression loss: 0.20964 | Running loss: 0.34155\n",
            "Epoch: 10 | Iteration: 913 | Classification loss: 0.12523 | Regression loss: 0.17145 | Running loss: 0.34161\n",
            "Epoch: 10 | Iteration: 914 | Classification loss: 0.13353 | Regression loss: 0.17873 | Running loss: 0.34156\n",
            "Epoch: 10 | Iteration: 915 | Classification loss: 0.10981 | Regression loss: 0.37965 | Running loss: 0.34172\n",
            "Epoch: 10 | Iteration: 916 | Classification loss: 0.08115 | Regression loss: 0.12321 | Running loss: 0.34146\n",
            "Epoch: 10 | Iteration: 917 | Classification loss: 0.05177 | Regression loss: 0.14203 | Running loss: 0.34135\n",
            "Epoch: 10 | Iteration: 918 | Classification loss: 0.14598 | Regression loss: 0.33884 | Running loss: 0.34114\n",
            "Epoch: 10 | Iteration: 919 | Classification loss: 0.05678 | Regression loss: 0.17938 | Running loss: 0.34128\n",
            "Epoch: 10 | Iteration: 920 | Classification loss: 0.04967 | Regression loss: 0.21312 | Running loss: 0.34117\n",
            "Epoch: 10 | Iteration: 921 | Classification loss: 0.03571 | Regression loss: 0.08901 | Running loss: 0.34017\n",
            "Epoch: 10 | Iteration: 922 | Classification loss: 0.02443 | Regression loss: 0.12207 | Running loss: 0.33984\n",
            "Epoch: 10 | Iteration: 923 | Classification loss: 0.14811 | Regression loss: 0.31018 | Running loss: 0.33999\n",
            "Epoch: 10 | Iteration: 924 | Classification loss: 0.07876 | Regression loss: 0.09471 | Running loss: 0.33961\n",
            "Epoch: 10 | Iteration: 925 | Classification loss: 0.05386 | Regression loss: 0.15426 | Running loss: 0.33918\n",
            "Epoch: 10 | Iteration: 926 | Classification loss: 0.22969 | Regression loss: 0.34401 | Running loss: 0.33992\n",
            "Epoch: 10 | Iteration: 927 | Classification loss: 0.08806 | Regression loss: 0.22114 | Running loss: 0.34002\n",
            "Epoch: 10 | Iteration: 928 | Classification loss: 0.07535 | Regression loss: 0.23225 | Running loss: 0.34002\n",
            "Epoch: 10 | Iteration: 929 | Classification loss: 0.18791 | Regression loss: 0.30420 | Running loss: 0.34053\n",
            "Epoch: 10 | Iteration: 930 | Classification loss: 0.11585 | Regression loss: 0.29712 | Running loss: 0.34064\n",
            "Epoch: 10 | Iteration: 931 | Classification loss: 0.10038 | Regression loss: 0.15620 | Running loss: 0.34050\n",
            "Epoch: 10 | Iteration: 932 | Classification loss: 0.07711 | Regression loss: 0.23216 | Running loss: 0.34073\n",
            "Epoch: 10 | Iteration: 933 | Classification loss: 0.12746 | Regression loss: 0.19460 | Running loss: 0.34112\n",
            "Epoch: 10 | Iteration: 934 | Classification loss: 0.02865 | Regression loss: 0.09073 | Running loss: 0.34063\n",
            "Epoch: 10 | Iteration: 935 | Classification loss: 0.08105 | Regression loss: 0.25995 | Running loss: 0.34098\n",
            "Epoch: 10 | Iteration: 936 | Classification loss: 0.04914 | Regression loss: 0.20959 | Running loss: 0.34069\n",
            "Epoch: 10 | Iteration: 937 | Classification loss: 0.05111 | Regression loss: 0.17259 | Running loss: 0.34069\n",
            "Epoch: 10 | Iteration: 938 | Classification loss: 0.14582 | Regression loss: 0.33970 | Running loss: 0.34124\n",
            "Epoch: 10 | Iteration: 939 | Classification loss: 0.15992 | Regression loss: 0.31339 | Running loss: 0.34138\n",
            "Epoch: 10 | Iteration: 940 | Classification loss: 0.15948 | Regression loss: 0.36327 | Running loss: 0.34223\n",
            "Epoch: 10 | Iteration: 941 | Classification loss: 0.06765 | Regression loss: 0.14551 | Running loss: 0.34201\n",
            "Epoch: 10 | Iteration: 942 | Classification loss: 0.07614 | Regression loss: 0.20512 | Running loss: 0.34140\n",
            "Epoch: 10 | Iteration: 943 | Classification loss: 0.07984 | Regression loss: 0.28198 | Running loss: 0.34143\n",
            "Epoch: 10 | Iteration: 944 | Classification loss: 0.06731 | Regression loss: 0.20331 | Running loss: 0.34156\n",
            "Epoch: 10 | Iteration: 945 | Classification loss: 0.16815 | Regression loss: 0.19653 | Running loss: 0.34183\n",
            "Epoch: 10 | Iteration: 946 | Classification loss: 0.11122 | Regression loss: 0.27316 | Running loss: 0.34162\n",
            "Epoch: 10 | Iteration: 947 | Classification loss: 0.11131 | Regression loss: 0.24217 | Running loss: 0.34169\n",
            "Epoch: 10 | Iteration: 948 | Classification loss: 0.13055 | Regression loss: 0.38097 | Running loss: 0.34211\n",
            "Epoch: 10 | Iteration: 949 | Classification loss: 0.06683 | Regression loss: 0.18953 | Running loss: 0.34186\n",
            "Epoch: 10 | Iteration: 950 | Classification loss: 0.05448 | Regression loss: 0.21986 | Running loss: 0.34178\n",
            "Epoch: 10 | Iteration: 951 | Classification loss: 0.09046 | Regression loss: 0.24770 | Running loss: 0.34165\n",
            "Epoch: 10 | Iteration: 952 | Classification loss: 0.07318 | Regression loss: 0.17005 | Running loss: 0.34137\n",
            "Epoch: 10 | Iteration: 953 | Classification loss: 0.11622 | Regression loss: 0.14875 | Running loss: 0.34149\n",
            "Epoch: 10 | Iteration: 954 | Classification loss: 0.08669 | Regression loss: 0.16870 | Running loss: 0.34140\n",
            "Epoch: 10 | Iteration: 955 | Classification loss: 0.27307 | Regression loss: 0.36969 | Running loss: 0.34221\n",
            "Epoch: 10 | Iteration: 956 | Classification loss: 0.08853 | Regression loss: 0.20420 | Running loss: 0.34238\n",
            "Epoch: 10 | Iteration: 957 | Classification loss: 0.16917 | Regression loss: 0.26915 | Running loss: 0.34278\n",
            "Epoch: 10 | Iteration: 958 | Classification loss: 0.11292 | Regression loss: 0.22297 | Running loss: 0.34289\n",
            "Epoch: 10 | Iteration: 959 | Classification loss: 0.09832 | Regression loss: 0.22068 | Running loss: 0.34269\n",
            "Epoch: 10 | Iteration: 960 | Classification loss: 0.07126 | Regression loss: 0.12632 | Running loss: 0.34252\n",
            "Epoch: 10 | Iteration: 961 | Classification loss: 0.05053 | Regression loss: 0.09989 | Running loss: 0.34233\n",
            "Epoch: 10 | Iteration: 962 | Classification loss: 0.10833 | Regression loss: 0.30653 | Running loss: 0.34258\n",
            "Epoch: 10 | Iteration: 963 | Classification loss: 0.13528 | Regression loss: 0.25508 | Running loss: 0.34232\n",
            "Epoch: 10 | Iteration: 964 | Classification loss: 0.11140 | Regression loss: 0.22373 | Running loss: 0.34240\n",
            "Epoch: 10 | Iteration: 965 | Classification loss: 0.26889 | Regression loss: 0.19957 | Running loss: 0.34272\n",
            "Epoch: 10 | Iteration: 966 | Classification loss: 0.03902 | Regression loss: 0.11633 | Running loss: 0.34218\n",
            "Epoch: 10 | Iteration: 967 | Classification loss: 0.04214 | Regression loss: 0.18951 | Running loss: 0.34165\n",
            "Epoch: 10 | Iteration: 968 | Classification loss: 0.14554 | Regression loss: 0.25676 | Running loss: 0.34186\n",
            "Epoch: 10 | Iteration: 969 | Classification loss: 0.07275 | Regression loss: 0.21224 | Running loss: 0.34166\n",
            "Epoch: 10 | Iteration: 970 | Classification loss: 0.07166 | Regression loss: 0.15931 | Running loss: 0.34134\n",
            "Epoch: 10 | Iteration: 971 | Classification loss: 0.07411 | Regression loss: 0.18461 | Running loss: 0.34067\n",
            "Epoch: 10 | Iteration: 972 | Classification loss: 0.04649 | Regression loss: 0.19213 | Running loss: 0.34050\n",
            "Epoch: 10 | Iteration: 973 | Classification loss: 0.01917 | Regression loss: 0.07337 | Running loss: 0.33935\n",
            "Epoch: 10 | Iteration: 974 | Classification loss: 0.24325 | Regression loss: 0.29367 | Running loss: 0.33968\n",
            "Epoch: 10 | Iteration: 975 | Classification loss: 0.20397 | Regression loss: 0.28811 | Running loss: 0.33960\n",
            "Epoch: 10 | Iteration: 976 | Classification loss: 0.16078 | Regression loss: 0.27616 | Running loss: 0.33984\n",
            "Epoch: 10 | Iteration: 977 | Classification loss: 0.04347 | Regression loss: 0.22171 | Running loss: 0.33977\n",
            "Epoch: 10 | Iteration: 978 | Classification loss: 0.15646 | Regression loss: 0.11403 | Running loss: 0.33901\n",
            "Epoch: 10 | Iteration: 979 | Classification loss: 0.07436 | Regression loss: 0.18297 | Running loss: 0.33901\n",
            "Epoch: 10 | Iteration: 980 | Classification loss: 0.04392 | Regression loss: 0.17668 | Running loss: 0.33902\n",
            "Epoch: 10 | Iteration: 981 | Classification loss: 0.12317 | Regression loss: 0.27109 | Running loss: 0.33917\n",
            "Epoch: 10 | Iteration: 982 | Classification loss: 0.27990 | Regression loss: 0.52941 | Running loss: 0.33991\n",
            "Epoch: 10 | Iteration: 983 | Classification loss: 0.13552 | Regression loss: 0.26201 | Running loss: 0.33994\n",
            "Epoch: 10 | Iteration: 984 | Classification loss: 0.11337 | Regression loss: 0.23651 | Running loss: 0.33984\n",
            "Epoch: 10 | Iteration: 985 | Classification loss: 0.09238 | Regression loss: 0.16269 | Running loss: 0.33947\n",
            "Epoch: 10 | Iteration: 986 | Classification loss: 0.08183 | Regression loss: 0.24192 | Running loss: 0.33925\n",
            "Epoch: 10 | Iteration: 987 | Classification loss: 0.09791 | Regression loss: 0.29828 | Running loss: 0.33937\n",
            "Epoch: 10 | Iteration: 988 | Classification loss: 0.04583 | Regression loss: 0.13572 | Running loss: 0.33934\n",
            "Epoch: 10 | Iteration: 989 | Classification loss: 0.10135 | Regression loss: 0.19037 | Running loss: 0.33931\n",
            "Epoch: 10 | Iteration: 990 | Classification loss: 0.19630 | Regression loss: 0.14422 | Running loss: 0.33906\n",
            "Epoch: 10 | Iteration: 991 | Classification loss: 0.10575 | Regression loss: 0.28047 | Running loss: 0.33910\n",
            "Epoch: 10 | Iteration: 992 | Classification loss: 0.21858 | Regression loss: 0.36513 | Running loss: 0.33992\n",
            "Epoch: 10 | Iteration: 993 | Classification loss: 0.14544 | Regression loss: 0.23579 | Running loss: 0.34028\n",
            "Epoch: 10 | Iteration: 994 | Classification loss: 0.08090 | Regression loss: 0.11707 | Running loss: 0.33994\n",
            "Epoch: 10 | Iteration: 995 | Classification loss: 0.11293 | Regression loss: 0.23136 | Running loss: 0.34020\n",
            "Epoch: 10 | Iteration: 996 | Classification loss: 0.10760 | Regression loss: 0.18358 | Running loss: 0.34037\n",
            "Epoch: 10 | Iteration: 997 | Classification loss: 0.07081 | Regression loss: 0.14367 | Running loss: 0.34017\n",
            "Epoch: 10 | Iteration: 998 | Classification loss: 0.06265 | Regression loss: 0.20331 | Running loss: 0.34021\n",
            "Epoch: 10 | Iteration: 999 | Classification loss: 0.11207 | Regression loss: 0.27835 | Running loss: 0.34054\n",
            "Epoch: 10 | Iteration: 1000 | Classification loss: 0.10389 | Regression loss: 0.25119 | Running loss: 0.34071\n",
            "Epoch: 10 | Iteration: 1001 | Classification loss: 0.05329 | Regression loss: 0.14562 | Running loss: 0.34033\n",
            "Epoch: 10 | Iteration: 1002 | Classification loss: 0.08769 | Regression loss: 0.26934 | Running loss: 0.34023\n",
            "Epoch: 10 | Iteration: 1003 | Classification loss: 0.16397 | Regression loss: 0.31510 | Running loss: 0.34072\n",
            "Epoch: 10 | Iteration: 1004 | Classification loss: 0.10491 | Regression loss: 0.27702 | Running loss: 0.34096\n",
            "Epoch: 10 | Iteration: 1005 | Classification loss: 0.15165 | Regression loss: 0.30695 | Running loss: 0.34114\n",
            "Epoch: 10 | Iteration: 1006 | Classification loss: 0.14597 | Regression loss: 0.25756 | Running loss: 0.34131\n",
            "Epoch: 10 | Iteration: 1007 | Classification loss: 0.03344 | Regression loss: 0.14772 | Running loss: 0.34125\n",
            "Epoch: 10 | Iteration: 1008 | Classification loss: 0.16299 | Regression loss: 0.38456 | Running loss: 0.34183\n",
            "Epoch: 10 | Iteration: 1009 | Classification loss: 0.15296 | Regression loss: 0.30972 | Running loss: 0.34220\n",
            "Epoch: 10 | Iteration: 1010 | Classification loss: 0.25670 | Regression loss: 0.34558 | Running loss: 0.34292\n",
            "Epoch: 10 | Iteration: 1011 | Classification loss: 0.03310 | Regression loss: 0.12357 | Running loss: 0.34281\n",
            "Epoch: 10 | Iteration: 1012 | Classification loss: 0.07386 | Regression loss: 0.14847 | Running loss: 0.34253\n",
            "Epoch: 10 | Iteration: 1013 | Classification loss: 0.13216 | Regression loss: 0.27805 | Running loss: 0.34209\n",
            "Epoch: 10 | Iteration: 1014 | Classification loss: 0.12985 | Regression loss: 0.30251 | Running loss: 0.34208\n",
            "Epoch: 10 | Iteration: 1015 | Classification loss: 0.03478 | Regression loss: 0.08317 | Running loss: 0.34153\n",
            "Epoch: 10 | Iteration: 1016 | Classification loss: 0.25609 | Regression loss: 0.37629 | Running loss: 0.34191\n",
            "Epoch: 10 | Iteration: 1017 | Classification loss: 0.05014 | Regression loss: 0.15454 | Running loss: 0.34148\n",
            "Epoch: 10 | Iteration: 1018 | Classification loss: 0.05213 | Regression loss: 0.16863 | Running loss: 0.34130\n",
            "Epoch: 10 | Iteration: 1019 | Classification loss: 0.17332 | Regression loss: 0.37090 | Running loss: 0.34172\n",
            "Epoch: 10 | Iteration: 1020 | Classification loss: 0.14997 | Regression loss: 0.21719 | Running loss: 0.34186\n",
            "Epoch: 10 | Iteration: 1021 | Classification loss: 0.11142 | Regression loss: 0.13565 | Running loss: 0.34184\n",
            "Epoch: 10 | Iteration: 1022 | Classification loss: 0.17225 | Regression loss: 0.27611 | Running loss: 0.34161\n",
            "Epoch: 10 | Iteration: 1023 | Classification loss: 0.19074 | Regression loss: 0.31073 | Running loss: 0.34180\n",
            "Epoch: 10 | Iteration: 1024 | Classification loss: 0.15311 | Regression loss: 0.30991 | Running loss: 0.34208\n",
            "Epoch: 10 | Iteration: 1025 | Classification loss: 0.04842 | Regression loss: 0.22195 | Running loss: 0.34210\n",
            "Epoch: 10 | Iteration: 1026 | Classification loss: 0.23269 | Regression loss: 0.33066 | Running loss: 0.34251\n",
            "Epoch: 10 | Iteration: 1027 | Classification loss: 0.16596 | Regression loss: 0.23727 | Running loss: 0.34253\n",
            "Epoch: 10 | Iteration: 1028 | Classification loss: 0.07093 | Regression loss: 0.19096 | Running loss: 0.34226\n",
            "Epoch: 10 | Iteration: 1029 | Classification loss: 0.16189 | Regression loss: 0.27373 | Running loss: 0.34266\n",
            "Epoch: 10 | Iteration: 1030 | Classification loss: 0.04226 | Regression loss: 0.17853 | Running loss: 0.34266\n",
            "Epoch: 10 | Iteration: 1031 | Classification loss: 0.10158 | Regression loss: 0.16123 | Running loss: 0.34230\n",
            "Epoch: 10 | Iteration: 1032 | Classification loss: 0.02755 | Regression loss: 0.18531 | Running loss: 0.34170\n",
            "Epoch: 10 | Iteration: 1033 | Classification loss: 0.06170 | Regression loss: 0.14303 | Running loss: 0.34109\n",
            "Epoch: 10 | Iteration: 1034 | Classification loss: 0.00333 | Regression loss: 0.03467 | Running loss: 0.34076\n",
            "Epoch: 10 | Iteration: 1035 | Classification loss: 0.07309 | Regression loss: 0.16373 | Running loss: 0.33998\n",
            "Epoch: 10 | Iteration: 1036 | Classification loss: 0.04720 | Regression loss: 0.10761 | Running loss: 0.33972\n",
            "Epoch: 10 | Iteration: 1037 | Classification loss: 0.14833 | Regression loss: 0.29171 | Running loss: 0.33983\n",
            "Epoch: 10 | Iteration: 1038 | Classification loss: 0.14813 | Regression loss: 0.29308 | Running loss: 0.33948\n",
            "Epoch: 10 | Iteration: 1039 | Classification loss: 0.10661 | Regression loss: 0.20817 | Running loss: 0.33971\n",
            "Epoch: 10 | Iteration: 1040 | Classification loss: 0.16818 | Regression loss: 0.20970 | Running loss: 0.33974\n",
            "Epoch: 10 | Iteration: 1041 | Classification loss: 0.26226 | Regression loss: 0.34500 | Running loss: 0.34035\n",
            "Epoch: 10 | Iteration: 1042 | Classification loss: 0.10428 | Regression loss: 0.14597 | Running loss: 0.33999\n",
            "Epoch: 10 | Iteration: 1043 | Classification loss: 0.10389 | Regression loss: 0.19640 | Running loss: 0.34028\n",
            "Epoch: 10 | Iteration: 1044 | Classification loss: 0.07765 | Regression loss: 0.21672 | Running loss: 0.33968\n",
            "Epoch: 10 | Iteration: 1045 | Classification loss: 0.07324 | Regression loss: 0.15306 | Running loss: 0.33929\n",
            "Epoch: 10 | Iteration: 1046 | Classification loss: 0.12271 | Regression loss: 0.22378 | Running loss: 0.33933\n",
            "Epoch: 10 | Iteration: 1047 | Classification loss: 0.06589 | Regression loss: 0.17940 | Running loss: 0.33931\n",
            "Epoch: 10 | Iteration: 1048 | Classification loss: 0.27276 | Regression loss: 0.42898 | Running loss: 0.34027\n",
            "Epoch: 10 | Iteration: 1049 | Classification loss: 0.11072 | Regression loss: 0.25391 | Running loss: 0.34045\n",
            "Epoch: 10 | Iteration: 1050 | Classification loss: 0.06847 | Regression loss: 0.14215 | Running loss: 0.34009\n",
            "Epoch: 10 | Iteration: 1051 | Classification loss: 0.14488 | Regression loss: 0.28699 | Running loss: 0.34040\n",
            "Epoch: 10 | Iteration: 1052 | Classification loss: 0.12661 | Regression loss: 0.29018 | Running loss: 0.34045\n",
            "Epoch: 10 | Iteration: 1053 | Classification loss: 0.12411 | Regression loss: 0.19790 | Running loss: 0.34074\n",
            "Epoch: 10 | Iteration: 1054 | Classification loss: 0.14350 | Regression loss: 0.35476 | Running loss: 0.34090\n",
            "Epoch: 10 | Iteration: 1055 | Classification loss: 0.15476 | Regression loss: 0.30030 | Running loss: 0.34098\n",
            "Epoch: 10 | Iteration: 1056 | Classification loss: 0.12570 | Regression loss: 0.23331 | Running loss: 0.34101\n",
            "Epoch: 10 | Iteration: 1057 | Classification loss: 0.11371 | Regression loss: 0.20318 | Running loss: 0.34129\n",
            "Epoch: 10 | Iteration: 1058 | Classification loss: 0.20639 | Regression loss: 0.33036 | Running loss: 0.34185\n",
            "Epoch: 10 | Iteration: 1059 | Classification loss: 0.05708 | Regression loss: 0.15442 | Running loss: 0.34115\n",
            "Epoch: 10 | Iteration: 1060 | Classification loss: 0.21950 | Regression loss: 0.24917 | Running loss: 0.34123\n",
            "Epoch: 10 | Iteration: 1061 | Classification loss: 0.04560 | Regression loss: 0.14909 | Running loss: 0.34089\n",
            "Epoch: 10 | Iteration: 1062 | Classification loss: 0.18558 | Regression loss: 0.18660 | Running loss: 0.34120\n",
            "Epoch: 10 | Iteration: 1063 | Classification loss: 0.09010 | Regression loss: 0.21625 | Running loss: 0.34129\n",
            "Epoch: 10 | Iteration: 1064 | Classification loss: 0.17520 | Regression loss: 0.22756 | Running loss: 0.34159\n",
            "Epoch: 10 | Iteration: 1065 | Classification loss: 0.13127 | Regression loss: 0.26351 | Running loss: 0.34204\n",
            "Epoch: 10 | Iteration: 1066 | Classification loss: 0.09600 | Regression loss: 0.18690 | Running loss: 0.34140\n",
            "Epoch: 10 | Iteration: 1067 | Classification loss: 0.09221 | Regression loss: 0.17622 | Running loss: 0.34116\n",
            "Epoch: 10 | Iteration: 1068 | Classification loss: 0.11077 | Regression loss: 0.20740 | Running loss: 0.34099\n",
            "Epoch: 10 | Iteration: 1069 | Classification loss: 0.07034 | Regression loss: 0.20514 | Running loss: 0.34044\n",
            "Epoch: 10 | Iteration: 1070 | Classification loss: 0.04146 | Regression loss: 0.16282 | Running loss: 0.34012\n",
            "Epoch: 10 | Iteration: 1071 | Classification loss: 0.08501 | Regression loss: 0.15683 | Running loss: 0.33973\n",
            "Epoch: 10 | Iteration: 1072 | Classification loss: 0.04465 | Regression loss: 0.08793 | Running loss: 0.33933\n",
            "Epoch: 10 | Iteration: 1073 | Classification loss: 0.06935 | Regression loss: 0.19993 | Running loss: 0.33954\n",
            "Epoch: 10 | Iteration: 1074 | Classification loss: 0.14933 | Regression loss: 0.16557 | Running loss: 0.33924\n",
            "Epoch: 10 | Iteration: 1075 | Classification loss: 0.10340 | Regression loss: 0.09596 | Running loss: 0.33918\n",
            "Epoch: 10 | Iteration: 1076 | Classification loss: 0.07044 | Regression loss: 0.13984 | Running loss: 0.33927\n",
            "Epoch: 10 | Iteration: 1077 | Classification loss: 0.06832 | Regression loss: 0.11506 | Running loss: 0.33846\n",
            "Epoch: 10 | Iteration: 1078 | Classification loss: 0.09475 | Regression loss: 0.23831 | Running loss: 0.33852\n",
            "Epoch: 10 | Iteration: 1079 | Classification loss: 0.05067 | Regression loss: 0.18733 | Running loss: 0.33850\n",
            "Epoch: 10 | Iteration: 1080 | Classification loss: 0.24567 | Regression loss: 0.40855 | Running loss: 0.33948\n",
            "Epoch: 10 | Iteration: 1081 | Classification loss: 0.13793 | Regression loss: 0.30971 | Running loss: 0.33987\n",
            "Epoch: 10 | Iteration: 1082 | Classification loss: 0.10316 | Regression loss: 0.18355 | Running loss: 0.33983\n",
            "Epoch: 10 | Iteration: 1083 | Classification loss: 0.13725 | Regression loss: 0.32354 | Running loss: 0.34009\n",
            "Epoch: 10 | Iteration: 1084 | Classification loss: 0.09514 | Regression loss: 0.22733 | Running loss: 0.34029\n",
            "Epoch: 10 | Iteration: 1085 | Classification loss: 0.10109 | Regression loss: 0.18219 | Running loss: 0.34046\n",
            "Epoch: 10 | Iteration: 1086 | Classification loss: 0.15457 | Regression loss: 0.31104 | Running loss: 0.34075\n",
            "Epoch: 10 | Iteration: 1087 | Classification loss: 0.09854 | Regression loss: 0.28936 | Running loss: 0.34082\n",
            "Epoch: 10 | Iteration: 1088 | Classification loss: 0.02924 | Regression loss: 0.15715 | Running loss: 0.34043\n",
            "Epoch: 10 | Iteration: 1089 | Classification loss: 0.11182 | Regression loss: 0.28146 | Running loss: 0.34065\n",
            "Epoch: 10 | Iteration: 1090 | Classification loss: 0.11256 | Regression loss: 0.19164 | Running loss: 0.34077\n",
            "Epoch: 10 | Iteration: 1091 | Classification loss: 0.09595 | Regression loss: 0.30787 | Running loss: 0.34066\n",
            "Epoch: 10 | Iteration: 1092 | Classification loss: 0.06641 | Regression loss: 0.15716 | Running loss: 0.34009\n",
            "Epoch: 10 | Iteration: 1093 | Classification loss: 0.09566 | Regression loss: 0.17684 | Running loss: 0.33988\n",
            "Epoch: 10 | Iteration: 1094 | Classification loss: 0.10180 | Regression loss: 0.23643 | Running loss: 0.34010\n",
            "Epoch: 10 | Iteration: 1095 | Classification loss: 0.11267 | Regression loss: 0.25904 | Running loss: 0.34005\n",
            "Epoch: 10 | Iteration: 1096 | Classification loss: 0.16656 | Regression loss: 0.21236 | Running loss: 0.33995\n",
            "Epoch: 10 | Iteration: 1097 | Classification loss: 0.11272 | Regression loss: 0.29187 | Running loss: 0.34017\n",
            "Epoch: 10 | Iteration: 1098 | Classification loss: 0.09010 | Regression loss: 0.14662 | Running loss: 0.34012\n",
            "Epoch: 10 | Iteration: 1099 | Classification loss: 0.12937 | Regression loss: 0.25777 | Running loss: 0.34002\n",
            "Epoch: 10 | Iteration: 1100 | Classification loss: 0.21566 | Regression loss: 0.19872 | Running loss: 0.34029\n",
            "Epoch: 10 | Iteration: 1101 | Classification loss: 0.08261 | Regression loss: 0.09842 | Running loss: 0.34007\n",
            "Epoch: 10 | Iteration: 1102 | Classification loss: 0.03440 | Regression loss: 0.11460 | Running loss: 0.33996\n",
            "Epoch: 10 | Iteration: 1103 | Classification loss: 0.13551 | Regression loss: 0.28489 | Running loss: 0.33988\n",
            "Epoch: 10 | Iteration: 1104 | Classification loss: 0.09561 | Regression loss: 0.33055 | Running loss: 0.34025\n",
            "Epoch: 10 | Iteration: 1105 | Classification loss: 0.20511 | Regression loss: 0.30280 | Running loss: 0.34073\n",
            "Epoch: 10 | Iteration: 1106 | Classification loss: 0.06350 | Regression loss: 0.14442 | Running loss: 0.34041\n",
            "Epoch: 10 | Iteration: 1107 | Classification loss: 0.25055 | Regression loss: 0.23370 | Running loss: 0.34075\n",
            "Epoch: 10 | Iteration: 1108 | Classification loss: 0.10226 | Regression loss: 0.25255 | Running loss: 0.34099\n",
            "Epoch: 10 | Iteration: 1109 | Classification loss: 0.12224 | Regression loss: 0.27579 | Running loss: 0.34096\n",
            "Epoch: 10 | Iteration: 1110 | Classification loss: 0.05551 | Regression loss: 0.11862 | Running loss: 0.34038\n",
            "Epoch: 10 | Iteration: 1111 | Classification loss: 0.14193 | Regression loss: 0.23361 | Running loss: 0.34087\n",
            "Epoch: 10 | Iteration: 1112 | Classification loss: 0.07774 | Regression loss: 0.21687 | Running loss: 0.34065\n",
            "Epoch: 10 | Iteration: 1113 | Classification loss: 0.19012 | Regression loss: 0.38573 | Running loss: 0.34066\n",
            "Epoch: 10 | Iteration: 1114 | Classification loss: 0.06531 | Regression loss: 0.18097 | Running loss: 0.34044\n",
            "Epoch: 10 | Iteration: 1115 | Classification loss: 0.13117 | Regression loss: 0.14170 | Running loss: 0.33988\n",
            "Epoch: 10 | Iteration: 1116 | Classification loss: 0.20582 | Regression loss: 0.24445 | Running loss: 0.33964\n",
            "Epoch: 10 | Iteration: 1117 | Classification loss: 0.08520 | Regression loss: 0.21300 | Running loss: 0.33942\n",
            "Epoch: 10 | Iteration: 1118 | Classification loss: 0.03908 | Regression loss: 0.06412 | Running loss: 0.33912\n",
            "Epoch: 10 | Iteration: 1119 | Classification loss: 0.14500 | Regression loss: 0.22203 | Running loss: 0.33929\n",
            "Epoch: 10 | Iteration: 1120 | Classification loss: 0.23766 | Regression loss: 0.30481 | Running loss: 0.33950\n",
            "Epoch: 10 | Iteration: 1121 | Classification loss: 0.12378 | Regression loss: 0.29369 | Running loss: 0.33955\n",
            "Epoch: 10 | Iteration: 1122 | Classification loss: 0.15157 | Regression loss: 0.28112 | Running loss: 0.33921\n",
            "Epoch: 10 | Iteration: 1123 | Classification loss: 0.27318 | Regression loss: 0.37559 | Running loss: 0.33944\n",
            "Epoch: 10 | Iteration: 1124 | Classification loss: 0.10130 | Regression loss: 0.20694 | Running loss: 0.33919\n",
            "Epoch: 10 | Iteration: 1125 | Classification loss: 0.09741 | Regression loss: 0.19537 | Running loss: 0.33925\n",
            "Epoch: 10 | Iteration: 1126 | Classification loss: 0.04204 | Regression loss: 0.14108 | Running loss: 0.33936\n",
            "Epoch: 10 | Iteration: 1127 | Classification loss: 0.15997 | Regression loss: 0.30675 | Running loss: 0.33968\n",
            "Epoch: 10 | Iteration: 1128 | Classification loss: 0.06351 | Regression loss: 0.16105 | Running loss: 0.33957\n",
            "Epoch: 10 | Iteration: 1129 | Classification loss: 0.21254 | Regression loss: 0.29818 | Running loss: 0.33990\n",
            "Epoch: 10 | Iteration: 1130 | Classification loss: 0.05918 | Regression loss: 0.19180 | Running loss: 0.33898\n",
            "Epoch: 10 | Iteration: 1131 | Classification loss: 0.15385 | Regression loss: 0.36391 | Running loss: 0.33938\n",
            "Epoch: 10 | Iteration: 1132 | Classification loss: 0.09193 | Regression loss: 0.21141 | Running loss: 0.33913\n",
            "Epoch: 10 | Iteration: 1133 | Classification loss: 0.06304 | Regression loss: 0.16494 | Running loss: 0.33866\n",
            "Epoch: 10 | Iteration: 1134 | Classification loss: 0.05948 | Regression loss: 0.13467 | Running loss: 0.33836\n",
            "Epoch: 10 | Iteration: 1135 | Classification loss: 0.14576 | Regression loss: 0.36894 | Running loss: 0.33836\n",
            "Epoch: 10 | Iteration: 1136 | Classification loss: 0.15820 | Regression loss: 0.29126 | Running loss: 0.33803\n",
            "Epoch: 10 | Iteration: 1137 | Classification loss: 0.09593 | Regression loss: 0.23285 | Running loss: 0.33806\n",
            "Epoch: 10 | Iteration: 1138 | Classification loss: 0.16244 | Regression loss: 0.35909 | Running loss: 0.33850\n",
            "Epoch: 10 | Iteration: 1139 | Classification loss: 0.09370 | Regression loss: 0.30073 | Running loss: 0.33882\n",
            "Epoch: 10 | Iteration: 1140 | Classification loss: 0.07572 | Regression loss: 0.14510 | Running loss: 0.33855\n",
            "Epoch: 10 | Iteration: 1141 | Classification loss: 0.15291 | Regression loss: 0.31059 | Running loss: 0.33868\n",
            "Epoch: 10 | Iteration: 1142 | Classification loss: 0.39496 | Regression loss: 0.55430 | Running loss: 0.33995\n",
            "Epoch: 10 | Iteration: 1143 | Classification loss: 0.23091 | Regression loss: 0.46859 | Running loss: 0.34072\n",
            "Epoch: 10 | Iteration: 1144 | Classification loss: 0.06437 | Regression loss: 0.22945 | Running loss: 0.34052\n",
            "Epoch: 10 | Iteration: 1145 | Classification loss: 0.10811 | Regression loss: 0.24486 | Running loss: 0.34006\n",
            "Epoch: 10 | Iteration: 1146 | Classification loss: 0.14389 | Regression loss: 0.20157 | Running loss: 0.34015\n",
            "Epoch: 10 | Iteration: 1147 | Classification loss: 0.10380 | Regression loss: 0.20605 | Running loss: 0.34029\n",
            "Epoch: 10 | Iteration: 1148 | Classification loss: 0.04254 | Regression loss: 0.10312 | Running loss: 0.33985\n",
            "Epoch: 10 | Iteration: 1149 | Classification loss: 0.27992 | Regression loss: 0.25868 | Running loss: 0.34043\n",
            "Epoch: 10 | Iteration: 1150 | Classification loss: 0.11692 | Regression loss: 0.36606 | Running loss: 0.34106\n",
            "Epoch: 10 | Iteration: 1151 | Classification loss: 0.18333 | Regression loss: 0.38178 | Running loss: 0.34163\n",
            "Epoch: 10 | Iteration: 1152 | Classification loss: 0.02268 | Regression loss: 0.07790 | Running loss: 0.34100\n",
            "Epoch: 10 | Iteration: 1153 | Classification loss: 0.14470 | Regression loss: 0.23333 | Running loss: 0.34120\n",
            "Epoch: 10 | Iteration: 1154 | Classification loss: 0.11198 | Regression loss: 0.15168 | Running loss: 0.34109\n",
            "Epoch: 10 | Iteration: 1155 | Classification loss: 0.03586 | Regression loss: 0.17592 | Running loss: 0.34081\n",
            "Epoch: 10 | Iteration: 1156 | Classification loss: 0.17613 | Regression loss: 0.27084 | Running loss: 0.34106\n",
            "Epoch: 10 | Iteration: 1157 | Classification loss: 0.13378 | Regression loss: 0.41572 | Running loss: 0.34105\n",
            "Epoch: 10 | Iteration: 1158 | Classification loss: 0.07518 | Regression loss: 0.20752 | Running loss: 0.34085\n",
            "Epoch: 10 | Iteration: 1159 | Classification loss: 0.12761 | Regression loss: 0.24431 | Running loss: 0.34118\n",
            "Epoch: 10 | Iteration: 1160 | Classification loss: 0.05843 | Regression loss: 0.17551 | Running loss: 0.34109\n",
            "Epoch: 10 | Iteration: 1161 | Classification loss: 0.15398 | Regression loss: 0.26420 | Running loss: 0.34153\n",
            "Epoch: 10 | Iteration: 1162 | Classification loss: 0.07565 | Regression loss: 0.21013 | Running loss: 0.34127\n",
            "Epoch: 10 | Iteration: 1163 | Classification loss: 0.12353 | Regression loss: 0.31474 | Running loss: 0.34147\n",
            "Epoch: 10 | Iteration: 1164 | Classification loss: 0.14182 | Regression loss: 0.21779 | Running loss: 0.34124\n",
            "Epoch: 10 | Iteration: 1165 | Classification loss: 0.09298 | Regression loss: 0.21507 | Running loss: 0.34103\n",
            "Epoch: 10 | Iteration: 1166 | Classification loss: 0.14657 | Regression loss: 0.21418 | Running loss: 0.34140\n",
            "Epoch: 10 | Iteration: 1167 | Classification loss: 0.18237 | Regression loss: 0.32974 | Running loss: 0.34181\n",
            "Epoch: 10 | Iteration: 1168 | Classification loss: 0.16210 | Regression loss: 0.19160 | Running loss: 0.34212\n",
            "Epoch: 10 | Iteration: 1169 | Classification loss: 0.11297 | Regression loss: 0.19824 | Running loss: 0.34214\n",
            "Epoch: 10 | Iteration: 1170 | Classification loss: 0.24226 | Regression loss: 0.27140 | Running loss: 0.34268\n",
            "Epoch: 10 | Iteration: 1171 | Classification loss: 0.14185 | Regression loss: 0.33869 | Running loss: 0.34320\n",
            "Epoch: 10 | Iteration: 1172 | Classification loss: 0.17647 | Regression loss: 0.40689 | Running loss: 0.34353\n",
            "Epoch: 10 | Iteration: 1173 | Classification loss: 0.11999 | Regression loss: 0.10198 | Running loss: 0.34309\n",
            "Epoch: 10 | Iteration: 1174 | Classification loss: 0.07118 | Regression loss: 0.23214 | Running loss: 0.34274\n",
            "Epoch: 10 | Iteration: 1175 | Classification loss: 0.06523 | Regression loss: 0.15367 | Running loss: 0.34262\n",
            "Epoch: 10 | Iteration: 1176 | Classification loss: 0.23043 | Regression loss: 0.32580 | Running loss: 0.34323\n",
            "Epoch: 10 | Iteration: 1177 | Classification loss: 0.39173 | Regression loss: 0.21282 | Running loss: 0.34391\n",
            "Epoch: 10 | Iteration: 1178 | Classification loss: 0.16971 | Regression loss: 0.26993 | Running loss: 0.34440\n",
            "Epoch: 10 | Iteration: 1179 | Classification loss: 0.09814 | Regression loss: 0.26168 | Running loss: 0.34446\n",
            "Epoch: 10 | Iteration: 1180 | Classification loss: 0.04845 | Regression loss: 0.20081 | Running loss: 0.34377\n",
            "Epoch: 10 | Iteration: 1181 | Classification loss: 0.03778 | Regression loss: 0.14104 | Running loss: 0.34306\n",
            "Epoch: 10 | Iteration: 1182 | Classification loss: 0.10809 | Regression loss: 0.23797 | Running loss: 0.34316\n",
            "Epoch: 10 | Iteration: 1183 | Classification loss: 0.11445 | Regression loss: 0.20845 | Running loss: 0.34316\n",
            "Epoch: 10 | Iteration: 1184 | Classification loss: 0.11942 | Regression loss: 0.18115 | Running loss: 0.34340\n",
            "Epoch: 10 | Iteration: 1185 | Classification loss: 0.24104 | Regression loss: 0.36488 | Running loss: 0.34429\n",
            "Epoch: 10 | Iteration: 1186 | Classification loss: 0.04745 | Regression loss: 0.20284 | Running loss: 0.34438\n",
            "Epoch: 10 | Iteration: 1187 | Classification loss: 0.11219 | Regression loss: 0.24709 | Running loss: 0.34418\n",
            "Epoch: 10 | Iteration: 1188 | Classification loss: 0.07052 | Regression loss: 0.20902 | Running loss: 0.34377\n",
            "Epoch: 10 | Iteration: 1189 | Classification loss: 0.07168 | Regression loss: 0.14388 | Running loss: 0.34349\n",
            "Epoch: 10 | Iteration: 1190 | Classification loss: 0.17969 | Regression loss: 0.29228 | Running loss: 0.34370\n",
            "Epoch: 10 | Iteration: 1191 | Classification loss: 0.16122 | Regression loss: 0.20172 | Running loss: 0.34379\n",
            "Epoch: 10 | Iteration: 1192 | Classification loss: 0.06359 | Regression loss: 0.17094 | Running loss: 0.34324\n",
            "Epoch: 10 | Iteration: 1193 | Classification loss: 0.13707 | Regression loss: 0.21074 | Running loss: 0.34329\n",
            "Epoch: 10 | Iteration: 1194 | Classification loss: 0.04556 | Regression loss: 0.13614 | Running loss: 0.34330\n",
            "Epoch: 10 | Iteration: 1195 | Classification loss: 0.07451 | Regression loss: 0.17111 | Running loss: 0.34293\n",
            "Epoch: 10 | Iteration: 1196 | Classification loss: 0.08991 | Regression loss: 0.24937 | Running loss: 0.34315\n",
            "Epoch: 10 | Iteration: 1197 | Classification loss: 0.13788 | Regression loss: 0.26355 | Running loss: 0.34294\n",
            "Epoch: 10 | Iteration: 1198 | Classification loss: 0.04938 | Regression loss: 0.11431 | Running loss: 0.34273\n",
            "Epoch: 10 | Iteration: 1199 | Classification loss: 0.10208 | Regression loss: 0.16499 | Running loss: 0.34257\n",
            "Evaluating dataset\n",
            "\n",
            "mAP:\n",
            "ambulance: 0.0017241379310344827\n",
            "auto rickshaw: 0.3399947868978853\n",
            "bicycle: 0.3055996996311771\n",
            "bus: 0.6474870873661032\n",
            "car: 0.6265756299482199\n",
            "garbage van: 0\n",
            "human hauler: 0.19787369067288058\n",
            "minibus: 0.049560439560439554\n",
            "minivan: 0.2509329030937181\n",
            "motorbike: 0.5500112078851812\n",
            "pickup: 0.29865904161877843\n",
            "army vehicle: 0.5787037037037037\n",
            "policecar: 0.0\n",
            "rickshaw: 0.5074848123254143\n",
            "scooter: 0.006756756756756757\n",
            "suv: 0.2065471405374166\n",
            "taxi: 0.3888888888888889\n",
            "three wheelers (CNG): 0.5832240114563478\n",
            "truck: 0.6259544314536631\n",
            "van: 0.144221694185049\n",
            "wheelbarrow: 0.01654055075215647\n",
            "Epoch: 11 | Iteration: 0 | Classification loss: 0.10004 | Regression loss: 0.24416 | Running loss: 0.34284\n",
            "Epoch: 11 | Iteration: 1 | Classification loss: 0.08560 | Regression loss: 0.27782 | Running loss: 0.34329\n",
            "Epoch: 11 | Iteration: 2 | Classification loss: 0.04860 | Regression loss: 0.11913 | Running loss: 0.34303\n",
            "Epoch: 11 | Iteration: 3 | Classification loss: 0.03117 | Regression loss: 0.09940 | Running loss: 0.34268\n",
            "Epoch: 11 | Iteration: 4 | Classification loss: 0.08487 | Regression loss: 0.23283 | Running loss: 0.34259\n",
            "Epoch: 11 | Iteration: 5 | Classification loss: 0.05961 | Regression loss: 0.17811 | Running loss: 0.34275\n",
            "Epoch: 11 | Iteration: 6 | Classification loss: 0.14804 | Regression loss: 0.39290 | Running loss: 0.34295\n",
            "Epoch: 11 | Iteration: 7 | Classification loss: 0.10925 | Regression loss: 0.12280 | Running loss: 0.34303\n",
            "Epoch: 11 | Iteration: 8 | Classification loss: 0.02683 | Regression loss: 0.08855 | Running loss: 0.34258\n",
            "Epoch: 11 | Iteration: 9 | Classification loss: 0.01572 | Regression loss: 0.10101 | Running loss: 0.34177\n",
            "Epoch: 11 | Iteration: 10 | Classification loss: 0.11426 | Regression loss: 0.22787 | Running loss: 0.34123\n",
            "Epoch: 11 | Iteration: 11 | Classification loss: 0.06807 | Regression loss: 0.20578 | Running loss: 0.34103\n",
            "Epoch: 11 | Iteration: 12 | Classification loss: 0.08184 | Regression loss: 0.20443 | Running loss: 0.34102\n",
            "Epoch: 11 | Iteration: 13 | Classification loss: 0.15113 | Regression loss: 0.24784 | Running loss: 0.34095\n",
            "Epoch: 11 | Iteration: 14 | Classification loss: 0.05334 | Regression loss: 0.15621 | Running loss: 0.34064\n",
            "Epoch: 11 | Iteration: 15 | Classification loss: 0.11069 | Regression loss: 0.21464 | Running loss: 0.34042\n",
            "Epoch: 11 | Iteration: 16 | Classification loss: 0.03585 | Regression loss: 0.13477 | Running loss: 0.34021\n",
            "Epoch: 11 | Iteration: 17 | Classification loss: 0.00976 | Regression loss: 0.07871 | Running loss: 0.33981\n",
            "Epoch: 11 | Iteration: 18 | Classification loss: 0.18354 | Regression loss: 0.33539 | Running loss: 0.34007\n",
            "Epoch: 11 | Iteration: 19 | Classification loss: 0.07725 | Regression loss: 0.12238 | Running loss: 0.33980\n",
            "Epoch: 11 | Iteration: 20 | Classification loss: 0.11758 | Regression loss: 0.16140 | Running loss: 0.33966\n",
            "Epoch: 11 | Iteration: 21 | Classification loss: 0.06659 | Regression loss: 0.13791 | Running loss: 0.33944\n",
            "Epoch: 11 | Iteration: 22 | Classification loss: 0.06791 | Regression loss: 0.13901 | Running loss: 0.33881\n",
            "Epoch: 11 | Iteration: 23 | Classification loss: 0.07906 | Regression loss: 0.27844 | Running loss: 0.33891\n",
            "Epoch: 11 | Iteration: 24 | Classification loss: 0.10920 | Regression loss: 0.34359 | Running loss: 0.33934\n",
            "Epoch: 11 | Iteration: 25 | Classification loss: 0.05651 | Regression loss: 0.18325 | Running loss: 0.33901\n",
            "Epoch: 11 | Iteration: 26 | Classification loss: 0.07572 | Regression loss: 0.18852 | Running loss: 0.33863\n",
            "Epoch: 11 | Iteration: 27 | Classification loss: 0.09668 | Regression loss: 0.20730 | Running loss: 0.33869\n",
            "Epoch: 11 | Iteration: 28 | Classification loss: 0.05771 | Regression loss: 0.23202 | Running loss: 0.33867\n",
            "Epoch: 11 | Iteration: 29 | Classification loss: 0.02095 | Regression loss: 0.12903 | Running loss: 0.33839\n",
            "Epoch: 11 | Iteration: 30 | Classification loss: 0.11639 | Regression loss: 0.26840 | Running loss: 0.33874\n",
            "Epoch: 11 | Iteration: 31 | Classification loss: 0.03301 | Regression loss: 0.09896 | Running loss: 0.33830\n",
            "Epoch: 11 | Iteration: 32 | Classification loss: 0.06711 | Regression loss: 0.16071 | Running loss: 0.33821\n",
            "Epoch: 11 | Iteration: 33 | Classification loss: 0.05909 | Regression loss: 0.25343 | Running loss: 0.33817\n",
            "Epoch: 11 | Iteration: 34 | Classification loss: 0.10935 | Regression loss: 0.19806 | Running loss: 0.33806\n",
            "Epoch: 11 | Iteration: 35 | Classification loss: 0.12507 | Regression loss: 0.26642 | Running loss: 0.33825\n",
            "Epoch: 11 | Iteration: 36 | Classification loss: 0.08125 | Regression loss: 0.16381 | Running loss: 0.33830\n",
            "Epoch: 11 | Iteration: 37 | Classification loss: 0.10860 | Regression loss: 0.29002 | Running loss: 0.33811\n",
            "Epoch: 11 | Iteration: 38 | Classification loss: 0.08840 | Regression loss: 0.27571 | Running loss: 0.33867\n",
            "Epoch: 11 | Iteration: 39 | Classification loss: 0.04809 | Regression loss: 0.09656 | Running loss: 0.33826\n",
            "Epoch: 11 | Iteration: 40 | Classification loss: 0.16964 | Regression loss: 0.30481 | Running loss: 0.33845\n",
            "Epoch: 11 | Iteration: 41 | Classification loss: 0.15192 | Regression loss: 0.21625 | Running loss: 0.33878\n",
            "Epoch: 11 | Iteration: 42 | Classification loss: 0.05408 | Regression loss: 0.18518 | Running loss: 0.33872\n",
            "Epoch: 11 | Iteration: 43 | Classification loss: 0.09387 | Regression loss: 0.18975 | Running loss: 0.33837\n",
            "Epoch: 11 | Iteration: 44 | Classification loss: 0.07548 | Regression loss: 0.20053 | Running loss: 0.33829\n",
            "Epoch: 11 | Iteration: 45 | Classification loss: 0.06907 | Regression loss: 0.22209 | Running loss: 0.33832\n",
            "Epoch: 11 | Iteration: 46 | Classification loss: 0.06389 | Regression loss: 0.11236 | Running loss: 0.33760\n",
            "Epoch: 11 | Iteration: 47 | Classification loss: 0.02526 | Regression loss: 0.11609 | Running loss: 0.33739\n",
            "Epoch: 11 | Iteration: 48 | Classification loss: 0.22110 | Regression loss: 0.47543 | Running loss: 0.33794\n",
            "Epoch: 11 | Iteration: 49 | Classification loss: 0.10989 | Regression loss: 0.27236 | Running loss: 0.33816\n",
            "Epoch: 11 | Iteration: 50 | Classification loss: 0.16625 | Regression loss: 0.24078 | Running loss: 0.33856\n",
            "Epoch: 11 | Iteration: 51 | Classification loss: 0.09431 | Regression loss: 0.35636 | Running loss: 0.33905\n",
            "Epoch: 11 | Iteration: 52 | Classification loss: 0.08785 | Regression loss: 0.24238 | Running loss: 0.33943\n",
            "Epoch: 11 | Iteration: 53 | Classification loss: 0.10612 | Regression loss: 0.32463 | Running loss: 0.33935\n",
            "Epoch: 11 | Iteration: 54 | Classification loss: 0.09851 | Regression loss: 0.21294 | Running loss: 0.33937\n",
            "Epoch: 11 | Iteration: 55 | Classification loss: 0.17738 | Regression loss: 0.33645 | Running loss: 0.33958\n",
            "Epoch: 11 | Iteration: 56 | Classification loss: 0.05345 | Regression loss: 0.15496 | Running loss: 0.33927\n",
            "Epoch: 11 | Iteration: 57 | Classification loss: 0.05576 | Regression loss: 0.16045 | Running loss: 0.33929\n",
            "Epoch: 11 | Iteration: 58 | Classification loss: 0.15368 | Regression loss: 0.29010 | Running loss: 0.33943\n",
            "Epoch: 11 | Iteration: 59 | Classification loss: 0.04470 | Regression loss: 0.10029 | Running loss: 0.33907\n",
            "Epoch: 11 | Iteration: 60 | Classification loss: 0.03941 | Regression loss: 0.14020 | Running loss: 0.33860\n",
            "Epoch: 11 | Iteration: 61 | Classification loss: 0.13652 | Regression loss: 0.23349 | Running loss: 0.33907\n",
            "Epoch: 11 | Iteration: 62 | Classification loss: 0.09737 | Regression loss: 0.21023 | Running loss: 0.33909\n",
            "Epoch: 11 | Iteration: 63 | Classification loss: 0.12243 | Regression loss: 0.24046 | Running loss: 0.33882\n",
            "Epoch: 11 | Iteration: 64 | Classification loss: 0.10732 | Regression loss: 0.17888 | Running loss: 0.33857\n",
            "Epoch: 11 | Iteration: 65 | Classification loss: 0.03386 | Regression loss: 0.08180 | Running loss: 0.33760\n",
            "Epoch: 11 | Iteration: 66 | Classification loss: 0.04616 | Regression loss: 0.15595 | Running loss: 0.33731\n",
            "Epoch: 11 | Iteration: 67 | Classification loss: 0.12303 | Regression loss: 0.16940 | Running loss: 0.33751\n",
            "Epoch: 11 | Iteration: 68 | Classification loss: 0.15161 | Regression loss: 0.23238 | Running loss: 0.33717\n",
            "Epoch: 11 | Iteration: 69 | Classification loss: 0.09583 | Regression loss: 0.21412 | Running loss: 0.33656\n",
            "Epoch: 11 | Iteration: 70 | Classification loss: 0.13252 | Regression loss: 0.24069 | Running loss: 0.33662\n",
            "Epoch: 11 | Iteration: 71 | Classification loss: 0.04147 | Regression loss: 0.15889 | Running loss: 0.33667\n",
            "Epoch: 11 | Iteration: 72 | Classification loss: 0.06930 | Regression loss: 0.17973 | Running loss: 0.33665\n",
            "Epoch: 11 | Iteration: 73 | Classification loss: 0.04402 | Regression loss: 0.17910 | Running loss: 0.33662\n",
            "Epoch: 11 | Iteration: 74 | Classification loss: 0.12337 | Regression loss: 0.26300 | Running loss: 0.33688\n",
            "Epoch: 11 | Iteration: 75 | Classification loss: 0.11828 | Regression loss: 0.30823 | Running loss: 0.33734\n",
            "Epoch: 11 | Iteration: 76 | Classification loss: 0.14592 | Regression loss: 0.25322 | Running loss: 0.33771\n",
            "Epoch: 11 | Iteration: 77 | Classification loss: 0.13487 | Regression loss: 0.29142 | Running loss: 0.33751\n",
            "Epoch: 11 | Iteration: 78 | Classification loss: 0.10703 | Regression loss: 0.15926 | Running loss: 0.33741\n",
            "Epoch: 11 | Iteration: 79 | Classification loss: 0.04245 | Regression loss: 0.12092 | Running loss: 0.33733\n",
            "Epoch: 11 | Iteration: 80 | Classification loss: 0.03186 | Regression loss: 0.14769 | Running loss: 0.33722\n",
            "Epoch: 11 | Iteration: 81 | Classification loss: 0.20229 | Regression loss: 0.34968 | Running loss: 0.33773\n",
            "Epoch: 11 | Iteration: 82 | Classification loss: 0.08251 | Regression loss: 0.22344 | Running loss: 0.33793\n",
            "Epoch: 11 | Iteration: 83 | Classification loss: 0.05211 | Regression loss: 0.17497 | Running loss: 0.33744\n",
            "Epoch: 11 | Iteration: 84 | Classification loss: 0.03983 | Regression loss: 0.14580 | Running loss: 0.33707\n",
            "Epoch: 11 | Iteration: 85 | Classification loss: 0.08509 | Regression loss: 0.24482 | Running loss: 0.33678\n",
            "Epoch: 11 | Iteration: 86 | Classification loss: 0.06624 | Regression loss: 0.14783 | Running loss: 0.33665\n",
            "Epoch: 11 | Iteration: 87 | Classification loss: 0.12099 | Regression loss: 0.19419 | Running loss: 0.33667\n",
            "Epoch: 11 | Iteration: 88 | Classification loss: 0.19798 | Regression loss: 0.23720 | Running loss: 0.33691\n",
            "Epoch: 11 | Iteration: 89 | Classification loss: 0.03798 | Regression loss: 0.13957 | Running loss: 0.33686\n",
            "Epoch: 11 | Iteration: 90 | Classification loss: 0.26112 | Regression loss: 0.16745 | Running loss: 0.33655\n",
            "Epoch: 11 | Iteration: 91 | Classification loss: 0.04989 | Regression loss: 0.16497 | Running loss: 0.33636\n",
            "Epoch: 11 | Iteration: 92 | Classification loss: 0.06830 | Regression loss: 0.14121 | Running loss: 0.33616\n",
            "Epoch: 11 | Iteration: 93 | Classification loss: 0.09959 | Regression loss: 0.21457 | Running loss: 0.33609\n",
            "Epoch: 11 | Iteration: 94 | Classification loss: 0.09467 | Regression loss: 0.29793 | Running loss: 0.33600\n",
            "Epoch: 11 | Iteration: 95 | Classification loss: 0.05545 | Regression loss: 0.17690 | Running loss: 0.33608\n",
            "Epoch: 11 | Iteration: 96 | Classification loss: 0.06374 | Regression loss: 0.19411 | Running loss: 0.33580\n",
            "Epoch: 11 | Iteration: 97 | Classification loss: 0.14246 | Regression loss: 0.16715 | Running loss: 0.33546\n",
            "Epoch: 11 | Iteration: 98 | Classification loss: 0.05725 | Regression loss: 0.16138 | Running loss: 0.33502\n",
            "Epoch: 11 | Iteration: 99 | Classification loss: 0.18255 | Regression loss: 0.28173 | Running loss: 0.33504\n",
            "Epoch: 11 | Iteration: 100 | Classification loss: 0.19814 | Regression loss: 0.35471 | Running loss: 0.33543\n",
            "Epoch: 11 | Iteration: 101 | Classification loss: 0.15935 | Regression loss: 0.27486 | Running loss: 0.33576\n",
            "Epoch: 11 | Iteration: 102 | Classification loss: 0.31918 | Regression loss: 0.38728 | Running loss: 0.33633\n",
            "Epoch: 11 | Iteration: 103 | Classification loss: 0.17503 | Regression loss: 0.34979 | Running loss: 0.33686\n",
            "Epoch: 11 | Iteration: 104 | Classification loss: 0.12029 | Regression loss: 0.30718 | Running loss: 0.33711\n",
            "Epoch: 11 | Iteration: 105 | Classification loss: 0.18097 | Regression loss: 0.37525 | Running loss: 0.33752\n",
            "Epoch: 11 | Iteration: 106 | Classification loss: 0.09051 | Regression loss: 0.13836 | Running loss: 0.33712\n",
            "Epoch: 11 | Iteration: 107 | Classification loss: 0.01144 | Regression loss: 0.15382 | Running loss: 0.33655\n",
            "Epoch: 11 | Iteration: 108 | Classification loss: 0.07620 | Regression loss: 0.17656 | Running loss: 0.33612\n",
            "Epoch: 11 | Iteration: 109 | Classification loss: 0.03786 | Regression loss: 0.12664 | Running loss: 0.33550\n",
            "Epoch: 11 | Iteration: 110 | Classification loss: 0.15527 | Regression loss: 0.31361 | Running loss: 0.33554\n",
            "Epoch: 11 | Iteration: 111 | Classification loss: 0.13183 | Regression loss: 0.23422 | Running loss: 0.33582\n",
            "Epoch: 11 | Iteration: 112 | Classification loss: 0.01828 | Regression loss: 0.10676 | Running loss: 0.33503\n",
            "Epoch: 11 | Iteration: 113 | Classification loss: 0.09621 | Regression loss: 0.25062 | Running loss: 0.33517\n",
            "Epoch: 11 | Iteration: 114 | Classification loss: 0.12420 | Regression loss: 0.23065 | Running loss: 0.33518\n",
            "Epoch: 11 | Iteration: 115 | Classification loss: 0.12008 | Regression loss: 0.28176 | Running loss: 0.33501\n",
            "Epoch: 11 | Iteration: 116 | Classification loss: 0.10467 | Regression loss: 0.27327 | Running loss: 0.33502\n",
            "Epoch: 11 | Iteration: 117 | Classification loss: 0.11465 | Regression loss: 0.21292 | Running loss: 0.33491\n",
            "Epoch: 11 | Iteration: 118 | Classification loss: 0.15774 | Regression loss: 0.31992 | Running loss: 0.33515\n",
            "Epoch: 11 | Iteration: 119 | Classification loss: 0.08159 | Regression loss: 0.25210 | Running loss: 0.33510\n",
            "Epoch: 11 | Iteration: 120 | Classification loss: 0.13841 | Regression loss: 0.32426 | Running loss: 0.33534\n",
            "Epoch: 11 | Iteration: 121 | Classification loss: 0.06863 | Regression loss: 0.19149 | Running loss: 0.33536\n",
            "Epoch: 11 | Iteration: 122 | Classification loss: 0.07250 | Regression loss: 0.20736 | Running loss: 0.33506\n",
            "Epoch: 11 | Iteration: 123 | Classification loss: 0.02881 | Regression loss: 0.14192 | Running loss: 0.33475\n",
            "Epoch: 11 | Iteration: 124 | Classification loss: 0.07342 | Regression loss: 0.18997 | Running loss: 0.33459\n",
            "Epoch: 11 | Iteration: 125 | Classification loss: 0.14300 | Regression loss: 0.16702 | Running loss: 0.33465\n",
            "Epoch: 11 | Iteration: 126 | Classification loss: 0.11997 | Regression loss: 0.22104 | Running loss: 0.33424\n",
            "Epoch: 11 | Iteration: 127 | Classification loss: 0.12934 | Regression loss: 0.28002 | Running loss: 0.33408\n",
            "Epoch: 11 | Iteration: 128 | Classification loss: 0.12841 | Regression loss: 0.19550 | Running loss: 0.33430\n",
            "Epoch: 11 | Iteration: 129 | Classification loss: 0.05787 | Regression loss: 0.16662 | Running loss: 0.33416\n",
            "Epoch: 11 | Iteration: 130 | Classification loss: 0.02912 | Regression loss: 0.08469 | Running loss: 0.33392\n",
            "Epoch: 11 | Iteration: 131 | Classification loss: 0.20143 | Regression loss: 0.20398 | Running loss: 0.33401\n",
            "Epoch: 11 | Iteration: 132 | Classification loss: 0.05411 | Regression loss: 0.14545 | Running loss: 0.33382\n",
            "Epoch: 11 | Iteration: 133 | Classification loss: 0.08934 | Regression loss: 0.22380 | Running loss: 0.33392\n",
            "Epoch: 11 | Iteration: 134 | Classification loss: 0.06395 | Regression loss: 0.28176 | Running loss: 0.33438\n",
            "Epoch: 11 | Iteration: 135 | Classification loss: 0.05030 | Regression loss: 0.18547 | Running loss: 0.33394\n",
            "Epoch: 11 | Iteration: 136 | Classification loss: 0.13789 | Regression loss: 0.22354 | Running loss: 0.33431\n",
            "Epoch: 11 | Iteration: 137 | Classification loss: 0.13490 | Regression loss: 0.33962 | Running loss: 0.33473\n",
            "Epoch: 11 | Iteration: 138 | Classification loss: 0.11301 | Regression loss: 0.22053 | Running loss: 0.33467\n",
            "Epoch: 11 | Iteration: 139 | Classification loss: 0.16191 | Regression loss: 0.31868 | Running loss: 0.33523\n",
            "Epoch: 11 | Iteration: 140 | Classification loss: 0.15558 | Regression loss: 0.28204 | Running loss: 0.33554\n",
            "Epoch: 11 | Iteration: 141 | Classification loss: 0.14033 | Regression loss: 0.29906 | Running loss: 0.33568\n",
            "Epoch: 11 | Iteration: 142 | Classification loss: 0.04098 | Regression loss: 0.31257 | Running loss: 0.33594\n",
            "Epoch: 11 | Iteration: 143 | Classification loss: 0.16118 | Regression loss: 0.28505 | Running loss: 0.33610\n",
            "Epoch: 11 | Iteration: 144 | Classification loss: 0.08125 | Regression loss: 0.24007 | Running loss: 0.33609\n",
            "Epoch: 11 | Iteration: 145 | Classification loss: 0.06923 | Regression loss: 0.35079 | Running loss: 0.33653\n",
            "Epoch: 11 | Iteration: 146 | Classification loss: 0.09943 | Regression loss: 0.15266 | Running loss: 0.33583\n",
            "Epoch: 11 | Iteration: 147 | Classification loss: 0.02503 | Regression loss: 0.07793 | Running loss: 0.33569\n",
            "Epoch: 11 | Iteration: 148 | Classification loss: 0.06570 | Regression loss: 0.11921 | Running loss: 0.33520\n",
            "Epoch: 11 | Iteration: 149 | Classification loss: 0.04962 | Regression loss: 0.19231 | Running loss: 0.33483\n",
            "Epoch: 11 | Iteration: 150 | Classification loss: 0.02245 | Regression loss: 0.11161 | Running loss: 0.33410\n",
            "Epoch: 11 | Iteration: 151 | Classification loss: 0.09177 | Regression loss: 0.20111 | Running loss: 0.33426\n",
            "Epoch: 11 | Iteration: 152 | Classification loss: 0.11064 | Regression loss: 0.24952 | Running loss: 0.33397\n",
            "Epoch: 11 | Iteration: 153 | Classification loss: 0.22825 | Regression loss: 0.32641 | Running loss: 0.33413\n",
            "Epoch: 11 | Iteration: 154 | Classification loss: 0.16028 | Regression loss: 0.32577 | Running loss: 0.33403\n",
            "Epoch: 11 | Iteration: 155 | Classification loss: 0.13216 | Regression loss: 0.25353 | Running loss: 0.33413\n",
            "Epoch: 11 | Iteration: 156 | Classification loss: 0.11914 | Regression loss: 0.21431 | Running loss: 0.33386\n",
            "Epoch: 11 | Iteration: 157 | Classification loss: 0.03628 | Regression loss: 0.14124 | Running loss: 0.33342\n",
            "Epoch: 11 | Iteration: 158 | Classification loss: 0.14176 | Regression loss: 0.14979 | Running loss: 0.33339\n",
            "Epoch: 11 | Iteration: 159 | Classification loss: 0.10259 | Regression loss: 0.20868 | Running loss: 0.33335\n",
            "Epoch: 11 | Iteration: 160 | Classification loss: 0.08608 | Regression loss: 0.11154 | Running loss: 0.33278\n",
            "Epoch: 11 | Iteration: 161 | Classification loss: 0.05852 | Regression loss: 0.21332 | Running loss: 0.33274\n",
            "Epoch: 11 | Iteration: 162 | Classification loss: 0.03029 | Regression loss: 0.13524 | Running loss: 0.33274\n",
            "Epoch: 11 | Iteration: 163 | Classification loss: 0.03216 | Regression loss: 0.16117 | Running loss: 0.33277\n",
            "Epoch: 11 | Iteration: 164 | Classification loss: 0.01637 | Regression loss: 0.07968 | Running loss: 0.33223\n",
            "Epoch: 11 | Iteration: 165 | Classification loss: 0.07134 | Regression loss: 0.14351 | Running loss: 0.33169\n",
            "Epoch: 11 | Iteration: 166 | Classification loss: 0.03458 | Regression loss: 0.14658 | Running loss: 0.33141\n",
            "Epoch: 11 | Iteration: 167 | Classification loss: 0.13147 | Regression loss: 0.26913 | Running loss: 0.33144\n",
            "Epoch: 11 | Iteration: 168 | Classification loss: 0.06175 | Regression loss: 0.15850 | Running loss: 0.33130\n",
            "Epoch: 11 | Iteration: 169 | Classification loss: 0.08394 | Regression loss: 0.16774 | Running loss: 0.33155\n",
            "Epoch: 11 | Iteration: 170 | Classification loss: 0.05797 | Regression loss: 0.17296 | Running loss: 0.33116\n",
            "Epoch: 11 | Iteration: 171 | Classification loss: 0.12617 | Regression loss: 0.22192 | Running loss: 0.33112\n",
            "Epoch: 11 | Iteration: 172 | Classification loss: 0.16308 | Regression loss: 0.18865 | Running loss: 0.33086\n",
            "Epoch: 11 | Iteration: 173 | Classification loss: 0.13093 | Regression loss: 0.23055 | Running loss: 0.33075\n",
            "Epoch: 11 | Iteration: 174 | Classification loss: 0.18504 | Regression loss: 0.26807 | Running loss: 0.33097\n",
            "Epoch: 11 | Iteration: 175 | Classification loss: 0.16780 | Regression loss: 0.26013 | Running loss: 0.33154\n",
            "Epoch: 11 | Iteration: 176 | Classification loss: 0.04113 | Regression loss: 0.16783 | Running loss: 0.33142\n",
            "Epoch: 11 | Iteration: 177 | Classification loss: 0.09903 | Regression loss: 0.22908 | Running loss: 0.33154\n",
            "Epoch: 11 | Iteration: 178 | Classification loss: 0.09125 | Regression loss: 0.21059 | Running loss: 0.33198\n",
            "Epoch: 11 | Iteration: 179 | Classification loss: 0.12071 | Regression loss: 0.20324 | Running loss: 0.33211\n",
            "Epoch: 11 | Iteration: 180 | Classification loss: 0.08885 | Regression loss: 0.14168 | Running loss: 0.33165\n",
            "Epoch: 11 | Iteration: 181 | Classification loss: 0.07199 | Regression loss: 0.15606 | Running loss: 0.33193\n",
            "Epoch: 11 | Iteration: 182 | Classification loss: 0.07888 | Regression loss: 0.18765 | Running loss: 0.33204\n",
            "Epoch: 11 | Iteration: 183 | Classification loss: 0.09796 | Regression loss: 0.24570 | Running loss: 0.33210\n",
            "Epoch: 11 | Iteration: 184 | Classification loss: 0.08201 | Regression loss: 0.22152 | Running loss: 0.33207\n",
            "Epoch: 11 | Iteration: 185 | Classification loss: 0.14722 | Regression loss: 0.27419 | Running loss: 0.33215\n",
            "Epoch: 11 | Iteration: 186 | Classification loss: 0.03909 | Regression loss: 0.13132 | Running loss: 0.33162\n",
            "Epoch: 11 | Iteration: 187 | Classification loss: 0.05454 | Regression loss: 0.08569 | Running loss: 0.33105\n",
            "Epoch: 11 | Iteration: 188 | Classification loss: 0.04613 | Regression loss: 0.16917 | Running loss: 0.33129\n",
            "Epoch: 11 | Iteration: 189 | Classification loss: 0.12308 | Regression loss: 0.23254 | Running loss: 0.33159\n",
            "Epoch: 11 | Iteration: 190 | Classification loss: 0.09922 | Regression loss: 0.22008 | Running loss: 0.33163\n",
            "Epoch: 11 | Iteration: 191 | Classification loss: 0.03818 | Regression loss: 0.17884 | Running loss: 0.33149\n",
            "Epoch: 11 | Iteration: 192 | Classification loss: 0.14948 | Regression loss: 0.27104 | Running loss: 0.33182\n",
            "Epoch: 11 | Iteration: 193 | Classification loss: 0.23895 | Regression loss: 0.42512 | Running loss: 0.33247\n",
            "Epoch: 11 | Iteration: 194 | Classification loss: 0.02193 | Regression loss: 0.12979 | Running loss: 0.33176\n",
            "Epoch: 11 | Iteration: 195 | Classification loss: 0.09532 | Regression loss: 0.21068 | Running loss: 0.33178\n",
            "Epoch: 11 | Iteration: 196 | Classification loss: 0.12501 | Regression loss: 0.27890 | Running loss: 0.33161\n",
            "Epoch: 11 | Iteration: 197 | Classification loss: 0.14894 | Regression loss: 0.30089 | Running loss: 0.33159\n",
            "Epoch: 11 | Iteration: 198 | Classification loss: 0.07536 | Regression loss: 0.20244 | Running loss: 0.33171\n",
            "Epoch: 11 | Iteration: 199 | Classification loss: 0.04226 | Regression loss: 0.15254 | Running loss: 0.33127\n",
            "Epoch: 11 | Iteration: 200 | Classification loss: 0.08130 | Regression loss: 0.14551 | Running loss: 0.33072\n",
            "Epoch: 11 | Iteration: 201 | Classification loss: 0.09392 | Regression loss: 0.27520 | Running loss: 0.33045\n",
            "Epoch: 11 | Iteration: 202 | Classification loss: 0.15266 | Regression loss: 0.20789 | Running loss: 0.33070\n",
            "Epoch: 11 | Iteration: 203 | Classification loss: 0.08802 | Regression loss: 0.11248 | Running loss: 0.32993\n",
            "Epoch: 11 | Iteration: 204 | Classification loss: 0.13403 | Regression loss: 0.19183 | Running loss: 0.33013\n",
            "Epoch: 11 | Iteration: 205 | Classification loss: 0.05496 | Regression loss: 0.16227 | Running loss: 0.33004\n",
            "Epoch: 11 | Iteration: 206 | Classification loss: 0.07709 | Regression loss: 0.16261 | Running loss: 0.32969\n",
            "Epoch: 11 | Iteration: 207 | Classification loss: 0.03757 | Regression loss: 0.12468 | Running loss: 0.32948\n",
            "Epoch: 11 | Iteration: 208 | Classification loss: 0.10375 | Regression loss: 0.26861 | Running loss: 0.32928\n",
            "Epoch: 11 | Iteration: 209 | Classification loss: 0.11152 | Regression loss: 0.19611 | Running loss: 0.32910\n",
            "Epoch: 11 | Iteration: 210 | Classification loss: 0.07710 | Regression loss: 0.17550 | Running loss: 0.32911\n",
            "Epoch: 11 | Iteration: 211 | Classification loss: 0.07695 | Regression loss: 0.20516 | Running loss: 0.32894\n",
            "Epoch: 11 | Iteration: 212 | Classification loss: 0.09960 | Regression loss: 0.19794 | Running loss: 0.32888\n",
            "Epoch: 11 | Iteration: 213 | Classification loss: 0.11429 | Regression loss: 0.26799 | Running loss: 0.32905\n",
            "Epoch: 11 | Iteration: 214 | Classification loss: 0.05401 | Regression loss: 0.21346 | Running loss: 0.32896\n",
            "Epoch: 11 | Iteration: 215 | Classification loss: 0.28218 | Regression loss: 0.35413 | Running loss: 0.32925\n",
            "Epoch: 11 | Iteration: 216 | Classification loss: 0.16186 | Regression loss: 0.29414 | Running loss: 0.32976\n",
            "Epoch: 11 | Iteration: 217 | Classification loss: 0.20671 | Regression loss: 0.31439 | Running loss: 0.33041\n",
            "Epoch: 11 | Iteration: 218 | Classification loss: 0.17382 | Regression loss: 0.30881 | Running loss: 0.33041\n",
            "Epoch: 11 | Iteration: 219 | Classification loss: 0.03926 | Regression loss: 0.13276 | Running loss: 0.33028\n",
            "Epoch: 11 | Iteration: 220 | Classification loss: 0.01750 | Regression loss: 0.08584 | Running loss: 0.32996\n",
            "Epoch: 11 | Iteration: 221 | Classification loss: 0.17409 | Regression loss: 0.33471 | Running loss: 0.33073\n",
            "Epoch: 11 | Iteration: 222 | Classification loss: 0.06018 | Regression loss: 0.24614 | Running loss: 0.33105\n",
            "Epoch: 11 | Iteration: 223 | Classification loss: 0.02834 | Regression loss: 0.09178 | Running loss: 0.33037\n",
            "Epoch: 11 | Iteration: 224 | Classification loss: 0.13295 | Regression loss: 0.25213 | Running loss: 0.33079\n",
            "Epoch: 11 | Iteration: 225 | Classification loss: 0.10591 | Regression loss: 0.18187 | Running loss: 0.33095\n",
            "Epoch: 11 | Iteration: 226 | Classification loss: 0.10789 | Regression loss: 0.18588 | Running loss: 0.33039\n",
            "Epoch: 11 | Iteration: 227 | Classification loss: 0.06438 | Regression loss: 0.16518 | Running loss: 0.33023\n",
            "Epoch: 11 | Iteration: 228 | Classification loss: 0.15864 | Regression loss: 0.28792 | Running loss: 0.33051\n",
            "Epoch: 11 | Iteration: 229 | Classification loss: 0.13442 | Regression loss: 0.17816 | Running loss: 0.33015\n",
            "Epoch: 11 | Iteration: 230 | Classification loss: 0.16163 | Regression loss: 0.28765 | Running loss: 0.33023\n",
            "Epoch: 11 | Iteration: 231 | Classification loss: 0.12596 | Regression loss: 0.18692 | Running loss: 0.33034\n",
            "Epoch: 11 | Iteration: 232 | Classification loss: 0.13144 | Regression loss: 0.18730 | Running loss: 0.33036\n",
            "Epoch: 11 | Iteration: 233 | Classification loss: 0.21655 | Regression loss: 0.40617 | Running loss: 0.33096\n",
            "Epoch: 11 | Iteration: 234 | Classification loss: 0.16443 | Regression loss: 0.21684 | Running loss: 0.33148\n",
            "Epoch: 11 | Iteration: 235 | Classification loss: 0.25017 | Regression loss: 0.41038 | Running loss: 0.33212\n",
            "Epoch: 11 | Iteration: 236 | Classification loss: 0.05317 | Regression loss: 0.13354 | Running loss: 0.33198\n",
            "Epoch: 11 | Iteration: 237 | Classification loss: 0.12709 | Regression loss: 0.27770 | Running loss: 0.33234\n",
            "Epoch: 11 | Iteration: 238 | Classification loss: 0.12307 | Regression loss: 0.22771 | Running loss: 0.33207\n",
            "Epoch: 11 | Iteration: 239 | Classification loss: 0.05022 | Regression loss: 0.12982 | Running loss: 0.33148\n",
            "Epoch: 11 | Iteration: 240 | Classification loss: 0.14126 | Regression loss: 0.32865 | Running loss: 0.33138\n",
            "Epoch: 11 | Iteration: 241 | Classification loss: 0.05870 | Regression loss: 0.10695 | Running loss: 0.33128\n",
            "Epoch: 11 | Iteration: 242 | Classification loss: 0.15172 | Regression loss: 0.27130 | Running loss: 0.33157\n",
            "Epoch: 11 | Iteration: 243 | Classification loss: 0.05839 | Regression loss: 0.20494 | Running loss: 0.33137\n",
            "Epoch: 11 | Iteration: 244 | Classification loss: 0.10675 | Regression loss: 0.31655 | Running loss: 0.33167\n",
            "Epoch: 11 | Iteration: 245 | Classification loss: 0.25368 | Regression loss: 0.50218 | Running loss: 0.33246\n",
            "Epoch: 11 | Iteration: 246 | Classification loss: 0.03499 | Regression loss: 0.10930 | Running loss: 0.33198\n",
            "Epoch: 11 | Iteration: 247 | Classification loss: 0.06523 | Regression loss: 0.09107 | Running loss: 0.33158\n",
            "Epoch: 11 | Iteration: 248 | Classification loss: 0.07181 | Regression loss: 0.23695 | Running loss: 0.33118\n",
            "Epoch: 11 | Iteration: 249 | Classification loss: 0.04619 | Regression loss: 0.16705 | Running loss: 0.33109\n",
            "Epoch: 11 | Iteration: 250 | Classification loss: 0.06391 | Regression loss: 0.15025 | Running loss: 0.33097\n",
            "Epoch: 11 | Iteration: 251 | Classification loss: 0.05044 | Regression loss: 0.14139 | Running loss: 0.33068\n",
            "Epoch: 11 | Iteration: 252 | Classification loss: 0.12789 | Regression loss: 0.23894 | Running loss: 0.33093\n",
            "Epoch: 11 | Iteration: 253 | Classification loss: 0.10815 | Regression loss: 0.13228 | Running loss: 0.33088\n",
            "Epoch: 11 | Iteration: 254 | Classification loss: 0.12170 | Regression loss: 0.20960 | Running loss: 0.33103\n",
            "Epoch: 11 | Iteration: 255 | Classification loss: 0.06548 | Regression loss: 0.14045 | Running loss: 0.33015\n",
            "Epoch: 11 | Iteration: 256 | Classification loss: 0.14096 | Regression loss: 0.14034 | Running loss: 0.33013\n",
            "Epoch: 11 | Iteration: 257 | Classification loss: 0.07215 | Regression loss: 0.15569 | Running loss: 0.32971\n",
            "Epoch: 11 | Iteration: 258 | Classification loss: 0.05399 | Regression loss: 0.13238 | Running loss: 0.32941\n",
            "Epoch: 11 | Iteration: 259 | Classification loss: 0.15629 | Regression loss: 0.34358 | Running loss: 0.32977\n",
            "Epoch: 11 | Iteration: 260 | Classification loss: 0.23232 | Regression loss: 0.31940 | Running loss: 0.33048\n",
            "Epoch: 11 | Iteration: 261 | Classification loss: 0.08970 | Regression loss: 0.14295 | Running loss: 0.33065\n",
            "Epoch: 11 | Iteration: 262 | Classification loss: 0.08519 | Regression loss: 0.11510 | Running loss: 0.33022\n",
            "Epoch: 11 | Iteration: 263 | Classification loss: 0.13802 | Regression loss: 0.19064 | Running loss: 0.33009\n",
            "Epoch: 11 | Iteration: 264 | Classification loss: 0.08164 | Regression loss: 0.17232 | Running loss: 0.32993\n",
            "Epoch: 11 | Iteration: 265 | Classification loss: 0.16618 | Regression loss: 0.29303 | Running loss: 0.32991\n",
            "Epoch: 11 | Iteration: 266 | Classification loss: 0.09502 | Regression loss: 0.26202 | Running loss: 0.33032\n",
            "Epoch: 11 | Iteration: 267 | Classification loss: 0.08047 | Regression loss: 0.20845 | Running loss: 0.33043\n",
            "Epoch: 11 | Iteration: 268 | Classification loss: 0.10087 | Regression loss: 0.20405 | Running loss: 0.33024\n",
            "Epoch: 11 | Iteration: 269 | Classification loss: 0.16498 | Regression loss: 0.42715 | Running loss: 0.33085\n",
            "Epoch: 11 | Iteration: 270 | Classification loss: 0.02689 | Regression loss: 0.17817 | Running loss: 0.33080\n",
            "Epoch: 11 | Iteration: 271 | Classification loss: 0.10012 | Regression loss: 0.19982 | Running loss: 0.33088\n",
            "Epoch: 11 | Iteration: 272 | Classification loss: 0.30247 | Regression loss: 0.46616 | Running loss: 0.33194\n",
            "Epoch: 11 | Iteration: 273 | Classification loss: 0.07145 | Regression loss: 0.13659 | Running loss: 0.33217\n",
            "Epoch: 11 | Iteration: 274 | Classification loss: 0.03840 | Regression loss: 0.24355 | Running loss: 0.33166\n",
            "Epoch: 11 | Iteration: 275 | Classification loss: 0.08412 | Regression loss: 0.19238 | Running loss: 0.33123\n",
            "Epoch: 11 | Iteration: 276 | Classification loss: 0.13849 | Regression loss: 0.31075 | Running loss: 0.33126\n",
            "Epoch: 11 | Iteration: 277 | Classification loss: 0.06403 | Regression loss: 0.21833 | Running loss: 0.33129\n",
            "Epoch: 11 | Iteration: 278 | Classification loss: 0.06635 | Regression loss: 0.19324 | Running loss: 0.33127\n",
            "Epoch: 11 | Iteration: 279 | Classification loss: 0.15854 | Regression loss: 0.28384 | Running loss: 0.33164\n",
            "Epoch: 11 | Iteration: 280 | Classification loss: 0.11728 | Regression loss: 0.19425 | Running loss: 0.33182\n",
            "Epoch: 11 | Iteration: 281 | Classification loss: 0.12743 | Regression loss: 0.12437 | Running loss: 0.33153\n",
            "Epoch: 11 | Iteration: 282 | Classification loss: 0.07204 | Regression loss: 0.17418 | Running loss: 0.33041\n",
            "Epoch: 11 | Iteration: 283 | Classification loss: 0.09925 | Regression loss: 0.26019 | Running loss: 0.33033\n",
            "Epoch: 11 | Iteration: 284 | Classification loss: 0.08504 | Regression loss: 0.21153 | Running loss: 0.33023\n",
            "Epoch: 11 | Iteration: 285 | Classification loss: 0.07777 | Regression loss: 0.19380 | Running loss: 0.33026\n",
            "Epoch: 11 | Iteration: 286 | Classification loss: 0.09505 | Regression loss: 0.26626 | Running loss: 0.33033\n",
            "Epoch: 11 | Iteration: 287 | Classification loss: 0.12664 | Regression loss: 0.25852 | Running loss: 0.33031\n",
            "Epoch: 11 | Iteration: 288 | Classification loss: 0.06918 | Regression loss: 0.22327 | Running loss: 0.33053\n",
            "Epoch: 11 | Iteration: 289 | Classification loss: 0.10476 | Regression loss: 0.13146 | Running loss: 0.33042\n",
            "Epoch: 11 | Iteration: 290 | Classification loss: 0.13863 | Regression loss: 0.24319 | Running loss: 0.33051\n",
            "Epoch: 11 | Iteration: 291 | Classification loss: 0.06928 | Regression loss: 0.15843 | Running loss: 0.33019\n",
            "Epoch: 11 | Iteration: 292 | Classification loss: 0.07406 | Regression loss: 0.15018 | Running loss: 0.32947\n",
            "Epoch: 11 | Iteration: 293 | Classification loss: 0.06220 | Regression loss: 0.19716 | Running loss: 0.32923\n",
            "Epoch: 11 | Iteration: 294 | Classification loss: 0.22480 | Regression loss: 0.24949 | Running loss: 0.32978\n",
            "Epoch: 11 | Iteration: 295 | Classification loss: 0.16162 | Regression loss: 0.28433 | Running loss: 0.32998\n",
            "Epoch: 11 | Iteration: 296 | Classification loss: 0.14560 | Regression loss: 0.22535 | Running loss: 0.33014\n",
            "Epoch: 11 | Iteration: 297 | Classification loss: 0.06499 | Regression loss: 0.18036 | Running loss: 0.33020\n",
            "Epoch: 11 | Iteration: 298 | Classification loss: 0.13665 | Regression loss: 0.22209 | Running loss: 0.33039\n",
            "Epoch: 11 | Iteration: 299 | Classification loss: 0.05271 | Regression loss: 0.10320 | Running loss: 0.32992\n",
            "Epoch: 11 | Iteration: 300 | Classification loss: 0.05749 | Regression loss: 0.18896 | Running loss: 0.32970\n",
            "Epoch: 11 | Iteration: 301 | Classification loss: 0.06677 | Regression loss: 0.17372 | Running loss: 0.32979\n",
            "Epoch: 11 | Iteration: 302 | Classification loss: 0.07027 | Regression loss: 0.12178 | Running loss: 0.32946\n",
            "Epoch: 11 | Iteration: 303 | Classification loss: 0.06262 | Regression loss: 0.21191 | Running loss: 0.32905\n",
            "Epoch: 11 | Iteration: 304 | Classification loss: 0.10944 | Regression loss: 0.24637 | Running loss: 0.32899\n",
            "Epoch: 11 | Iteration: 305 | Classification loss: 0.07920 | Regression loss: 0.15315 | Running loss: 0.32854\n",
            "Epoch: 11 | Iteration: 306 | Classification loss: 0.13284 | Regression loss: 0.17553 | Running loss: 0.32835\n",
            "Epoch: 11 | Iteration: 307 | Classification loss: 0.05256 | Regression loss: 0.15472 | Running loss: 0.32840\n",
            "Epoch: 11 | Iteration: 308 | Classification loss: 0.06583 | Regression loss: 0.15552 | Running loss: 0.32775\n",
            "Epoch: 11 | Iteration: 309 | Classification loss: 0.12572 | Regression loss: 0.28289 | Running loss: 0.32764\n",
            "Epoch: 11 | Iteration: 310 | Classification loss: 0.06800 | Regression loss: 0.16940 | Running loss: 0.32691\n",
            "Epoch: 11 | Iteration: 311 | Classification loss: 0.09259 | Regression loss: 0.21337 | Running loss: 0.32721\n",
            "Epoch: 11 | Iteration: 312 | Classification loss: 0.05498 | Regression loss: 0.14834 | Running loss: 0.32717\n",
            "Epoch: 11 | Iteration: 313 | Classification loss: 0.05492 | Regression loss: 0.14351 | Running loss: 0.32675\n",
            "Epoch: 11 | Iteration: 314 | Classification loss: 0.04847 | Regression loss: 0.16537 | Running loss: 0.32631\n",
            "Epoch: 11 | Iteration: 315 | Classification loss: 0.06978 | Regression loss: 0.18576 | Running loss: 0.32659\n",
            "Epoch: 11 | Iteration: 316 | Classification loss: 0.03120 | Regression loss: 0.09221 | Running loss: 0.32557\n",
            "Epoch: 11 | Iteration: 317 | Classification loss: 0.12874 | Regression loss: 0.23788 | Running loss: 0.32589\n",
            "Epoch: 11 | Iteration: 318 | Classification loss: 0.04061 | Regression loss: 0.10155 | Running loss: 0.32574\n",
            "Epoch: 11 | Iteration: 319 | Classification loss: 0.05941 | Regression loss: 0.12651 | Running loss: 0.32502\n",
            "Epoch: 11 | Iteration: 320 | Classification loss: 0.08709 | Regression loss: 0.23538 | Running loss: 0.32493\n",
            "Epoch: 11 | Iteration: 321 | Classification loss: 0.03778 | Regression loss: 0.11908 | Running loss: 0.32475\n",
            "Epoch: 11 | Iteration: 322 | Classification loss: 0.12950 | Regression loss: 0.27839 | Running loss: 0.32467\n",
            "Epoch: 11 | Iteration: 323 | Classification loss: 0.06277 | Regression loss: 0.15275 | Running loss: 0.32410\n",
            "Epoch: 11 | Iteration: 324 | Classification loss: 0.09023 | Regression loss: 0.13368 | Running loss: 0.32362\n",
            "Epoch: 11 | Iteration: 325 | Classification loss: 0.10269 | Regression loss: 0.23201 | Running loss: 0.32375\n",
            "Epoch: 11 | Iteration: 326 | Classification loss: 0.08266 | Regression loss: 0.24306 | Running loss: 0.32327\n",
            "Epoch: 11 | Iteration: 327 | Classification loss: 0.15480 | Regression loss: 0.22787 | Running loss: 0.32323\n",
            "Epoch: 11 | Iteration: 328 | Classification loss: 0.06960 | Regression loss: 0.18761 | Running loss: 0.32322\n",
            "Epoch: 11 | Iteration: 329 | Classification loss: 0.06976 | Regression loss: 0.21088 | Running loss: 0.32291\n",
            "Epoch: 11 | Iteration: 330 | Classification loss: 0.19547 | Regression loss: 0.25208 | Running loss: 0.32337\n",
            "Epoch: 11 | Iteration: 331 | Classification loss: 0.21366 | Regression loss: 0.41283 | Running loss: 0.32409\n",
            "Epoch: 11 | Iteration: 332 | Classification loss: 0.03326 | Regression loss: 0.12794 | Running loss: 0.32399\n",
            "Epoch: 11 | Iteration: 333 | Classification loss: 0.13812 | Regression loss: 0.16478 | Running loss: 0.32419\n",
            "Epoch: 11 | Iteration: 334 | Classification loss: 0.09165 | Regression loss: 0.15989 | Running loss: 0.32461\n",
            "Epoch: 11 | Iteration: 335 | Classification loss: 0.27726 | Regression loss: 0.38850 | Running loss: 0.32547\n",
            "Epoch: 11 | Iteration: 336 | Classification loss: 0.11250 | Regression loss: 0.18592 | Running loss: 0.32576\n",
            "Epoch: 11 | Iteration: 337 | Classification loss: 0.14360 | Regression loss: 0.23715 | Running loss: 0.32564\n",
            "Epoch: 11 | Iteration: 338 | Classification loss: 0.09203 | Regression loss: 0.23687 | Running loss: 0.32542\n",
            "Epoch: 11 | Iteration: 339 | Classification loss: 0.05140 | Regression loss: 0.17507 | Running loss: 0.32524\n",
            "Epoch: 11 | Iteration: 340 | Classification loss: 0.05025 | Regression loss: 0.16712 | Running loss: 0.32492\n",
            "Epoch: 11 | Iteration: 341 | Classification loss: 0.11063 | Regression loss: 0.32803 | Running loss: 0.32458\n",
            "Epoch: 11 | Iteration: 342 | Classification loss: 0.07878 | Regression loss: 0.18817 | Running loss: 0.32461\n",
            "Epoch: 11 | Iteration: 343 | Classification loss: 0.14731 | Regression loss: 0.39693 | Running loss: 0.32510\n",
            "Epoch: 11 | Iteration: 344 | Classification loss: 0.08346 | Regression loss: 0.21927 | Running loss: 0.32512\n",
            "Epoch: 11 | Iteration: 345 | Classification loss: 0.12014 | Regression loss: 0.17258 | Running loss: 0.32525\n",
            "Epoch: 11 | Iteration: 346 | Classification loss: 0.04587 | Regression loss: 0.20942 | Running loss: 0.32507\n",
            "Epoch: 11 | Iteration: 347 | Classification loss: 0.04115 | Regression loss: 0.19241 | Running loss: 0.32505\n",
            "Epoch: 11 | Iteration: 348 | Classification loss: 0.04073 | Regression loss: 0.15276 | Running loss: 0.32403\n",
            "Epoch: 11 | Iteration: 349 | Classification loss: 0.02152 | Regression loss: 0.12742 | Running loss: 0.32360\n",
            "Epoch: 11 | Iteration: 350 | Classification loss: 0.13992 | Regression loss: 0.29487 | Running loss: 0.32405\n",
            "Epoch: 11 | Iteration: 351 | Classification loss: 0.02408 | Regression loss: 0.11953 | Running loss: 0.32347\n",
            "Epoch: 11 | Iteration: 352 | Classification loss: 0.04508 | Regression loss: 0.16453 | Running loss: 0.32305\n",
            "Epoch: 11 | Iteration: 353 | Classification loss: 0.09275 | Regression loss: 0.24114 | Running loss: 0.32308\n",
            "Epoch: 11 | Iteration: 354 | Classification loss: 0.15024 | Regression loss: 0.23004 | Running loss: 0.32284\n",
            "Epoch: 11 | Iteration: 355 | Classification loss: 0.14683 | Regression loss: 0.21191 | Running loss: 0.32265\n",
            "Epoch: 11 | Iteration: 356 | Classification loss: 0.03888 | Regression loss: 0.13005 | Running loss: 0.32227\n",
            "Epoch: 11 | Iteration: 357 | Classification loss: 0.06356 | Regression loss: 0.15404 | Running loss: 0.32207\n",
            "Epoch: 11 | Iteration: 358 | Classification loss: 0.06316 | Regression loss: 0.14066 | Running loss: 0.32141\n",
            "Epoch: 11 | Iteration: 359 | Classification loss: 0.12191 | Regression loss: 0.31372 | Running loss: 0.32185\n",
            "Epoch: 11 | Iteration: 360 | Classification loss: 0.16853 | Regression loss: 0.32958 | Running loss: 0.32191\n",
            "Epoch: 11 | Iteration: 361 | Classification loss: 0.30170 | Regression loss: 0.47529 | Running loss: 0.32308\n",
            "Epoch: 11 | Iteration: 362 | Classification loss: 0.06377 | Regression loss: 0.14308 | Running loss: 0.32275\n",
            "Epoch: 11 | Iteration: 363 | Classification loss: 0.10154 | Regression loss: 0.28625 | Running loss: 0.32291\n",
            "Epoch: 11 | Iteration: 364 | Classification loss: 0.08349 | Regression loss: 0.15562 | Running loss: 0.32258\n",
            "Epoch: 11 | Iteration: 365 | Classification loss: 0.05501 | Regression loss: 0.20041 | Running loss: 0.32230\n",
            "Epoch: 11 | Iteration: 366 | Classification loss: 0.11674 | Regression loss: 0.24247 | Running loss: 0.32246\n",
            "Epoch: 11 | Iteration: 367 | Classification loss: 0.04512 | Regression loss: 0.15186 | Running loss: 0.32231\n",
            "Epoch: 11 | Iteration: 368 | Classification loss: 0.07209 | Regression loss: 0.13956 | Running loss: 0.32210\n",
            "Epoch: 11 | Iteration: 369 | Classification loss: 0.11167 | Regression loss: 0.22387 | Running loss: 0.32222\n",
            "Epoch: 11 | Iteration: 370 | Classification loss: 0.06049 | Regression loss: 0.19157 | Running loss: 0.32232\n",
            "Epoch: 11 | Iteration: 371 | Classification loss: 0.12736 | Regression loss: 0.27368 | Running loss: 0.32263\n",
            "Epoch: 11 | Iteration: 372 | Classification loss: 0.12196 | Regression loss: 0.29026 | Running loss: 0.32319\n",
            "Epoch: 11 | Iteration: 373 | Classification loss: 0.04970 | Regression loss: 0.17481 | Running loss: 0.32310\n",
            "Epoch: 11 | Iteration: 374 | Classification loss: 0.09086 | Regression loss: 0.15670 | Running loss: 0.32297\n",
            "Epoch: 11 | Iteration: 375 | Classification loss: 0.18861 | Regression loss: 0.33022 | Running loss: 0.32361\n",
            "Epoch: 11 | Iteration: 376 | Classification loss: 0.11670 | Regression loss: 0.23268 | Running loss: 0.32389\n",
            "Epoch: 11 | Iteration: 377 | Classification loss: 0.17447 | Regression loss: 0.37236 | Running loss: 0.32461\n",
            "Epoch: 11 | Iteration: 378 | Classification loss: 0.16185 | Regression loss: 0.30258 | Running loss: 0.32488\n",
            "Epoch: 11 | Iteration: 379 | Classification loss: 0.10555 | Regression loss: 0.25753 | Running loss: 0.32513\n",
            "Epoch: 11 | Iteration: 380 | Classification loss: 0.08274 | Regression loss: 0.29076 | Running loss: 0.32456\n",
            "Epoch: 11 | Iteration: 381 | Classification loss: 0.06551 | Regression loss: 0.14610 | Running loss: 0.32409\n",
            "Epoch: 11 | Iteration: 382 | Classification loss: 0.04965 | Regression loss: 0.16456 | Running loss: 0.32395\n",
            "Epoch: 11 | Iteration: 383 | Classification loss: 0.10181 | Regression loss: 0.30795 | Running loss: 0.32385\n",
            "Epoch: 11 | Iteration: 384 | Classification loss: 0.11991 | Regression loss: 0.29195 | Running loss: 0.32402\n",
            "Epoch: 11 | Iteration: 385 | Classification loss: 0.05072 | Regression loss: 0.13828 | Running loss: 0.32384\n",
            "Epoch: 11 | Iteration: 386 | Classification loss: 0.07732 | Regression loss: 0.22234 | Running loss: 0.32350\n",
            "Epoch: 11 | Iteration: 387 | Classification loss: 0.13392 | Regression loss: 0.25264 | Running loss: 0.32350\n",
            "Epoch: 11 | Iteration: 388 | Classification loss: 0.08749 | Regression loss: 0.21624 | Running loss: 0.32374\n",
            "Epoch: 11 | Iteration: 389 | Classification loss: 0.15607 | Regression loss: 0.32253 | Running loss: 0.32391\n",
            "Epoch: 11 | Iteration: 390 | Classification loss: 0.05730 | Regression loss: 0.18263 | Running loss: 0.32378\n",
            "Epoch: 11 | Iteration: 391 | Classification loss: 0.08174 | Regression loss: 0.17968 | Running loss: 0.32349\n",
            "Epoch: 11 | Iteration: 392 | Classification loss: 0.15784 | Regression loss: 0.24494 | Running loss: 0.32385\n",
            "Epoch: 11 | Iteration: 393 | Classification loss: 0.13063 | Regression loss: 0.24438 | Running loss: 0.32406\n",
            "Epoch: 11 | Iteration: 394 | Classification loss: 0.22928 | Regression loss: 0.37679 | Running loss: 0.32459\n",
            "Epoch: 11 | Iteration: 395 | Classification loss: 0.08114 | Regression loss: 0.27012 | Running loss: 0.32455\n",
            "Epoch: 11 | Iteration: 396 | Classification loss: 0.04343 | Regression loss: 0.17193 | Running loss: 0.32422\n",
            "Epoch: 11 | Iteration: 397 | Classification loss: 0.05727 | Regression loss: 0.16206 | Running loss: 0.32385\n",
            "Epoch: 11 | Iteration: 398 | Classification loss: 0.28256 | Regression loss: 0.33652 | Running loss: 0.32462\n",
            "Epoch: 11 | Iteration: 399 | Classification loss: 0.10849 | Regression loss: 0.25185 | Running loss: 0.32456\n",
            "Epoch: 11 | Iteration: 400 | Classification loss: 0.27584 | Regression loss: 0.36055 | Running loss: 0.32501\n",
            "Epoch: 11 | Iteration: 401 | Classification loss: 0.06999 | Regression loss: 0.10400 | Running loss: 0.32499\n",
            "Epoch: 11 | Iteration: 402 | Classification loss: 0.13864 | Regression loss: 0.32459 | Running loss: 0.32562\n",
            "Epoch: 11 | Iteration: 403 | Classification loss: 0.13719 | Regression loss: 0.31080 | Running loss: 0.32568\n",
            "Epoch: 11 | Iteration: 404 | Classification loss: 0.06829 | Regression loss: 0.12038 | Running loss: 0.32520\n",
            "Epoch: 11 | Iteration: 405 | Classification loss: 0.19375 | Regression loss: 0.25887 | Running loss: 0.32509\n",
            "Epoch: 11 | Iteration: 406 | Classification loss: 0.04240 | Regression loss: 0.14912 | Running loss: 0.32506\n",
            "Epoch: 11 | Iteration: 407 | Classification loss: 0.15822 | Regression loss: 0.26837 | Running loss: 0.32494\n",
            "Epoch: 11 | Iteration: 408 | Classification loss: 0.04862 | Regression loss: 0.12012 | Running loss: 0.32457\n",
            "Epoch: 11 | Iteration: 409 | Classification loss: 0.02379 | Regression loss: 0.14728 | Running loss: 0.32412\n",
            "Epoch: 11 | Iteration: 410 | Classification loss: 0.07158 | Regression loss: 0.15638 | Running loss: 0.32423\n",
            "Epoch: 11 | Iteration: 411 | Classification loss: 0.03961 | Regression loss: 0.18975 | Running loss: 0.32393\n",
            "Epoch: 11 | Iteration: 412 | Classification loss: 0.17041 | Regression loss: 0.29195 | Running loss: 0.32427\n",
            "Epoch: 11 | Iteration: 413 | Classification loss: 0.05718 | Regression loss: 0.18191 | Running loss: 0.32360\n",
            "Epoch: 11 | Iteration: 414 | Classification loss: 0.05559 | Regression loss: 0.16153 | Running loss: 0.32354\n",
            "Epoch: 11 | Iteration: 415 | Classification loss: 0.07051 | Regression loss: 0.19755 | Running loss: 0.32353\n",
            "Epoch: 11 | Iteration: 416 | Classification loss: 0.05468 | Regression loss: 0.18491 | Running loss: 0.32311\n",
            "Epoch: 11 | Iteration: 417 | Classification loss: 0.15154 | Regression loss: 0.37189 | Running loss: 0.32356\n",
            "Epoch: 11 | Iteration: 418 | Classification loss: 0.09243 | Regression loss: 0.13534 | Running loss: 0.32381\n",
            "Epoch: 11 | Iteration: 419 | Classification loss: 0.05763 | Regression loss: 0.18587 | Running loss: 0.32356\n",
            "Epoch: 11 | Iteration: 420 | Classification loss: 0.08078 | Regression loss: 0.21017 | Running loss: 0.32306\n",
            "Epoch: 11 | Iteration: 421 | Classification loss: 0.13804 | Regression loss: 0.31498 | Running loss: 0.32313\n",
            "Epoch: 11 | Iteration: 422 | Classification loss: 0.08782 | Regression loss: 0.23504 | Running loss: 0.32291\n",
            "Epoch: 11 | Iteration: 423 | Classification loss: 0.04979 | Regression loss: 0.15602 | Running loss: 0.32202\n",
            "Epoch: 11 | Iteration: 424 | Classification loss: 0.04711 | Regression loss: 0.17923 | Running loss: 0.32186\n",
            "Epoch: 11 | Iteration: 425 | Classification loss: 0.11047 | Regression loss: 0.23723 | Running loss: 0.32197\n",
            "Epoch: 11 | Iteration: 426 | Classification loss: 0.02886 | Regression loss: 0.09468 | Running loss: 0.32185\n",
            "Epoch: 11 | Iteration: 427 | Classification loss: 0.06657 | Regression loss: 0.13522 | Running loss: 0.32132\n",
            "Epoch: 11 | Iteration: 428 | Classification loss: 0.20923 | Regression loss: 0.46214 | Running loss: 0.32221\n",
            "Epoch: 11 | Iteration: 429 | Classification loss: 0.04945 | Regression loss: 0.16823 | Running loss: 0.32163\n",
            "Epoch: 11 | Iteration: 430 | Classification loss: 0.14176 | Regression loss: 0.32061 | Running loss: 0.32205\n",
            "Epoch: 11 | Iteration: 431 | Classification loss: 0.10302 | Regression loss: 0.19825 | Running loss: 0.32162\n",
            "Epoch: 11 | Iteration: 432 | Classification loss: 0.21572 | Regression loss: 0.26146 | Running loss: 0.32196\n",
            "Epoch: 11 | Iteration: 433 | Classification loss: 0.06879 | Regression loss: 0.21532 | Running loss: 0.32208\n",
            "Epoch: 11 | Iteration: 434 | Classification loss: 0.02461 | Regression loss: 0.12958 | Running loss: 0.32200\n",
            "Epoch: 11 | Iteration: 435 | Classification loss: 0.04493 | Regression loss: 0.17648 | Running loss: 0.32141\n",
            "Epoch: 11 | Iteration: 436 | Classification loss: 0.07723 | Regression loss: 0.26236 | Running loss: 0.32119\n",
            "Epoch: 11 | Iteration: 437 | Classification loss: 0.10009 | Regression loss: 0.31897 | Running loss: 0.32137\n",
            "Epoch: 11 | Iteration: 438 | Classification loss: 0.10513 | Regression loss: 0.22462 | Running loss: 0.32099\n",
            "Epoch: 11 | Iteration: 439 | Classification loss: 0.06483 | Regression loss: 0.15002 | Running loss: 0.32063\n",
            "Epoch: 11 | Iteration: 440 | Classification loss: 0.11593 | Regression loss: 0.22673 | Running loss: 0.32087\n",
            "Epoch: 11 | Iteration: 441 | Classification loss: 0.04933 | Regression loss: 0.19267 | Running loss: 0.32043\n",
            "Epoch: 11 | Iteration: 442 | Classification loss: 0.07582 | Regression loss: 0.12147 | Running loss: 0.31892\n",
            "Epoch: 11 | Iteration: 443 | Classification loss: 0.11354 | Regression loss: 0.20009 | Running loss: 0.31815\n",
            "Epoch: 11 | Iteration: 444 | Classification loss: 0.08308 | Regression loss: 0.13352 | Running loss: 0.31800\n",
            "Epoch: 11 | Iteration: 445 | Classification loss: 0.02925 | Regression loss: 0.12568 | Running loss: 0.31760\n",
            "Epoch: 11 | Iteration: 446 | Classification loss: 0.22712 | Regression loss: 0.41657 | Running loss: 0.31820\n",
            "Epoch: 11 | Iteration: 447 | Classification loss: 0.11457 | Regression loss: 0.18591 | Running loss: 0.31818\n",
            "Epoch: 11 | Iteration: 448 | Classification loss: 0.08734 | Regression loss: 0.21894 | Running loss: 0.31850\n",
            "Epoch: 11 | Iteration: 449 | Classification loss: 0.07720 | Regression loss: 0.29764 | Running loss: 0.31817\n",
            "Epoch: 11 | Iteration: 450 | Classification loss: 0.05194 | Regression loss: 0.17816 | Running loss: 0.31767\n",
            "Epoch: 11 | Iteration: 451 | Classification loss: 0.14020 | Regression loss: 0.24596 | Running loss: 0.31731\n",
            "Epoch: 11 | Iteration: 452 | Classification loss: 0.07157 | Regression loss: 0.08675 | Running loss: 0.31743\n",
            "Epoch: 11 | Iteration: 453 | Classification loss: 0.03875 | Regression loss: 0.10003 | Running loss: 0.31695\n",
            "Epoch: 11 | Iteration: 454 | Classification loss: 0.09651 | Regression loss: 0.19827 | Running loss: 0.31701\n",
            "Epoch: 11 | Iteration: 455 | Classification loss: 0.10378 | Regression loss: 0.22050 | Running loss: 0.31723\n",
            "Epoch: 11 | Iteration: 456 | Classification loss: 0.10917 | Regression loss: 0.15963 | Running loss: 0.31688\n",
            "Epoch: 11 | Iteration: 457 | Classification loss: 0.05175 | Regression loss: 0.12786 | Running loss: 0.31614\n",
            "Epoch: 11 | Iteration: 458 | Classification loss: 0.09976 | Regression loss: 0.22011 | Running loss: 0.31621\n",
            "Epoch: 11 | Iteration: 459 | Classification loss: 0.12680 | Regression loss: 0.26363 | Running loss: 0.31625\n",
            "Epoch: 11 | Iteration: 460 | Classification loss: 0.04160 | Regression loss: 0.09550 | Running loss: 0.31606\n",
            "Epoch: 11 | Iteration: 461 | Classification loss: 0.10269 | Regression loss: 0.25739 | Running loss: 0.31594\n",
            "Epoch: 11 | Iteration: 462 | Classification loss: 0.03081 | Regression loss: 0.11420 | Running loss: 0.31566\n",
            "Epoch: 11 | Iteration: 463 | Classification loss: 0.05679 | Regression loss: 0.12359 | Running loss: 0.31514\n",
            "Epoch: 11 | Iteration: 464 | Classification loss: 0.07039 | Regression loss: 0.19239 | Running loss: 0.31495\n",
            "Epoch: 11 | Iteration: 465 | Classification loss: 0.03942 | Regression loss: 0.19213 | Running loss: 0.31480\n",
            "Epoch: 11 | Iteration: 466 | Classification loss: 0.03927 | Regression loss: 0.12256 | Running loss: 0.31440\n",
            "Epoch: 11 | Iteration: 467 | Classification loss: 0.12136 | Regression loss: 0.15217 | Running loss: 0.31392\n",
            "Epoch: 11 | Iteration: 468 | Classification loss: 0.09390 | Regression loss: 0.26384 | Running loss: 0.31393\n",
            "Epoch: 11 | Iteration: 469 | Classification loss: 0.24942 | Regression loss: 0.48008 | Running loss: 0.31477\n",
            "Epoch: 11 | Iteration: 470 | Classification loss: 0.07893 | Regression loss: 0.23587 | Running loss: 0.31437\n",
            "Epoch: 11 | Iteration: 471 | Classification loss: 0.15577 | Regression loss: 0.31680 | Running loss: 0.31435\n",
            "Epoch: 11 | Iteration: 472 | Classification loss: 0.14498 | Regression loss: 0.38139 | Running loss: 0.31424\n",
            "Epoch: 11 | Iteration: 473 | Classification loss: 0.06473 | Regression loss: 0.22233 | Running loss: 0.31437\n",
            "Epoch: 11 | Iteration: 474 | Classification loss: 0.08680 | Regression loss: 0.13552 | Running loss: 0.31421\n",
            "Epoch: 11 | Iteration: 475 | Classification loss: 0.14977 | Regression loss: 0.34430 | Running loss: 0.31476\n",
            "Epoch: 11 | Iteration: 476 | Classification loss: 0.10715 | Regression loss: 0.23302 | Running loss: 0.31432\n",
            "Epoch: 11 | Iteration: 477 | Classification loss: 0.19775 | Regression loss: 0.23745 | Running loss: 0.31399\n",
            "Epoch: 11 | Iteration: 478 | Classification loss: 0.12509 | Regression loss: 0.25917 | Running loss: 0.31387\n",
            "Epoch: 11 | Iteration: 479 | Classification loss: 0.10648 | Regression loss: 0.28514 | Running loss: 0.31394\n",
            "Epoch: 11 | Iteration: 480 | Classification loss: 0.06910 | Regression loss: 0.16386 | Running loss: 0.31391\n",
            "Epoch: 11 | Iteration: 481 | Classification loss: 0.08298 | Regression loss: 0.23294 | Running loss: 0.31418\n",
            "Epoch: 11 | Iteration: 482 | Classification loss: 0.10994 | Regression loss: 0.23656 | Running loss: 0.31418\n",
            "Epoch: 11 | Iteration: 483 | Classification loss: 0.06697 | Regression loss: 0.13245 | Running loss: 0.31393\n",
            "Epoch: 11 | Iteration: 484 | Classification loss: 0.07151 | Regression loss: 0.15412 | Running loss: 0.31378\n",
            "Epoch: 11 | Iteration: 485 | Classification loss: 0.12093 | Regression loss: 0.26522 | Running loss: 0.31334\n",
            "Epoch: 11 | Iteration: 486 | Classification loss: 0.06047 | Regression loss: 0.19442 | Running loss: 0.31335\n",
            "Epoch: 11 | Iteration: 487 | Classification loss: 0.21229 | Regression loss: 0.21743 | Running loss: 0.31349\n",
            "Epoch: 11 | Iteration: 488 | Classification loss: 0.01567 | Regression loss: 0.10733 | Running loss: 0.31318\n",
            "Epoch: 11 | Iteration: 489 | Classification loss: 0.07116 | Regression loss: 0.16320 | Running loss: 0.31322\n",
            "Epoch: 11 | Iteration: 490 | Classification loss: 0.09520 | Regression loss: 0.14630 | Running loss: 0.31276\n",
            "Epoch: 11 | Iteration: 491 | Classification loss: 0.05845 | Regression loss: 0.13176 | Running loss: 0.31241\n",
            "Epoch: 11 | Iteration: 492 | Classification loss: 0.07337 | Regression loss: 0.17217 | Running loss: 0.31243\n",
            "Epoch: 11 | Iteration: 493 | Classification loss: 0.08503 | Regression loss: 0.09601 | Running loss: 0.31210\n",
            "Epoch: 11 | Iteration: 494 | Classification loss: 0.09963 | Regression loss: 0.29013 | Running loss: 0.31252\n",
            "Epoch: 11 | Iteration: 495 | Classification loss: 0.12804 | Regression loss: 0.16938 | Running loss: 0.31262\n",
            "Epoch: 11 | Iteration: 496 | Classification loss: 0.02689 | Regression loss: 0.12383 | Running loss: 0.31224\n",
            "Epoch: 11 | Iteration: 497 | Classification loss: 0.10274 | Regression loss: 0.28986 | Running loss: 0.31223\n",
            "Epoch: 11 | Iteration: 498 | Classification loss: 0.11818 | Regression loss: 0.27833 | Running loss: 0.31269\n",
            "Epoch: 11 | Iteration: 499 | Classification loss: 0.09069 | Regression loss: 0.14204 | Running loss: 0.31262\n",
            "Epoch: 11 | Iteration: 500 | Classification loss: 0.09238 | Regression loss: 0.17760 | Running loss: 0.31247\n",
            "Epoch: 11 | Iteration: 501 | Classification loss: 0.14288 | Regression loss: 0.22832 | Running loss: 0.31249\n",
            "Epoch: 11 | Iteration: 502 | Classification loss: 0.07813 | Regression loss: 0.18975 | Running loss: 0.31269\n",
            "Epoch: 11 | Iteration: 503 | Classification loss: 0.15090 | Regression loss: 0.25341 | Running loss: 0.31324\n",
            "Epoch: 11 | Iteration: 504 | Classification loss: 0.10241 | Regression loss: 0.20393 | Running loss: 0.31322\n",
            "Epoch: 11 | Iteration: 505 | Classification loss: 0.08563 | Regression loss: 0.23572 | Running loss: 0.31338\n",
            "Epoch: 11 | Iteration: 506 | Classification loss: 0.07615 | Regression loss: 0.18543 | Running loss: 0.31282\n",
            "Epoch: 11 | Iteration: 507 | Classification loss: 0.10514 | Regression loss: 0.31515 | Running loss: 0.31320\n",
            "Epoch: 11 | Iteration: 508 | Classification loss: 0.09557 | Regression loss: 0.20130 | Running loss: 0.31356\n",
            "Epoch: 11 | Iteration: 509 | Classification loss: 0.09730 | Regression loss: 0.30328 | Running loss: 0.31413\n",
            "Epoch: 11 | Iteration: 510 | Classification loss: 0.02861 | Regression loss: 0.10116 | Running loss: 0.31371\n",
            "Epoch: 11 | Iteration: 511 | Classification loss: 0.03797 | Regression loss: 0.15983 | Running loss: 0.31355\n",
            "Epoch: 11 | Iteration: 512 | Classification loss: 0.11645 | Regression loss: 0.22652 | Running loss: 0.31367\n",
            "Epoch: 11 | Iteration: 513 | Classification loss: 0.12822 | Regression loss: 0.30285 | Running loss: 0.31373\n",
            "Epoch: 11 | Iteration: 514 | Classification loss: 0.04289 | Regression loss: 0.14056 | Running loss: 0.31368\n",
            "Epoch: 11 | Iteration: 515 | Classification loss: 0.08771 | Regression loss: 0.24597 | Running loss: 0.31370\n",
            "Epoch: 11 | Iteration: 516 | Classification loss: 0.14717 | Regression loss: 0.30803 | Running loss: 0.31427\n",
            "Epoch: 11 | Iteration: 517 | Classification loss: 0.03980 | Regression loss: 0.11463 | Running loss: 0.31440\n",
            "Epoch: 11 | Iteration: 518 | Classification loss: 0.08581 | Regression loss: 0.23979 | Running loss: 0.31401\n",
            "Epoch: 11 | Iteration: 519 | Classification loss: 0.18057 | Regression loss: 0.34757 | Running loss: 0.31467\n",
            "Epoch: 11 | Iteration: 520 | Classification loss: 0.16080 | Regression loss: 0.20223 | Running loss: 0.31484\n",
            "Epoch: 11 | Iteration: 521 | Classification loss: 0.08252 | Regression loss: 0.19597 | Running loss: 0.31498\n",
            "Epoch: 11 | Iteration: 522 | Classification loss: 0.11749 | Regression loss: 0.28181 | Running loss: 0.31537\n",
            "Epoch: 11 | Iteration: 523 | Classification loss: 0.08729 | Regression loss: 0.13419 | Running loss: 0.31510\n",
            "Epoch: 11 | Iteration: 524 | Classification loss: 0.04440 | Regression loss: 0.16353 | Running loss: 0.31461\n",
            "Epoch: 11 | Iteration: 525 | Classification loss: 0.06724 | Regression loss: 0.12053 | Running loss: 0.31450\n",
            "Epoch: 11 | Iteration: 526 | Classification loss: 0.14250 | Regression loss: 0.33246 | Running loss: 0.31492\n",
            "Epoch: 11 | Iteration: 527 | Classification loss: 0.02885 | Regression loss: 0.16052 | Running loss: 0.31469\n",
            "Epoch: 11 | Iteration: 528 | Classification loss: 0.05013 | Regression loss: 0.18703 | Running loss: 0.31459\n",
            "Epoch: 11 | Iteration: 529 | Classification loss: 0.10609 | Regression loss: 0.28320 | Running loss: 0.31507\n",
            "Epoch: 11 | Iteration: 530 | Classification loss: 0.08655 | Regression loss: 0.11253 | Running loss: 0.31470\n",
            "Epoch: 11 | Iteration: 531 | Classification loss: 0.13894 | Regression loss: 0.22856 | Running loss: 0.31517\n",
            "Epoch: 11 | Iteration: 532 | Classification loss: 0.18923 | Regression loss: 0.32410 | Running loss: 0.31574\n",
            "Epoch: 11 | Iteration: 533 | Classification loss: 0.11315 | Regression loss: 0.25818 | Running loss: 0.31586\n",
            "Epoch: 11 | Iteration: 534 | Classification loss: 0.05859 | Regression loss: 0.10592 | Running loss: 0.31557\n",
            "Epoch: 11 | Iteration: 535 | Classification loss: 0.10855 | Regression loss: 0.19724 | Running loss: 0.31540\n",
            "Epoch: 11 | Iteration: 536 | Classification loss: 0.05353 | Regression loss: 0.16457 | Running loss: 0.31535\n",
            "Epoch: 11 | Iteration: 537 | Classification loss: 0.14752 | Regression loss: 0.23564 | Running loss: 0.31531\n",
            "Epoch: 11 | Iteration: 538 | Classification loss: 0.15547 | Regression loss: 0.21780 | Running loss: 0.31533\n",
            "Epoch: 11 | Iteration: 539 | Classification loss: 0.16370 | Regression loss: 0.27275 | Running loss: 0.31592\n",
            "Epoch: 11 | Iteration: 540 | Classification loss: 0.14938 | Regression loss: 0.21830 | Running loss: 0.31570\n",
            "Epoch: 11 | Iteration: 541 | Classification loss: 0.14928 | Regression loss: 0.37658 | Running loss: 0.31602\n",
            "Epoch: 11 | Iteration: 542 | Classification loss: 0.15942 | Regression loss: 0.15246 | Running loss: 0.31616\n",
            "Epoch: 11 | Iteration: 543 | Classification loss: 0.07158 | Regression loss: 0.15742 | Running loss: 0.31605\n",
            "Epoch: 11 | Iteration: 544 | Classification loss: 0.27405 | Regression loss: 0.35976 | Running loss: 0.31677\n",
            "Epoch: 11 | Iteration: 545 | Classification loss: 0.18174 | Regression loss: 0.34558 | Running loss: 0.31724\n",
            "Epoch: 11 | Iteration: 546 | Classification loss: 0.08945 | Regression loss: 0.27291 | Running loss: 0.31761\n",
            "Epoch: 11 | Iteration: 547 | Classification loss: 0.17997 | Regression loss: 0.36875 | Running loss: 0.31843\n",
            "Epoch: 11 | Iteration: 548 | Classification loss: 0.09566 | Regression loss: 0.20199 | Running loss: 0.31763\n",
            "Epoch: 11 | Iteration: 549 | Classification loss: 0.03847 | Regression loss: 0.12356 | Running loss: 0.31719\n",
            "Epoch: 11 | Iteration: 550 | Classification loss: 0.15434 | Regression loss: 0.35606 | Running loss: 0.31740\n",
            "Epoch: 11 | Iteration: 551 | Classification loss: 0.15453 | Regression loss: 0.06661 | Running loss: 0.31694\n",
            "Epoch: 11 | Iteration: 552 | Classification loss: 0.03872 | Regression loss: 0.13555 | Running loss: 0.31663\n",
            "Epoch: 11 | Iteration: 553 | Classification loss: 0.06857 | Regression loss: 0.12983 | Running loss: 0.31616\n",
            "Epoch: 11 | Iteration: 554 | Classification loss: 0.03711 | Regression loss: 0.14503 | Running loss: 0.31590\n",
            "Epoch: 11 | Iteration: 555 | Classification loss: 0.03049 | Regression loss: 0.12692 | Running loss: 0.31519\n",
            "Epoch: 11 | Iteration: 556 | Classification loss: 0.04362 | Regression loss: 0.17169 | Running loss: 0.31520\n",
            "Epoch: 11 | Iteration: 557 | Classification loss: 0.09523 | Regression loss: 0.21176 | Running loss: 0.31539\n",
            "Epoch: 11 | Iteration: 558 | Classification loss: 0.03412 | Regression loss: 0.16144 | Running loss: 0.31489\n",
            "Epoch: 11 | Iteration: 559 | Classification loss: 0.06677 | Regression loss: 0.15063 | Running loss: 0.31503\n",
            "Epoch: 11 | Iteration: 560 | Classification loss: 0.07688 | Regression loss: 0.17276 | Running loss: 0.31517\n",
            "Epoch: 11 | Iteration: 561 | Classification loss: 0.08042 | Regression loss: 0.16682 | Running loss: 0.31493\n",
            "Epoch: 11 | Iteration: 562 | Classification loss: 0.05799 | Regression loss: 0.20359 | Running loss: 0.31484\n",
            "Epoch: 11 | Iteration: 563 | Classification loss: 0.11544 | Regression loss: 0.25370 | Running loss: 0.31485\n",
            "Epoch: 11 | Iteration: 564 | Classification loss: 0.10407 | Regression loss: 0.13675 | Running loss: 0.31476\n",
            "Epoch: 11 | Iteration: 565 | Classification loss: 0.13381 | Regression loss: 0.29753 | Running loss: 0.31539\n",
            "Epoch: 11 | Iteration: 566 | Classification loss: 0.15625 | Regression loss: 0.19282 | Running loss: 0.31568\n",
            "Epoch: 11 | Iteration: 567 | Classification loss: 0.13461 | Regression loss: 0.22055 | Running loss: 0.31581\n",
            "Epoch: 11 | Iteration: 568 | Classification loss: 0.14026 | Regression loss: 0.30893 | Running loss: 0.31594\n",
            "Epoch: 11 | Iteration: 569 | Classification loss: 0.07704 | Regression loss: 0.19088 | Running loss: 0.31586\n",
            "Epoch: 11 | Iteration: 570 | Classification loss: 0.06885 | Regression loss: 0.16002 | Running loss: 0.31557\n",
            "Epoch: 11 | Iteration: 571 | Classification loss: 0.09060 | Regression loss: 0.21473 | Running loss: 0.31578\n",
            "Epoch: 11 | Iteration: 572 | Classification loss: 0.04765 | Regression loss: 0.12264 | Running loss: 0.31562\n",
            "Epoch: 11 | Iteration: 573 | Classification loss: 0.08688 | Regression loss: 0.27994 | Running loss: 0.31591\n",
            "Epoch: 11 | Iteration: 574 | Classification loss: 0.05094 | Regression loss: 0.12489 | Running loss: 0.31549\n",
            "Epoch: 11 | Iteration: 575 | Classification loss: 0.03689 | Regression loss: 0.11945 | Running loss: 0.31495\n",
            "Epoch: 11 | Iteration: 576 | Classification loss: 0.17384 | Regression loss: 0.33516 | Running loss: 0.31517\n",
            "Epoch: 11 | Iteration: 577 | Classification loss: 0.08644 | Regression loss: 0.20297 | Running loss: 0.31489\n",
            "Epoch: 11 | Iteration: 578 | Classification loss: 0.08382 | Regression loss: 0.19352 | Running loss: 0.31491\n",
            "Epoch: 11 | Iteration: 579 | Classification loss: 0.11036 | Regression loss: 0.26859 | Running loss: 0.31534\n",
            "Epoch: 11 | Iteration: 580 | Classification loss: 0.08452 | Regression loss: 0.30575 | Running loss: 0.31577\n",
            "Epoch: 11 | Iteration: 581 | Classification loss: 0.11754 | Regression loss: 0.26575 | Running loss: 0.31543\n",
            "Epoch: 11 | Iteration: 582 | Classification loss: 0.10259 | Regression loss: 0.23252 | Running loss: 0.31549\n",
            "Epoch: 11 | Iteration: 583 | Classification loss: 0.15365 | Regression loss: 0.23022 | Running loss: 0.31580\n",
            "Epoch: 11 | Iteration: 584 | Classification loss: 0.13780 | Regression loss: 0.28388 | Running loss: 0.31627\n",
            "Epoch: 11 | Iteration: 585 | Classification loss: 0.04472 | Regression loss: 0.12376 | Running loss: 0.31595\n",
            "Epoch: 11 | Iteration: 586 | Classification loss: 0.10069 | Regression loss: 0.26548 | Running loss: 0.31625\n",
            "Epoch: 11 | Iteration: 587 | Classification loss: 0.07971 | Regression loss: 0.27878 | Running loss: 0.31634\n",
            "Epoch: 11 | Iteration: 588 | Classification loss: 0.05063 | Regression loss: 0.17819 | Running loss: 0.31593\n",
            "Epoch: 11 | Iteration: 589 | Classification loss: 0.03524 | Regression loss: 0.12107 | Running loss: 0.31589\n",
            "Epoch: 11 | Iteration: 590 | Classification loss: 0.08617 | Regression loss: 0.18861 | Running loss: 0.31558\n",
            "Epoch: 11 | Iteration: 591 | Classification loss: 0.11339 | Regression loss: 0.26008 | Running loss: 0.31590\n",
            "Epoch: 11 | Iteration: 592 | Classification loss: 0.08140 | Regression loss: 0.17807 | Running loss: 0.31600\n",
            "Epoch: 11 | Iteration: 593 | Classification loss: 0.09718 | Regression loss: 0.25948 | Running loss: 0.31608\n",
            "Epoch: 11 | Iteration: 594 | Classification loss: 0.04509 | Regression loss: 0.15981 | Running loss: 0.31570\n",
            "Epoch: 11 | Iteration: 595 | Classification loss: 0.09047 | Regression loss: 0.20455 | Running loss: 0.31583\n",
            "Epoch: 11 | Iteration: 596 | Classification loss: 0.11043 | Regression loss: 0.17343 | Running loss: 0.31588\n",
            "Epoch: 11 | Iteration: 597 | Classification loss: 0.04980 | Regression loss: 0.20620 | Running loss: 0.31577\n",
            "Epoch: 11 | Iteration: 598 | Classification loss: 0.13534 | Regression loss: 0.28183 | Running loss: 0.31617\n",
            "Epoch: 11 | Iteration: 599 | Classification loss: 0.09368 | Regression loss: 0.28930 | Running loss: 0.31601\n",
            "Epoch: 11 | Iteration: 600 | Classification loss: 0.03307 | Regression loss: 0.09714 | Running loss: 0.31516\n",
            "Epoch: 11 | Iteration: 601 | Classification loss: 0.09777 | Regression loss: 0.14244 | Running loss: 0.31478\n",
            "Epoch: 11 | Iteration: 602 | Classification loss: 0.04632 | Regression loss: 0.14166 | Running loss: 0.31374\n",
            "Epoch: 11 | Iteration: 603 | Classification loss: 0.13027 | Regression loss: 0.18143 | Running loss: 0.31331\n",
            "Epoch: 11 | Iteration: 604 | Classification loss: 0.17529 | Regression loss: 0.30675 | Running loss: 0.31342\n",
            "Epoch: 11 | Iteration: 605 | Classification loss: 0.07194 | Regression loss: 0.22732 | Running loss: 0.31291\n",
            "Epoch: 11 | Iteration: 606 | Classification loss: 0.06929 | Regression loss: 0.16256 | Running loss: 0.31291\n",
            "Epoch: 11 | Iteration: 607 | Classification loss: 0.14398 | Regression loss: 0.28501 | Running loss: 0.31344\n",
            "Epoch: 11 | Iteration: 608 | Classification loss: 0.11265 | Regression loss: 0.21749 | Running loss: 0.31360\n",
            "Epoch: 11 | Iteration: 609 | Classification loss: 0.06626 | Regression loss: 0.14004 | Running loss: 0.31368\n",
            "Epoch: 11 | Iteration: 610 | Classification loss: 0.03990 | Regression loss: 0.11025 | Running loss: 0.31304\n",
            "Epoch: 11 | Iteration: 611 | Classification loss: 0.14222 | Regression loss: 0.30545 | Running loss: 0.31321\n",
            "Epoch: 11 | Iteration: 612 | Classification loss: 0.05372 | Regression loss: 0.13113 | Running loss: 0.31333\n",
            "Epoch: 11 | Iteration: 613 | Classification loss: 0.16562 | Regression loss: 0.25019 | Running loss: 0.31346\n",
            "Epoch: 11 | Iteration: 614 | Classification loss: 0.03136 | Regression loss: 0.11821 | Running loss: 0.31305\n",
            "Epoch: 11 | Iteration: 615 | Classification loss: 0.05778 | Regression loss: 0.18671 | Running loss: 0.31274\n",
            "Epoch: 11 | Iteration: 616 | Classification loss: 0.10237 | Regression loss: 0.18275 | Running loss: 0.31255\n",
            "Epoch: 11 | Iteration: 617 | Classification loss: 0.12332 | Regression loss: 0.19446 | Running loss: 0.31253\n",
            "Epoch: 11 | Iteration: 618 | Classification loss: 0.07514 | Regression loss: 0.21348 | Running loss: 0.31215\n",
            "Epoch: 11 | Iteration: 619 | Classification loss: 0.23731 | Regression loss: 0.37448 | Running loss: 0.31271\n",
            "Epoch: 11 | Iteration: 620 | Classification loss: 0.03453 | Regression loss: 0.06473 | Running loss: 0.31198\n",
            "Epoch: 11 | Iteration: 621 | Classification loss: 0.13997 | Regression loss: 0.26572 | Running loss: 0.31228\n",
            "Epoch: 11 | Iteration: 622 | Classification loss: 0.12418 | Regression loss: 0.30319 | Running loss: 0.31257\n",
            "Epoch: 11 | Iteration: 623 | Classification loss: 0.07749 | Regression loss: 0.19541 | Running loss: 0.31277\n",
            "Epoch: 11 | Iteration: 624 | Classification loss: 0.03468 | Regression loss: 0.23178 | Running loss: 0.31278\n",
            "Epoch: 11 | Iteration: 625 | Classification loss: 0.13306 | Regression loss: 0.25404 | Running loss: 0.31293\n",
            "Epoch: 11 | Iteration: 626 | Classification loss: 0.18900 | Regression loss: 0.38120 | Running loss: 0.31339\n",
            "Epoch: 11 | Iteration: 627 | Classification loss: 0.09481 | Regression loss: 0.16989 | Running loss: 0.31310\n",
            "Epoch: 11 | Iteration: 628 | Classification loss: 0.11371 | Regression loss: 0.30187 | Running loss: 0.31329\n",
            "Epoch: 11 | Iteration: 629 | Classification loss: 0.03471 | Regression loss: 0.15700 | Running loss: 0.31322\n",
            "Epoch: 11 | Iteration: 630 | Classification loss: 0.14025 | Regression loss: 0.24083 | Running loss: 0.31376\n",
            "Epoch: 11 | Iteration: 631 | Classification loss: 0.10903 | Regression loss: 0.21800 | Running loss: 0.31360\n",
            "Epoch: 11 | Iteration: 632 | Classification loss: 0.08792 | Regression loss: 0.19259 | Running loss: 0.31376\n",
            "Epoch: 11 | Iteration: 633 | Classification loss: 0.03628 | Regression loss: 0.16489 | Running loss: 0.31354\n",
            "Epoch: 11 | Iteration: 634 | Classification loss: 0.05341 | Regression loss: 0.24060 | Running loss: 0.31343\n",
            "Epoch: 11 | Iteration: 635 | Classification loss: 0.07595 | Regression loss: 0.17505 | Running loss: 0.31346\n",
            "Epoch: 11 | Iteration: 636 | Classification loss: 0.17927 | Regression loss: 0.37432 | Running loss: 0.31385\n",
            "Epoch: 11 | Iteration: 637 | Classification loss: 0.08177 | Regression loss: 0.23244 | Running loss: 0.31353\n",
            "Epoch: 11 | Iteration: 638 | Classification loss: 0.05625 | Regression loss: 0.18123 | Running loss: 0.31334\n",
            "Epoch: 11 | Iteration: 639 | Classification loss: 0.08987 | Regression loss: 0.21741 | Running loss: 0.31299\n",
            "Epoch: 11 | Iteration: 640 | Classification loss: 0.13278 | Regression loss: 0.15429 | Running loss: 0.31269\n",
            "Epoch: 11 | Iteration: 641 | Classification loss: 0.10211 | Regression loss: 0.24695 | Running loss: 0.31251\n",
            "Epoch: 11 | Iteration: 642 | Classification loss: 0.09549 | Regression loss: 0.25287 | Running loss: 0.31250\n",
            "Epoch: 11 | Iteration: 643 | Classification loss: 0.05757 | Regression loss: 0.24369 | Running loss: 0.31221\n",
            "Epoch: 11 | Iteration: 644 | Classification loss: 0.12736 | Regression loss: 0.24361 | Running loss: 0.31231\n",
            "Epoch: 11 | Iteration: 645 | Classification loss: 0.23347 | Regression loss: 0.18174 | Running loss: 0.31230\n",
            "Epoch: 11 | Iteration: 646 | Classification loss: 0.07700 | Regression loss: 0.13601 | Running loss: 0.31222\n",
            "Epoch: 11 | Iteration: 647 | Classification loss: 0.07778 | Regression loss: 0.26114 | Running loss: 0.31269\n",
            "Epoch: 11 | Iteration: 648 | Classification loss: 0.05649 | Regression loss: 0.16622 | Running loss: 0.31277\n",
            "Epoch: 11 | Iteration: 649 | Classification loss: 0.14745 | Regression loss: 0.29718 | Running loss: 0.31317\n",
            "Epoch: 11 | Iteration: 650 | Classification loss: 0.05802 | Regression loss: 0.14688 | Running loss: 0.31331\n",
            "Epoch: 11 | Iteration: 651 | Classification loss: 0.10351 | Regression loss: 0.20476 | Running loss: 0.31334\n",
            "Epoch: 11 | Iteration: 652 | Classification loss: 0.06258 | Regression loss: 0.13722 | Running loss: 0.31302\n",
            "Epoch: 11 | Iteration: 653 | Classification loss: 0.10510 | Regression loss: 0.19542 | Running loss: 0.31252\n",
            "Epoch: 11 | Iteration: 654 | Classification loss: 0.17320 | Regression loss: 0.31311 | Running loss: 0.31252\n",
            "Epoch: 11 | Iteration: 655 | Classification loss: 0.09406 | Regression loss: 0.15715 | Running loss: 0.31225\n",
            "Epoch: 11 | Iteration: 656 | Classification loss: 0.06522 | Regression loss: 0.12111 | Running loss: 0.31195\n",
            "Epoch: 11 | Iteration: 657 | Classification loss: 0.05411 | Regression loss: 0.12963 | Running loss: 0.31196\n",
            "Epoch: 11 | Iteration: 658 | Classification loss: 0.11864 | Regression loss: 0.25034 | Running loss: 0.31212\n",
            "Epoch: 11 | Iteration: 659 | Classification loss: 0.17811 | Regression loss: 0.32923 | Running loss: 0.31251\n",
            "Epoch: 11 | Iteration: 660 | Classification loss: 0.14971 | Regression loss: 0.34702 | Running loss: 0.31311\n",
            "Epoch: 11 | Iteration: 661 | Classification loss: 0.06805 | Regression loss: 0.22988 | Running loss: 0.31316\n",
            "Epoch: 11 | Iteration: 662 | Classification loss: 0.11586 | Regression loss: 0.25952 | Running loss: 0.31358\n",
            "Epoch: 11 | Iteration: 663 | Classification loss: 0.13045 | Regression loss: 0.29602 | Running loss: 0.31405\n",
            "Epoch: 11 | Iteration: 664 | Classification loss: 0.03152 | Regression loss: 0.13842 | Running loss: 0.31420\n",
            "Epoch: 11 | Iteration: 665 | Classification loss: 0.14121 | Regression loss: 0.32878 | Running loss: 0.31471\n",
            "Epoch: 11 | Iteration: 666 | Classification loss: 0.01674 | Regression loss: 0.05577 | Running loss: 0.31449\n",
            "Epoch: 11 | Iteration: 667 | Classification loss: 0.12841 | Regression loss: 0.26466 | Running loss: 0.31447\n",
            "Epoch: 11 | Iteration: 668 | Classification loss: 0.21374 | Regression loss: 0.22858 | Running loss: 0.31492\n",
            "Epoch: 11 | Iteration: 669 | Classification loss: 0.12853 | Regression loss: 0.20953 | Running loss: 0.31509\n",
            "Epoch: 11 | Iteration: 670 | Classification loss: 0.15616 | Regression loss: 0.29374 | Running loss: 0.31553\n",
            "Epoch: 11 | Iteration: 671 | Classification loss: 0.04630 | Regression loss: 0.10591 | Running loss: 0.31514\n",
            "Epoch: 11 | Iteration: 672 | Classification loss: 0.10971 | Regression loss: 0.20111 | Running loss: 0.31506\n",
            "Epoch: 11 | Iteration: 673 | Classification loss: 0.04789 | Regression loss: 0.12689 | Running loss: 0.31468\n",
            "Epoch: 11 | Iteration: 674 | Classification loss: 0.04215 | Regression loss: 0.15090 | Running loss: 0.31416\n",
            "Epoch: 11 | Iteration: 675 | Classification loss: 0.14404 | Regression loss: 0.22798 | Running loss: 0.31405\n",
            "Epoch: 11 | Iteration: 676 | Classification loss: 0.15792 | Regression loss: 0.35422 | Running loss: 0.31466\n",
            "Epoch: 11 | Iteration: 677 | Classification loss: 0.05098 | Regression loss: 0.18174 | Running loss: 0.31447\n",
            "Epoch: 11 | Iteration: 678 | Classification loss: 0.10062 | Regression loss: 0.30648 | Running loss: 0.31468\n",
            "Epoch: 11 | Iteration: 679 | Classification loss: 0.08141 | Regression loss: 0.19396 | Running loss: 0.31458\n",
            "Epoch: 11 | Iteration: 680 | Classification loss: 0.15113 | Regression loss: 0.14519 | Running loss: 0.31471\n",
            "Epoch: 11 | Iteration: 681 | Classification loss: 0.06957 | Regression loss: 0.17221 | Running loss: 0.31474\n",
            "Epoch: 11 | Iteration: 682 | Classification loss: 0.08535 | Regression loss: 0.14473 | Running loss: 0.31466\n",
            "Epoch: 11 | Iteration: 683 | Classification loss: 0.03996 | Regression loss: 0.10406 | Running loss: 0.31427\n",
            "Epoch: 11 | Iteration: 684 | Classification loss: 0.12485 | Regression loss: 0.13789 | Running loss: 0.31418\n",
            "Epoch: 11 | Iteration: 685 | Classification loss: 0.08882 | Regression loss: 0.23812 | Running loss: 0.31400\n",
            "Epoch: 11 | Iteration: 686 | Classification loss: 0.06849 | Regression loss: 0.15081 | Running loss: 0.31409\n",
            "Epoch: 11 | Iteration: 687 | Classification loss: 0.05480 | Regression loss: 0.20820 | Running loss: 0.31434\n",
            "Epoch: 11 | Iteration: 688 | Classification loss: 0.13631 | Regression loss: 0.41466 | Running loss: 0.31501\n",
            "Epoch: 11 | Iteration: 689 | Classification loss: 0.07632 | Regression loss: 0.24139 | Running loss: 0.31493\n",
            "Epoch: 11 | Iteration: 690 | Classification loss: 0.05974 | Regression loss: 0.20331 | Running loss: 0.31482\n",
            "Epoch: 11 | Iteration: 691 | Classification loss: 0.07518 | Regression loss: 0.20127 | Running loss: 0.31494\n",
            "Epoch: 11 | Iteration: 692 | Classification loss: 0.09145 | Regression loss: 0.21961 | Running loss: 0.31472\n",
            "Epoch: 11 | Iteration: 693 | Classification loss: 0.03295 | Regression loss: 0.13260 | Running loss: 0.31372\n",
            "Epoch: 11 | Iteration: 694 | Classification loss: 0.20599 | Regression loss: 0.35968 | Running loss: 0.31455\n",
            "Epoch: 11 | Iteration: 695 | Classification loss: 0.17085 | Regression loss: 0.37758 | Running loss: 0.31504\n",
            "Epoch: 11 | Iteration: 696 | Classification loss: 0.06966 | Regression loss: 0.14743 | Running loss: 0.31466\n",
            "Epoch: 11 | Iteration: 697 | Classification loss: 0.17522 | Regression loss: 0.17057 | Running loss: 0.31446\n",
            "Epoch: 11 | Iteration: 698 | Classification loss: 0.06491 | Regression loss: 0.14397 | Running loss: 0.31432\n",
            "Epoch: 11 | Iteration: 699 | Classification loss: 0.17002 | Regression loss: 0.34985 | Running loss: 0.31497\n",
            "Epoch: 11 | Iteration: 700 | Classification loss: 0.07865 | Regression loss: 0.23619 | Running loss: 0.31514\n",
            "Epoch: 11 | Iteration: 701 | Classification loss: 0.06040 | Regression loss: 0.12593 | Running loss: 0.31478\n",
            "Epoch: 11 | Iteration: 702 | Classification loss: 0.05759 | Regression loss: 0.09925 | Running loss: 0.31437\n",
            "Epoch: 11 | Iteration: 703 | Classification loss: 0.08806 | Regression loss: 0.29300 | Running loss: 0.31473\n",
            "Epoch: 11 | Iteration: 704 | Classification loss: 0.06081 | Regression loss: 0.19267 | Running loss: 0.31459\n",
            "Epoch: 11 | Iteration: 705 | Classification loss: 0.10159 | Regression loss: 0.24672 | Running loss: 0.31485\n",
            "Epoch: 11 | Iteration: 706 | Classification loss: 0.15312 | Regression loss: 0.25642 | Running loss: 0.31519\n",
            "Epoch: 11 | Iteration: 707 | Classification loss: 0.13006 | Regression loss: 0.27062 | Running loss: 0.31567\n",
            "Epoch: 11 | Iteration: 708 | Classification loss: 0.02411 | Regression loss: 0.10611 | Running loss: 0.31518\n",
            "Epoch: 11 | Iteration: 709 | Classification loss: 0.16614 | Regression loss: 0.28921 | Running loss: 0.31548\n",
            "Epoch: 11 | Iteration: 710 | Classification loss: 0.04135 | Regression loss: 0.17372 | Running loss: 0.31540\n",
            "Epoch: 11 | Iteration: 711 | Classification loss: 0.33738 | Regression loss: 0.36940 | Running loss: 0.31625\n",
            "Epoch: 11 | Iteration: 712 | Classification loss: 0.10505 | Regression loss: 0.29050 | Running loss: 0.31645\n",
            "Epoch: 11 | Iteration: 713 | Classification loss: 0.11060 | Regression loss: 0.17113 | Running loss: 0.31625\n",
            "Epoch: 11 | Iteration: 714 | Classification loss: 0.05950 | Regression loss: 0.14258 | Running loss: 0.31612\n",
            "Epoch: 11 | Iteration: 715 | Classification loss: 0.04628 | Regression loss: 0.16312 | Running loss: 0.31526\n",
            "Epoch: 11 | Iteration: 716 | Classification loss: 0.06300 | Regression loss: 0.16998 | Running loss: 0.31482\n",
            "Epoch: 11 | Iteration: 717 | Classification loss: 0.07572 | Regression loss: 0.19986 | Running loss: 0.31432\n",
            "Epoch: 11 | Iteration: 718 | Classification loss: 0.11820 | Regression loss: 0.23507 | Running loss: 0.31407\n",
            "Epoch: 11 | Iteration: 719 | Classification loss: 0.12860 | Regression loss: 0.28446 | Running loss: 0.31455\n",
            "Epoch: 11 | Iteration: 720 | Classification loss: 0.07735 | Regression loss: 0.21907 | Running loss: 0.31493\n",
            "Epoch: 11 | Iteration: 721 | Classification loss: 0.07826 | Regression loss: 0.10862 | Running loss: 0.31429\n",
            "Epoch: 11 | Iteration: 722 | Classification loss: 0.12771 | Regression loss: 0.25837 | Running loss: 0.31445\n",
            "Epoch: 11 | Iteration: 723 | Classification loss: 0.15302 | Regression loss: 0.26657 | Running loss: 0.31505\n",
            "Epoch: 11 | Iteration: 724 | Classification loss: 0.11359 | Regression loss: 0.29478 | Running loss: 0.31510\n",
            "Epoch: 11 | Iteration: 725 | Classification loss: 0.09047 | Regression loss: 0.18140 | Running loss: 0.31506\n",
            "Epoch: 11 | Iteration: 726 | Classification loss: 0.08944 | Regression loss: 0.21892 | Running loss: 0.31509\n",
            "Epoch: 11 | Iteration: 727 | Classification loss: 0.05882 | Regression loss: 0.15310 | Running loss: 0.31506\n",
            "Epoch: 11 | Iteration: 728 | Classification loss: 0.04663 | Regression loss: 0.13155 | Running loss: 0.31452\n",
            "Epoch: 11 | Iteration: 729 | Classification loss: 0.10649 | Regression loss: 0.30030 | Running loss: 0.31471\n",
            "Epoch: 11 | Iteration: 730 | Classification loss: 0.04319 | Regression loss: 0.14767 | Running loss: 0.31419\n",
            "Epoch: 11 | Iteration: 731 | Classification loss: 0.10974 | Regression loss: 0.21725 | Running loss: 0.31422\n",
            "Epoch: 11 | Iteration: 732 | Classification loss: 0.08021 | Regression loss: 0.12689 | Running loss: 0.31400\n",
            "Epoch: 11 | Iteration: 733 | Classification loss: 0.20592 | Regression loss: 0.23253 | Running loss: 0.31363\n",
            "Epoch: 11 | Iteration: 734 | Classification loss: 0.12973 | Regression loss: 0.30464 | Running loss: 0.31373\n",
            "Epoch: 11 | Iteration: 735 | Classification loss: 0.11104 | Regression loss: 0.22774 | Running loss: 0.31309\n",
            "Epoch: 11 | Iteration: 736 | Classification loss: 0.13545 | Regression loss: 0.22487 | Running loss: 0.31344\n",
            "Epoch: 11 | Iteration: 737 | Classification loss: 0.14711 | Regression loss: 0.28642 | Running loss: 0.31350\n",
            "Epoch: 11 | Iteration: 738 | Classification loss: 0.07790 | Regression loss: 0.15919 | Running loss: 0.31327\n",
            "Epoch: 11 | Iteration: 739 | Classification loss: 0.07896 | Regression loss: 0.20695 | Running loss: 0.31348\n",
            "Epoch: 11 | Iteration: 740 | Classification loss: 0.01264 | Regression loss: 0.07787 | Running loss: 0.31272\n",
            "Epoch: 11 | Iteration: 741 | Classification loss: 0.10367 | Regression loss: 0.19536 | Running loss: 0.31299\n",
            "Epoch: 11 | Iteration: 742 | Classification loss: 0.02941 | Regression loss: 0.11113 | Running loss: 0.31242\n",
            "Epoch: 11 | Iteration: 743 | Classification loss: 0.17185 | Regression loss: 0.32360 | Running loss: 0.31289\n",
            "Epoch: 11 | Iteration: 744 | Classification loss: 0.23653 | Regression loss: 0.34329 | Running loss: 0.31320\n",
            "Epoch: 11 | Iteration: 745 | Classification loss: 0.06953 | Regression loss: 0.22886 | Running loss: 0.31229\n",
            "Epoch: 11 | Iteration: 746 | Classification loss: 0.16021 | Regression loss: 0.25970 | Running loss: 0.31284\n",
            "Epoch: 11 | Iteration: 747 | Classification loss: 0.10035 | Regression loss: 0.23075 | Running loss: 0.31319\n",
            "Epoch: 11 | Iteration: 748 | Classification loss: 0.23944 | Regression loss: 0.40163 | Running loss: 0.31385\n",
            "Epoch: 11 | Iteration: 749 | Classification loss: 0.06969 | Regression loss: 0.18040 | Running loss: 0.31392\n",
            "Epoch: 11 | Iteration: 750 | Classification loss: 0.12455 | Regression loss: 0.35345 | Running loss: 0.31445\n",
            "Epoch: 11 | Iteration: 751 | Classification loss: 0.11941 | Regression loss: 0.28233 | Running loss: 0.31487\n",
            "Epoch: 11 | Iteration: 752 | Classification loss: 0.07220 | Regression loss: 0.20951 | Running loss: 0.31470\n",
            "Epoch: 11 | Iteration: 753 | Classification loss: 0.04756 | Regression loss: 0.11083 | Running loss: 0.31454\n",
            "Epoch: 11 | Iteration: 754 | Classification loss: 0.14866 | Regression loss: 0.25367 | Running loss: 0.31468\n",
            "Epoch: 11 | Iteration: 755 | Classification loss: 0.00142 | Regression loss: 0.03089 | Running loss: 0.31433\n",
            "Epoch: 11 | Iteration: 756 | Classification loss: 0.14544 | Regression loss: 0.36233 | Running loss: 0.31479\n",
            "Epoch: 11 | Iteration: 757 | Classification loss: 0.11355 | Regression loss: 0.17118 | Running loss: 0.31490\n",
            "Epoch: 11 | Iteration: 758 | Classification loss: 0.08251 | Regression loss: 0.22369 | Running loss: 0.31514\n",
            "Epoch: 11 | Iteration: 759 | Classification loss: 0.13193 | Regression loss: 0.25701 | Running loss: 0.31492\n",
            "Epoch: 11 | Iteration: 760 | Classification loss: 0.07080 | Regression loss: 0.19924 | Running loss: 0.31435\n",
            "Epoch: 11 | Iteration: 761 | Classification loss: 0.10374 | Regression loss: 0.24004 | Running loss: 0.31458\n",
            "Epoch: 11 | Iteration: 762 | Classification loss: 0.13210 | Regression loss: 0.36934 | Running loss: 0.31518\n",
            "Epoch: 11 | Iteration: 763 | Classification loss: 0.06267 | Regression loss: 0.14472 | Running loss: 0.31494\n",
            "Epoch: 11 | Iteration: 764 | Classification loss: 0.07318 | Regression loss: 0.22597 | Running loss: 0.31503\n",
            "Epoch: 11 | Iteration: 765 | Classification loss: 0.12807 | Regression loss: 0.23921 | Running loss: 0.31484\n",
            "Epoch: 11 | Iteration: 766 | Classification loss: 0.12270 | Regression loss: 0.28666 | Running loss: 0.31495\n",
            "Epoch: 11 | Iteration: 767 | Classification loss: 0.06475 | Regression loss: 0.23648 | Running loss: 0.31497\n",
            "Epoch: 11 | Iteration: 768 | Classification loss: 0.07006 | Regression loss: 0.14355 | Running loss: 0.31479\n",
            "Epoch: 11 | Iteration: 769 | Classification loss: 0.07763 | Regression loss: 0.17052 | Running loss: 0.31410\n",
            "Epoch: 11 | Iteration: 770 | Classification loss: 0.07253 | Regression loss: 0.22413 | Running loss: 0.31428\n",
            "Epoch: 11 | Iteration: 771 | Classification loss: 0.09450 | Regression loss: 0.33332 | Running loss: 0.31454\n",
            "Epoch: 11 | Iteration: 772 | Classification loss: 0.14048 | Regression loss: 0.34538 | Running loss: 0.31397\n",
            "Epoch: 11 | Iteration: 773 | Classification loss: 0.14626 | Regression loss: 0.11480 | Running loss: 0.31408\n",
            "Epoch: 11 | Iteration: 774 | Classification loss: 0.10590 | Regression loss: 0.22995 | Running loss: 0.31419\n",
            "Epoch: 11 | Iteration: 775 | Classification loss: 0.13455 | Regression loss: 0.25758 | Running loss: 0.31442\n",
            "Epoch: 11 | Iteration: 776 | Classification loss: 0.07220 | Regression loss: 0.12669 | Running loss: 0.31392\n",
            "Epoch: 11 | Iteration: 777 | Classification loss: 0.06814 | Regression loss: 0.13199 | Running loss: 0.31375\n",
            "Epoch: 11 | Iteration: 778 | Classification loss: 0.18915 | Regression loss: 0.28593 | Running loss: 0.31419\n",
            "Epoch: 11 | Iteration: 779 | Classification loss: 0.04212 | Regression loss: 0.14886 | Running loss: 0.31368\n",
            "Epoch: 11 | Iteration: 780 | Classification loss: 0.09824 | Regression loss: 0.25337 | Running loss: 0.31376\n",
            "Epoch: 11 | Iteration: 781 | Classification loss: 0.16803 | Regression loss: 0.28868 | Running loss: 0.31417\n",
            "Epoch: 11 | Iteration: 782 | Classification loss: 0.22208 | Regression loss: 0.32589 | Running loss: 0.31478\n",
            "Epoch: 11 | Iteration: 783 | Classification loss: 0.08796 | Regression loss: 0.20846 | Running loss: 0.31465\n",
            "Epoch: 11 | Iteration: 784 | Classification loss: 0.08776 | Regression loss: 0.22496 | Running loss: 0.31468\n",
            "Epoch: 11 | Iteration: 785 | Classification loss: 0.19250 | Regression loss: 0.34226 | Running loss: 0.31521\n",
            "Epoch: 11 | Iteration: 786 | Classification loss: 0.10338 | Regression loss: 0.23403 | Running loss: 0.31516\n",
            "Epoch: 11 | Iteration: 787 | Classification loss: 0.04728 | Regression loss: 0.13814 | Running loss: 0.31476\n",
            "Epoch: 11 | Iteration: 788 | Classification loss: 0.08522 | Regression loss: 0.21005 | Running loss: 0.31477\n",
            "Epoch: 11 | Iteration: 789 | Classification loss: 0.16849 | Regression loss: 0.32236 | Running loss: 0.31528\n",
            "Epoch: 11 | Iteration: 790 | Classification loss: 0.11499 | Regression loss: 0.25386 | Running loss: 0.31525\n",
            "Epoch: 11 | Iteration: 791 | Classification loss: 0.09063 | Regression loss: 0.21496 | Running loss: 0.31541\n",
            "Epoch: 11 | Iteration: 792 | Classification loss: 0.10264 | Regression loss: 0.26412 | Running loss: 0.31569\n",
            "Epoch: 11 | Iteration: 793 | Classification loss: 0.06517 | Regression loss: 0.19098 | Running loss: 0.31568\n",
            "Epoch: 11 | Iteration: 794 | Classification loss: 0.04754 | Regression loss: 0.25184 | Running loss: 0.31534\n",
            "Epoch: 11 | Iteration: 795 | Classification loss: 0.07459 | Regression loss: 0.13316 | Running loss: 0.31486\n",
            "Epoch: 11 | Iteration: 796 | Classification loss: 0.07949 | Regression loss: 0.21108 | Running loss: 0.31470\n",
            "Epoch: 11 | Iteration: 797 | Classification loss: 0.13924 | Regression loss: 0.24245 | Running loss: 0.31497\n",
            "Epoch: 11 | Iteration: 798 | Classification loss: 0.18402 | Regression loss: 0.32883 | Running loss: 0.31528\n",
            "Epoch: 11 | Iteration: 799 | Classification loss: 0.10554 | Regression loss: 0.22316 | Running loss: 0.31562\n",
            "Epoch: 11 | Iteration: 800 | Classification loss: 0.16974 | Regression loss: 0.38520 | Running loss: 0.31624\n",
            "Epoch: 11 | Iteration: 801 | Classification loss: 0.10481 | Regression loss: 0.23808 | Running loss: 0.31645\n",
            "Epoch: 11 | Iteration: 802 | Classification loss: 0.08498 | Regression loss: 0.20485 | Running loss: 0.31664\n",
            "Epoch: 11 | Iteration: 803 | Classification loss: 0.11088 | Regression loss: 0.24687 | Running loss: 0.31681\n",
            "Epoch: 11 | Iteration: 804 | Classification loss: 0.04399 | Regression loss: 0.14086 | Running loss: 0.31647\n",
            "Epoch: 11 | Iteration: 805 | Classification loss: 0.13601 | Regression loss: 0.20595 | Running loss: 0.31669\n",
            "Epoch: 11 | Iteration: 806 | Classification loss: 0.03000 | Regression loss: 0.10049 | Running loss: 0.31633\n",
            "Epoch: 11 | Iteration: 807 | Classification loss: 0.05700 | Regression loss: 0.12515 | Running loss: 0.31628\n",
            "Epoch: 11 | Iteration: 808 | Classification loss: 0.08153 | Regression loss: 0.22993 | Running loss: 0.31646\n",
            "Epoch: 11 | Iteration: 809 | Classification loss: 0.13534 | Regression loss: 0.29582 | Running loss: 0.31650\n",
            "Epoch: 11 | Iteration: 810 | Classification loss: 0.12055 | Regression loss: 0.30824 | Running loss: 0.31689\n",
            "Epoch: 11 | Iteration: 811 | Classification loss: 0.18506 | Regression loss: 0.27439 | Running loss: 0.31719\n",
            "Epoch: 11 | Iteration: 812 | Classification loss: 0.05443 | Regression loss: 0.15630 | Running loss: 0.31721\n",
            "Epoch: 11 | Iteration: 813 | Classification loss: 0.12979 | Regression loss: 0.30124 | Running loss: 0.31767\n",
            "Epoch: 11 | Iteration: 814 | Classification loss: 0.07602 | Regression loss: 0.20599 | Running loss: 0.31781\n",
            "Epoch: 11 | Iteration: 815 | Classification loss: 0.07669 | Regression loss: 0.22895 | Running loss: 0.31791\n",
            "Epoch: 11 | Iteration: 816 | Classification loss: 0.07245 | Regression loss: 0.17750 | Running loss: 0.31816\n",
            "Epoch: 11 | Iteration: 817 | Classification loss: 0.09715 | Regression loss: 0.16953 | Running loss: 0.31796\n",
            "Epoch: 11 | Iteration: 818 | Classification loss: 0.13431 | Regression loss: 0.23053 | Running loss: 0.31841\n",
            "Epoch: 11 | Iteration: 819 | Classification loss: 0.03512 | Regression loss: 0.14120 | Running loss: 0.31839\n",
            "Epoch: 11 | Iteration: 820 | Classification loss: 0.16156 | Regression loss: 0.23559 | Running loss: 0.31854\n",
            "Epoch: 11 | Iteration: 821 | Classification loss: 0.06944 | Regression loss: 0.10689 | Running loss: 0.31858\n",
            "Epoch: 11 | Iteration: 822 | Classification loss: 0.25455 | Regression loss: 0.47501 | Running loss: 0.31922\n",
            "Epoch: 11 | Iteration: 823 | Classification loss: 0.04484 | Regression loss: 0.14864 | Running loss: 0.31918\n",
            "Epoch: 11 | Iteration: 824 | Classification loss: 0.13179 | Regression loss: 0.24826 | Running loss: 0.31949\n",
            "Epoch: 11 | Iteration: 825 | Classification loss: 0.09477 | Regression loss: 0.15794 | Running loss: 0.31933\n",
            "Epoch: 11 | Iteration: 826 | Classification loss: 0.07299 | Regression loss: 0.19580 | Running loss: 0.31921\n",
            "Epoch: 11 | Iteration: 827 | Classification loss: 0.14321 | Regression loss: 0.22524 | Running loss: 0.31918\n",
            "Epoch: 11 | Iteration: 828 | Classification loss: 0.11500 | Regression loss: 0.25085 | Running loss: 0.31940\n",
            "Epoch: 11 | Iteration: 829 | Classification loss: 0.10090 | Regression loss: 0.23093 | Running loss: 0.31950\n",
            "Epoch: 11 | Iteration: 830 | Classification loss: 0.10344 | Regression loss: 0.20073 | Running loss: 0.31922\n",
            "Epoch: 11 | Iteration: 831 | Classification loss: 0.07193 | Regression loss: 0.12451 | Running loss: 0.31836\n",
            "Epoch: 11 | Iteration: 832 | Classification loss: 0.06821 | Regression loss: 0.20834 | Running loss: 0.31859\n",
            "Epoch: 11 | Iteration: 833 | Classification loss: 0.21634 | Regression loss: 0.34535 | Running loss: 0.31911\n",
            "Epoch: 11 | Iteration: 834 | Classification loss: 0.15037 | Regression loss: 0.24177 | Running loss: 0.31939\n",
            "Epoch: 11 | Iteration: 835 | Classification loss: 0.07753 | Regression loss: 0.17630 | Running loss: 0.31856\n",
            "Epoch: 11 | Iteration: 836 | Classification loss: 0.15301 | Regression loss: 0.25230 | Running loss: 0.31878\n",
            "Epoch: 11 | Iteration: 837 | Classification loss: 0.12032 | Regression loss: 0.24479 | Running loss: 0.31874\n",
            "Epoch: 11 | Iteration: 838 | Classification loss: 0.06296 | Regression loss: 0.20795 | Running loss: 0.31863\n",
            "Epoch: 11 | Iteration: 839 | Classification loss: 0.09002 | Regression loss: 0.17109 | Running loss: 0.31870\n",
            "Epoch: 11 | Iteration: 840 | Classification loss: 0.04559 | Regression loss: 0.14582 | Running loss: 0.31865\n",
            "Epoch: 11 | Iteration: 841 | Classification loss: 0.15766 | Regression loss: 0.34538 | Running loss: 0.31878\n",
            "Epoch: 11 | Iteration: 842 | Classification loss: 0.07931 | Regression loss: 0.21610 | Running loss: 0.31883\n",
            "Epoch: 11 | Iteration: 843 | Classification loss: 0.10105 | Regression loss: 0.20590 | Running loss: 0.31836\n",
            "Epoch: 11 | Iteration: 844 | Classification loss: 0.10006 | Regression loss: 0.18464 | Running loss: 0.31832\n",
            "Epoch: 11 | Iteration: 845 | Classification loss: 0.03345 | Regression loss: 0.17567 | Running loss: 0.31815\n",
            "Epoch: 11 | Iteration: 846 | Classification loss: 0.05607 | Regression loss: 0.17878 | Running loss: 0.31811\n",
            "Epoch: 11 | Iteration: 847 | Classification loss: 0.06625 | Regression loss: 0.17499 | Running loss: 0.31813\n",
            "Epoch: 11 | Iteration: 848 | Classification loss: 0.04668 | Regression loss: 0.16402 | Running loss: 0.31816\n",
            "Epoch: 11 | Iteration: 849 | Classification loss: 0.12321 | Regression loss: 0.21935 | Running loss: 0.31855\n",
            "Epoch: 11 | Iteration: 850 | Classification loss: 0.12022 | Regression loss: 0.21049 | Running loss: 0.31834\n",
            "Epoch: 11 | Iteration: 851 | Classification loss: 0.04420 | Regression loss: 0.17352 | Running loss: 0.31849\n",
            "Epoch: 11 | Iteration: 852 | Classification loss: 0.11955 | Regression loss: 0.15554 | Running loss: 0.31862\n",
            "Epoch: 11 | Iteration: 853 | Classification loss: 0.12555 | Regression loss: 0.27061 | Running loss: 0.31875\n",
            "Epoch: 11 | Iteration: 854 | Classification loss: 0.05701 | Regression loss: 0.20053 | Running loss: 0.31850\n",
            "Epoch: 11 | Iteration: 855 | Classification loss: 0.07317 | Regression loss: 0.15458 | Running loss: 0.31824\n",
            "Epoch: 11 | Iteration: 856 | Classification loss: 0.09839 | Regression loss: 0.23862 | Running loss: 0.31857\n",
            "Epoch: 11 | Iteration: 857 | Classification loss: 0.05173 | Regression loss: 0.14754 | Running loss: 0.31854\n",
            "Epoch: 11 | Iteration: 858 | Classification loss: 0.15647 | Regression loss: 0.32403 | Running loss: 0.31909\n",
            "Epoch: 11 | Iteration: 859 | Classification loss: 0.07119 | Regression loss: 0.14070 | Running loss: 0.31864\n",
            "Epoch: 11 | Iteration: 860 | Classification loss: 0.08467 | Regression loss: 0.23031 | Running loss: 0.31828\n",
            "Epoch: 11 | Iteration: 861 | Classification loss: 0.04357 | Regression loss: 0.08607 | Running loss: 0.31698\n",
            "Epoch: 11 | Iteration: 862 | Classification loss: 0.13838 | Regression loss: 0.29797 | Running loss: 0.31744\n",
            "Epoch: 11 | Iteration: 863 | Classification loss: 0.08248 | Regression loss: 0.26688 | Running loss: 0.31736\n",
            "Epoch: 11 | Iteration: 864 | Classification loss: 0.07545 | Regression loss: 0.19437 | Running loss: 0.31743\n",
            "Epoch: 11 | Iteration: 865 | Classification loss: 0.06092 | Regression loss: 0.18279 | Running loss: 0.31740\n",
            "Epoch: 11 | Iteration: 866 | Classification loss: 0.05088 | Regression loss: 0.18677 | Running loss: 0.31716\n",
            "Epoch: 11 | Iteration: 867 | Classification loss: 0.03675 | Regression loss: 0.08904 | Running loss: 0.31702\n",
            "Epoch: 11 | Iteration: 868 | Classification loss: 0.03896 | Regression loss: 0.08649 | Running loss: 0.31685\n",
            "Epoch: 11 | Iteration: 869 | Classification loss: 0.07084 | Regression loss: 0.19715 | Running loss: 0.31671\n",
            "Epoch: 11 | Iteration: 870 | Classification loss: 0.09481 | Regression loss: 0.21321 | Running loss: 0.31682\n",
            "Epoch: 11 | Iteration: 871 | Classification loss: 0.04712 | Regression loss: 0.15976 | Running loss: 0.31643\n",
            "Epoch: 11 | Iteration: 872 | Classification loss: 0.20355 | Regression loss: 0.35869 | Running loss: 0.31673\n",
            "Epoch: 11 | Iteration: 873 | Classification loss: 0.35510 | Regression loss: 0.44178 | Running loss: 0.31788\n",
            "Epoch: 11 | Iteration: 874 | Classification loss: 0.15601 | Regression loss: 0.24299 | Running loss: 0.31818\n",
            "Epoch: 11 | Iteration: 875 | Classification loss: 0.07854 | Regression loss: 0.25803 | Running loss: 0.31782\n",
            "Epoch: 11 | Iteration: 876 | Classification loss: 0.07616 | Regression loss: 0.15239 | Running loss: 0.31757\n",
            "Epoch: 11 | Iteration: 877 | Classification loss: 0.05768 | Regression loss: 0.20864 | Running loss: 0.31701\n",
            "Epoch: 11 | Iteration: 878 | Classification loss: 0.02250 | Regression loss: 0.14674 | Running loss: 0.31642\n",
            "Epoch: 11 | Iteration: 879 | Classification loss: 0.28615 | Regression loss: 0.44572 | Running loss: 0.31716\n",
            "Epoch: 11 | Iteration: 880 | Classification loss: 0.02551 | Regression loss: 0.08554 | Running loss: 0.31664\n",
            "Epoch: 11 | Iteration: 881 | Classification loss: 0.04095 | Regression loss: 0.19246 | Running loss: 0.31668\n",
            "Epoch: 11 | Iteration: 882 | Classification loss: 0.20276 | Regression loss: 0.38759 | Running loss: 0.31743\n",
            "Epoch: 11 | Iteration: 883 | Classification loss: 0.06853 | Regression loss: 0.17729 | Running loss: 0.31710\n",
            "Epoch: 11 | Iteration: 884 | Classification loss: 0.08746 | Regression loss: 0.17201 | Running loss: 0.31680\n",
            "Epoch: 11 | Iteration: 885 | Classification loss: 0.08772 | Regression loss: 0.17922 | Running loss: 0.31696\n",
            "Epoch: 11 | Iteration: 886 | Classification loss: 0.08569 | Regression loss: 0.21979 | Running loss: 0.31697\n",
            "Epoch: 11 | Iteration: 887 | Classification loss: 0.06175 | Regression loss: 0.22690 | Running loss: 0.31677\n",
            "Epoch: 11 | Iteration: 888 | Classification loss: 0.06429 | Regression loss: 0.16472 | Running loss: 0.31662\n",
            "Epoch: 11 | Iteration: 889 | Classification loss: 0.03459 | Regression loss: 0.15380 | Running loss: 0.31604\n",
            "Epoch: 11 | Iteration: 890 | Classification loss: 0.11193 | Regression loss: 0.18454 | Running loss: 0.31615\n",
            "Epoch: 11 | Iteration: 891 | Classification loss: 0.15202 | Regression loss: 0.32831 | Running loss: 0.31659\n",
            "Epoch: 11 | Iteration: 892 | Classification loss: 0.10243 | Regression loss: 0.23045 | Running loss: 0.31645\n",
            "Epoch: 11 | Iteration: 893 | Classification loss: 0.07648 | Regression loss: 0.24619 | Running loss: 0.31635\n",
            "Epoch: 11 | Iteration: 894 | Classification loss: 0.06487 | Regression loss: 0.15793 | Running loss: 0.31558\n",
            "Epoch: 11 | Iteration: 895 | Classification loss: 0.10432 | Regression loss: 0.17355 | Running loss: 0.31543\n",
            "Epoch: 11 | Iteration: 896 | Classification loss: 0.04368 | Regression loss: 0.10269 | Running loss: 0.31530\n",
            "Epoch: 11 | Iteration: 897 | Classification loss: 0.16012 | Regression loss: 0.23549 | Running loss: 0.31565\n",
            "Epoch: 11 | Iteration: 898 | Classification loss: 0.08069 | Regression loss: 0.13493 | Running loss: 0.31484\n",
            "Epoch: 11 | Iteration: 899 | Classification loss: 0.09906 | Regression loss: 0.19451 | Running loss: 0.31471\n",
            "Epoch: 11 | Iteration: 900 | Classification loss: 0.04537 | Regression loss: 0.13851 | Running loss: 0.31380\n",
            "Epoch: 11 | Iteration: 901 | Classification loss: 0.12434 | Regression loss: 0.20548 | Running loss: 0.31412\n",
            "Epoch: 11 | Iteration: 902 | Classification loss: 0.05874 | Regression loss: 0.17333 | Running loss: 0.31365\n",
            "Epoch: 11 | Iteration: 903 | Classification loss: 0.04053 | Regression loss: 0.10176 | Running loss: 0.31304\n",
            "Epoch: 11 | Iteration: 904 | Classification loss: 0.06255 | Regression loss: 0.18662 | Running loss: 0.31316\n",
            "Epoch: 11 | Iteration: 905 | Classification loss: 0.02086 | Regression loss: 0.08309 | Running loss: 0.31247\n",
            "Epoch: 11 | Iteration: 906 | Classification loss: 0.05176 | Regression loss: 0.15387 | Running loss: 0.31249\n",
            "Epoch: 11 | Iteration: 907 | Classification loss: 0.06854 | Regression loss: 0.14837 | Running loss: 0.31207\n",
            "Epoch: 11 | Iteration: 908 | Classification loss: 0.13337 | Regression loss: 0.25657 | Running loss: 0.31252\n",
            "Epoch: 11 | Iteration: 909 | Classification loss: 0.08988 | Regression loss: 0.11516 | Running loss: 0.31258\n",
            "Epoch: 11 | Iteration: 910 | Classification loss: 0.09024 | Regression loss: 0.18925 | Running loss: 0.31269\n",
            "Epoch: 11 | Iteration: 911 | Classification loss: 0.16754 | Regression loss: 0.20522 | Running loss: 0.31297\n",
            "Epoch: 11 | Iteration: 912 | Classification loss: 0.05945 | Regression loss: 0.11253 | Running loss: 0.31239\n",
            "Epoch: 11 | Iteration: 913 | Classification loss: 0.14300 | Regression loss: 0.34826 | Running loss: 0.31290\n",
            "Epoch: 11 | Iteration: 914 | Classification loss: 0.12855 | Regression loss: 0.25676 | Running loss: 0.31323\n",
            "Epoch: 11 | Iteration: 915 | Classification loss: 0.22533 | Regression loss: 0.32615 | Running loss: 0.31380\n",
            "Epoch: 11 | Iteration: 916 | Classification loss: 0.13779 | Regression loss: 0.17092 | Running loss: 0.31394\n",
            "Epoch: 11 | Iteration: 917 | Classification loss: 0.16294 | Regression loss: 0.32321 | Running loss: 0.31386\n",
            "Epoch: 11 | Iteration: 918 | Classification loss: 0.09125 | Regression loss: 0.22201 | Running loss: 0.31404\n",
            "Epoch: 11 | Iteration: 919 | Classification loss: 0.09837 | Regression loss: 0.15933 | Running loss: 0.31406\n",
            "Epoch: 11 | Iteration: 920 | Classification loss: 0.13057 | Regression loss: 0.31730 | Running loss: 0.31438\n",
            "Epoch: 11 | Iteration: 921 | Classification loss: 0.11700 | Regression loss: 0.33596 | Running loss: 0.31438\n",
            "Epoch: 11 | Iteration: 922 | Classification loss: 0.16963 | Regression loss: 0.31375 | Running loss: 0.31470\n",
            "Epoch: 11 | Iteration: 923 | Classification loss: 0.15508 | Regression loss: 0.29432 | Running loss: 0.31519\n",
            "Epoch: 11 | Iteration: 924 | Classification loss: 0.20450 | Regression loss: 0.30630 | Running loss: 0.31575\n",
            "Epoch: 11 | Iteration: 925 | Classification loss: 0.08798 | Regression loss: 0.13580 | Running loss: 0.31551\n",
            "Epoch: 11 | Iteration: 926 | Classification loss: 0.07952 | Regression loss: 0.23610 | Running loss: 0.31589\n",
            "Epoch: 11 | Iteration: 927 | Classification loss: 0.07092 | Regression loss: 0.21946 | Running loss: 0.31607\n",
            "Epoch: 11 | Iteration: 928 | Classification loss: 0.15087 | Regression loss: 0.19233 | Running loss: 0.31541\n",
            "Epoch: 11 | Iteration: 929 | Classification loss: 0.04491 | Regression loss: 0.13254 | Running loss: 0.31533\n",
            "Epoch: 11 | Iteration: 930 | Classification loss: 0.09058 | Regression loss: 0.20869 | Running loss: 0.31501\n",
            "Epoch: 11 | Iteration: 931 | Classification loss: 0.09597 | Regression loss: 0.18990 | Running loss: 0.31497\n",
            "Epoch: 11 | Iteration: 932 | Classification loss: 0.16050 | Regression loss: 0.24092 | Running loss: 0.31482\n",
            "Epoch: 11 | Iteration: 933 | Classification loss: 0.08996 | Regression loss: 0.24781 | Running loss: 0.31493\n",
            "Epoch: 11 | Iteration: 934 | Classification loss: 0.05619 | Regression loss: 0.21457 | Running loss: 0.31516\n",
            "Epoch: 11 | Iteration: 935 | Classification loss: 0.03985 | Regression loss: 0.12432 | Running loss: 0.31505\n",
            "Epoch: 11 | Iteration: 936 | Classification loss: 0.05250 | Regression loss: 0.19497 | Running loss: 0.31486\n",
            "Epoch: 11 | Iteration: 937 | Classification loss: 0.10494 | Regression loss: 0.17425 | Running loss: 0.31459\n",
            "Epoch: 11 | Iteration: 938 | Classification loss: 0.04415 | Regression loss: 0.16477 | Running loss: 0.31434\n",
            "Epoch: 11 | Iteration: 939 | Classification loss: 0.05481 | Regression loss: 0.12659 | Running loss: 0.31428\n",
            "Epoch: 11 | Iteration: 940 | Classification loss: 0.09988 | Regression loss: 0.27222 | Running loss: 0.31434\n",
            "Epoch: 11 | Iteration: 941 | Classification loss: 0.16368 | Regression loss: 0.28814 | Running loss: 0.31476\n",
            "Epoch: 11 | Iteration: 942 | Classification loss: 0.03174 | Regression loss: 0.09550 | Running loss: 0.31461\n",
            "Epoch: 11 | Iteration: 943 | Classification loss: 0.06198 | Regression loss: 0.20191 | Running loss: 0.31452\n",
            "Epoch: 11 | Iteration: 944 | Classification loss: 0.13305 | Regression loss: 0.26640 | Running loss: 0.31488\n",
            "Epoch: 11 | Iteration: 945 | Classification loss: 0.08797 | Regression loss: 0.11679 | Running loss: 0.31498\n",
            "Epoch: 11 | Iteration: 946 | Classification loss: 0.16148 | Regression loss: 0.18409 | Running loss: 0.31438\n",
            "Epoch: 11 | Iteration: 947 | Classification loss: 0.06250 | Regression loss: 0.11131 | Running loss: 0.31413\n",
            "Epoch: 11 | Iteration: 948 | Classification loss: 0.06594 | Regression loss: 0.14168 | Running loss: 0.31393\n",
            "Epoch: 11 | Iteration: 949 | Classification loss: 0.11262 | Regression loss: 0.21642 | Running loss: 0.31384\n",
            "Epoch: 11 | Iteration: 950 | Classification loss: 0.07796 | Regression loss: 0.10051 | Running loss: 0.31374\n",
            "Epoch: 11 | Iteration: 951 | Classification loss: 0.11945 | Regression loss: 0.23573 | Running loss: 0.31368\n",
            "Epoch: 11 | Iteration: 952 | Classification loss: 0.10680 | Regression loss: 0.26636 | Running loss: 0.31411\n",
            "Epoch: 11 | Iteration: 953 | Classification loss: 0.09315 | Regression loss: 0.21612 | Running loss: 0.31445\n",
            "Epoch: 11 | Iteration: 954 | Classification loss: 0.08117 | Regression loss: 0.19127 | Running loss: 0.31440\n",
            "Epoch: 11 | Iteration: 955 | Classification loss: 0.09329 | Regression loss: 0.22290 | Running loss: 0.31439\n",
            "Epoch: 11 | Iteration: 956 | Classification loss: 0.05217 | Regression loss: 0.12285 | Running loss: 0.31420\n",
            "Epoch: 11 | Iteration: 957 | Classification loss: 0.05082 | Regression loss: 0.14351 | Running loss: 0.31423\n",
            "Epoch: 11 | Iteration: 958 | Classification loss: 0.05403 | Regression loss: 0.16030 | Running loss: 0.31402\n",
            "Epoch: 11 | Iteration: 959 | Classification loss: 0.08903 | Regression loss: 0.25391 | Running loss: 0.31392\n",
            "Epoch: 11 | Iteration: 960 | Classification loss: 0.07799 | Regression loss: 0.23209 | Running loss: 0.31427\n",
            "Epoch: 11 | Iteration: 961 | Classification loss: 0.08417 | Regression loss: 0.16268 | Running loss: 0.31404\n",
            "Epoch: 11 | Iteration: 962 | Classification loss: 0.09511 | Regression loss: 0.18744 | Running loss: 0.31432\n",
            "Epoch: 11 | Iteration: 963 | Classification loss: 0.09055 | Regression loss: 0.23212 | Running loss: 0.31460\n",
            "Epoch: 11 | Iteration: 964 | Classification loss: 0.09940 | Regression loss: 0.20974 | Running loss: 0.31469\n",
            "Epoch: 11 | Iteration: 965 | Classification loss: 0.03114 | Regression loss: 0.15570 | Running loss: 0.31461\n",
            "Epoch: 11 | Iteration: 966 | Classification loss: 0.07336 | Regression loss: 0.19767 | Running loss: 0.31482\n",
            "Epoch: 11 | Iteration: 967 | Classification loss: 0.11763 | Regression loss: 0.21726 | Running loss: 0.31495\n",
            "Epoch: 11 | Iteration: 968 | Classification loss: 0.12962 | Regression loss: 0.27515 | Running loss: 0.31504\n",
            "Epoch: 11 | Iteration: 969 | Classification loss: 0.04011 | Regression loss: 0.09073 | Running loss: 0.31384\n",
            "Epoch: 11 | Iteration: 970 | Classification loss: 0.02706 | Regression loss: 0.13618 | Running loss: 0.31354\n",
            "Epoch: 11 | Iteration: 971 | Classification loss: 0.03473 | Regression loss: 0.09869 | Running loss: 0.31286\n",
            "Epoch: 11 | Iteration: 972 | Classification loss: 0.06813 | Regression loss: 0.19595 | Running loss: 0.31234\n",
            "Epoch: 11 | Iteration: 973 | Classification loss: 0.05480 | Regression loss: 0.13011 | Running loss: 0.31213\n",
            "Epoch: 11 | Iteration: 974 | Classification loss: 0.03695 | Regression loss: 0.15776 | Running loss: 0.31208\n",
            "Epoch: 11 | Iteration: 975 | Classification loss: 0.05909 | Regression loss: 0.08899 | Running loss: 0.31139\n",
            "Epoch: 11 | Iteration: 976 | Classification loss: 0.11965 | Regression loss: 0.22147 | Running loss: 0.31139\n",
            "Epoch: 11 | Iteration: 977 | Classification loss: 0.16025 | Regression loss: 0.28660 | Running loss: 0.31141\n",
            "Epoch: 11 | Iteration: 978 | Classification loss: 0.03854 | Regression loss: 0.14126 | Running loss: 0.31100\n",
            "Epoch: 11 | Iteration: 979 | Classification loss: 0.03854 | Regression loss: 0.18717 | Running loss: 0.31067\n",
            "Epoch: 11 | Iteration: 980 | Classification loss: 0.05862 | Regression loss: 0.23514 | Running loss: 0.31079\n",
            "Epoch: 11 | Iteration: 981 | Classification loss: 0.08985 | Regression loss: 0.26737 | Running loss: 0.31087\n",
            "Epoch: 11 | Iteration: 982 | Classification loss: 0.02018 | Regression loss: 0.16063 | Running loss: 0.31054\n",
            "Epoch: 11 | Iteration: 983 | Classification loss: 0.13367 | Regression loss: 0.28128 | Running loss: 0.31097\n",
            "Epoch: 11 | Iteration: 984 | Classification loss: 0.08681 | Regression loss: 0.24891 | Running loss: 0.31119\n",
            "Epoch: 11 | Iteration: 985 | Classification loss: 0.09834 | Regression loss: 0.13094 | Running loss: 0.31088\n",
            "Epoch: 11 | Iteration: 986 | Classification loss: 0.09159 | Regression loss: 0.18892 | Running loss: 0.31093\n",
            "Epoch: 11 | Iteration: 987 | Classification loss: 0.10094 | Regression loss: 0.10419 | Running loss: 0.31048\n",
            "Epoch: 11 | Iteration: 988 | Classification loss: 0.15528 | Regression loss: 0.33495 | Running loss: 0.31122\n",
            "Epoch: 11 | Iteration: 989 | Classification loss: 0.03549 | Regression loss: 0.18938 | Running loss: 0.31120\n",
            "Epoch: 11 | Iteration: 990 | Classification loss: 0.06178 | Regression loss: 0.15760 | Running loss: 0.31115\n",
            "Epoch: 11 | Iteration: 991 | Classification loss: 0.05279 | Regression loss: 0.14036 | Running loss: 0.31116\n",
            "Epoch: 11 | Iteration: 992 | Classification loss: 0.06154 | Regression loss: 0.11068 | Running loss: 0.31101\n",
            "Epoch: 11 | Iteration: 993 | Classification loss: 0.05189 | Regression loss: 0.12393 | Running loss: 0.31100\n",
            "Epoch: 11 | Iteration: 994 | Classification loss: 0.08538 | Regression loss: 0.17193 | Running loss: 0.31074\n",
            "Epoch: 11 | Iteration: 995 | Classification loss: 0.17064 | Regression loss: 0.18080 | Running loss: 0.31085\n",
            "Epoch: 11 | Iteration: 996 | Classification loss: 0.14890 | Regression loss: 0.24270 | Running loss: 0.31133\n",
            "Epoch: 11 | Iteration: 997 | Classification loss: 0.10626 | Regression loss: 0.16611 | Running loss: 0.31109\n",
            "Epoch: 11 | Iteration: 998 | Classification loss: 0.10659 | Regression loss: 0.34483 | Running loss: 0.31120\n",
            "Epoch: 11 | Iteration: 999 | Classification loss: 0.07907 | Regression loss: 0.12000 | Running loss: 0.31113\n",
            "Epoch: 11 | Iteration: 1000 | Classification loss: 0.10409 | Regression loss: 0.20724 | Running loss: 0.31121\n",
            "Epoch: 11 | Iteration: 1001 | Classification loss: 0.07381 | Regression loss: 0.32921 | Running loss: 0.31128\n",
            "Epoch: 11 | Iteration: 1002 | Classification loss: 0.11001 | Regression loss: 0.14035 | Running loss: 0.31124\n",
            "Epoch: 11 | Iteration: 1003 | Classification loss: 0.03277 | Regression loss: 0.10552 | Running loss: 0.31071\n",
            "Epoch: 11 | Iteration: 1004 | Classification loss: 0.09532 | Regression loss: 0.23502 | Running loss: 0.31076\n",
            "Epoch: 11 | Iteration: 1005 | Classification loss: 0.04944 | Regression loss: 0.14791 | Running loss: 0.31051\n",
            "Epoch: 11 | Iteration: 1006 | Classification loss: 0.15870 | Regression loss: 0.35672 | Running loss: 0.31102\n",
            "Epoch: 11 | Iteration: 1007 | Classification loss: 0.12295 | Regression loss: 0.15836 | Running loss: 0.31074\n",
            "Epoch: 11 | Iteration: 1008 | Classification loss: 0.08536 | Regression loss: 0.18721 | Running loss: 0.31069\n",
            "Epoch: 11 | Iteration: 1009 | Classification loss: 0.15612 | Regression loss: 0.23494 | Running loss: 0.31067\n",
            "Epoch: 11 | Iteration: 1010 | Classification loss: 0.09635 | Regression loss: 0.17679 | Running loss: 0.31096\n",
            "Epoch: 11 | Iteration: 1011 | Classification loss: 0.05866 | Regression loss: 0.05927 | Running loss: 0.31080\n",
            "Epoch: 11 | Iteration: 1012 | Classification loss: 0.12221 | Regression loss: 0.24654 | Running loss: 0.31085\n",
            "Epoch: 11 | Iteration: 1013 | Classification loss: 0.03256 | Regression loss: 0.14096 | Running loss: 0.31033\n",
            "Epoch: 11 | Iteration: 1014 | Classification loss: 0.15849 | Regression loss: 0.31950 | Running loss: 0.31092\n",
            "Epoch: 11 | Iteration: 1015 | Classification loss: 0.10011 | Regression loss: 0.25252 | Running loss: 0.31096\n",
            "Epoch: 11 | Iteration: 1016 | Classification loss: 0.03056 | Regression loss: 0.10671 | Running loss: 0.31033\n",
            "Epoch: 11 | Iteration: 1017 | Classification loss: 0.07132 | Regression loss: 0.12549 | Running loss: 0.31041\n",
            "Epoch: 11 | Iteration: 1018 | Classification loss: 0.16700 | Regression loss: 0.16638 | Running loss: 0.31043\n",
            "Epoch: 11 | Iteration: 1019 | Classification loss: 0.04235 | Regression loss: 0.08599 | Running loss: 0.30963\n",
            "Epoch: 11 | Iteration: 1020 | Classification loss: 0.08555 | Regression loss: 0.19630 | Running loss: 0.30946\n",
            "Epoch: 11 | Iteration: 1021 | Classification loss: 0.09816 | Regression loss: 0.24527 | Running loss: 0.30959\n",
            "Epoch: 11 | Iteration: 1022 | Classification loss: 0.02721 | Regression loss: 0.11766 | Running loss: 0.30908\n",
            "Epoch: 11 | Iteration: 1023 | Classification loss: 0.07629 | Regression loss: 0.20455 | Running loss: 0.30920\n",
            "Epoch: 11 | Iteration: 1024 | Classification loss: 0.13454 | Regression loss: 0.21012 | Running loss: 0.30948\n",
            "Epoch: 11 | Iteration: 1025 | Classification loss: 0.08487 | Regression loss: 0.23823 | Running loss: 0.30975\n",
            "Epoch: 11 | Iteration: 1026 | Classification loss: 0.14528 | Regression loss: 0.27150 | Running loss: 0.30963\n",
            "Epoch: 11 | Iteration: 1027 | Classification loss: 0.05702 | Regression loss: 0.14529 | Running loss: 0.30966\n",
            "Epoch: 11 | Iteration: 1028 | Classification loss: 0.05641 | Regression loss: 0.17709 | Running loss: 0.30965\n",
            "Epoch: 11 | Iteration: 1029 | Classification loss: 0.10998 | Regression loss: 0.18976 | Running loss: 0.30947\n",
            "Epoch: 11 | Iteration: 1030 | Classification loss: 0.07426 | Regression loss: 0.18450 | Running loss: 0.30959\n",
            "Epoch: 11 | Iteration: 1031 | Classification loss: 0.06276 | Regression loss: 0.17931 | Running loss: 0.30934\n",
            "Epoch: 11 | Iteration: 1032 | Classification loss: 0.10280 | Regression loss: 0.22293 | Running loss: 0.30896\n",
            "Epoch: 11 | Iteration: 1033 | Classification loss: 0.12505 | Regression loss: 0.37094 | Running loss: 0.30921\n",
            "Epoch: 11 | Iteration: 1034 | Classification loss: 0.07421 | Regression loss: 0.18866 | Running loss: 0.30941\n",
            "Epoch: 11 | Iteration: 1035 | Classification loss: 0.09985 | Regression loss: 0.17055 | Running loss: 0.30934\n",
            "Epoch: 11 | Iteration: 1036 | Classification loss: 0.13167 | Regression loss: 0.20060 | Running loss: 0.30957\n",
            "Epoch: 11 | Iteration: 1037 | Classification loss: 0.07095 | Regression loss: 0.20777 | Running loss: 0.30936\n",
            "Epoch: 11 | Iteration: 1038 | Classification loss: 0.04097 | Regression loss: 0.13418 | Running loss: 0.30896\n",
            "Epoch: 11 | Iteration: 1039 | Classification loss: 0.03693 | Regression loss: 0.14388 | Running loss: 0.30845\n",
            "Epoch: 11 | Iteration: 1040 | Classification loss: 0.13648 | Regression loss: 0.39480 | Running loss: 0.30878\n",
            "Epoch: 11 | Iteration: 1041 | Classification loss: 0.11966 | Regression loss: 0.25800 | Running loss: 0.30848\n",
            "Epoch: 11 | Iteration: 1042 | Classification loss: 0.18228 | Regression loss: 0.33618 | Running loss: 0.30889\n",
            "Epoch: 11 | Iteration: 1043 | Classification loss: 0.10816 | Regression loss: 0.22166 | Running loss: 0.30910\n",
            "Epoch: 11 | Iteration: 1044 | Classification loss: 0.12875 | Regression loss: 0.29897 | Running loss: 0.30868\n",
            "Epoch: 11 | Iteration: 1045 | Classification loss: 0.04721 | Regression loss: 0.19559 | Running loss: 0.30812\n",
            "Epoch: 11 | Iteration: 1046 | Classification loss: 0.07948 | Regression loss: 0.14190 | Running loss: 0.30783\n",
            "Epoch: 11 | Iteration: 1047 | Classification loss: 0.11066 | Regression loss: 0.26851 | Running loss: 0.30749\n",
            "Epoch: 11 | Iteration: 1048 | Classification loss: 0.15625 | Regression loss: 0.21153 | Running loss: 0.30763\n",
            "Epoch: 11 | Iteration: 1049 | Classification loss: 0.03566 | Regression loss: 0.12454 | Running loss: 0.30763\n",
            "Epoch: 11 | Iteration: 1050 | Classification loss: 0.06043 | Regression loss: 0.28042 | Running loss: 0.30729\n",
            "Epoch: 11 | Iteration: 1051 | Classification loss: 0.04707 | Regression loss: 0.14440 | Running loss: 0.30723\n",
            "Epoch: 11 | Iteration: 1052 | Classification loss: 0.06339 | Regression loss: 0.19695 | Running loss: 0.30740\n",
            "Epoch: 11 | Iteration: 1053 | Classification loss: 0.09806 | Regression loss: 0.26996 | Running loss: 0.30774\n",
            "Epoch: 11 | Iteration: 1054 | Classification loss: 0.06819 | Regression loss: 0.13234 | Running loss: 0.30778\n",
            "Epoch: 11 | Iteration: 1055 | Classification loss: 0.08585 | Regression loss: 0.20740 | Running loss: 0.30805\n",
            "Epoch: 11 | Iteration: 1056 | Classification loss: 0.07329 | Regression loss: 0.15338 | Running loss: 0.30807\n",
            "Epoch: 11 | Iteration: 1057 | Classification loss: 0.05187 | Regression loss: 0.15918 | Running loss: 0.30788\n",
            "Epoch: 11 | Iteration: 1058 | Classification loss: 0.08514 | Regression loss: 0.23850 | Running loss: 0.30814\n",
            "Epoch: 11 | Iteration: 1059 | Classification loss: 0.15396 | Regression loss: 0.10963 | Running loss: 0.30823\n",
            "Epoch: 11 | Iteration: 1060 | Classification loss: 0.07982 | Regression loss: 0.18197 | Running loss: 0.30826\n",
            "Epoch: 11 | Iteration: 1061 | Classification loss: 0.12363 | Regression loss: 0.24814 | Running loss: 0.30850\n",
            "Epoch: 11 | Iteration: 1062 | Classification loss: 0.08557 | Regression loss: 0.22192 | Running loss: 0.30860\n",
            "Epoch: 11 | Iteration: 1063 | Classification loss: 0.29228 | Regression loss: 0.23944 | Running loss: 0.30892\n",
            "Epoch: 11 | Iteration: 1064 | Classification loss: 0.04291 | Regression loss: 0.23796 | Running loss: 0.30900\n",
            "Epoch: 11 | Iteration: 1065 | Classification loss: 0.09027 | Regression loss: 0.24351 | Running loss: 0.30881\n",
            "Epoch: 11 | Iteration: 1066 | Classification loss: 0.06028 | Regression loss: 0.17867 | Running loss: 0.30859\n",
            "Epoch: 11 | Iteration: 1067 | Classification loss: 0.08916 | Regression loss: 0.26790 | Running loss: 0.30859\n",
            "Epoch: 11 | Iteration: 1068 | Classification loss: 0.08156 | Regression loss: 0.19652 | Running loss: 0.30825\n",
            "Epoch: 11 | Iteration: 1069 | Classification loss: 0.15110 | Regression loss: 0.17149 | Running loss: 0.30836\n",
            "Epoch: 11 | Iteration: 1070 | Classification loss: 0.20744 | Regression loss: 0.26841 | Running loss: 0.30885\n",
            "Epoch: 11 | Iteration: 1071 | Classification loss: 0.08641 | Regression loss: 0.13911 | Running loss: 0.30869\n",
            "Epoch: 11 | Iteration: 1072 | Classification loss: 0.03154 | Regression loss: 0.07528 | Running loss: 0.30856\n",
            "Epoch: 11 | Iteration: 1073 | Classification loss: 0.06836 | Regression loss: 0.14369 | Running loss: 0.30826\n",
            "Epoch: 11 | Iteration: 1074 | Classification loss: 0.21527 | Regression loss: 0.27909 | Running loss: 0.30889\n",
            "Epoch: 11 | Iteration: 1075 | Classification loss: 0.08342 | Regression loss: 0.19674 | Running loss: 0.30914\n",
            "Epoch: 11 | Iteration: 1076 | Classification loss: 0.11661 | Regression loss: 0.23327 | Running loss: 0.30882\n",
            "Epoch: 11 | Iteration: 1077 | Classification loss: 0.05480 | Regression loss: 0.13349 | Running loss: 0.30862\n",
            "Epoch: 11 | Iteration: 1078 | Classification loss: 0.05870 | Regression loss: 0.16880 | Running loss: 0.30852\n",
            "Epoch: 11 | Iteration: 1079 | Classification loss: 0.13978 | Regression loss: 0.14135 | Running loss: 0.30832\n",
            "Epoch: 11 | Iteration: 1080 | Classification loss: 0.06070 | Regression loss: 0.16898 | Running loss: 0.30800\n",
            "Epoch: 11 | Iteration: 1081 | Classification loss: 0.10413 | Regression loss: 0.26581 | Running loss: 0.30798\n",
            "Epoch: 11 | Iteration: 1082 | Classification loss: 0.10733 | Regression loss: 0.22758 | Running loss: 0.30798\n",
            "Epoch: 11 | Iteration: 1083 | Classification loss: 0.08690 | Regression loss: 0.22913 | Running loss: 0.30784\n",
            "Epoch: 11 | Iteration: 1084 | Classification loss: 0.11741 | Regression loss: 0.20989 | Running loss: 0.30765\n",
            "Epoch: 11 | Iteration: 1085 | Classification loss: 0.10562 | Regression loss: 0.23051 | Running loss: 0.30799\n",
            "Epoch: 11 | Iteration: 1086 | Classification loss: 0.04693 | Regression loss: 0.13929 | Running loss: 0.30763\n",
            "Epoch: 11 | Iteration: 1087 | Classification loss: 0.11415 | Regression loss: 0.26414 | Running loss: 0.30767\n",
            "Epoch: 11 | Iteration: 1088 | Classification loss: 0.25828 | Regression loss: 0.42352 | Running loss: 0.30857\n",
            "Epoch: 11 | Iteration: 1089 | Classification loss: 0.06075 | Regression loss: 0.18354 | Running loss: 0.30875\n",
            "Epoch: 11 | Iteration: 1090 | Classification loss: 0.07691 | Regression loss: 0.25517 | Running loss: 0.30886\n",
            "Epoch: 11 | Iteration: 1091 | Classification loss: 0.17115 | Regression loss: 0.26268 | Running loss: 0.30898\n",
            "Epoch: 11 | Iteration: 1092 | Classification loss: 0.10589 | Regression loss: 0.20910 | Running loss: 0.30909\n",
            "Epoch: 11 | Iteration: 1093 | Classification loss: 0.05872 | Regression loss: 0.13867 | Running loss: 0.30878\n",
            "Epoch: 11 | Iteration: 1094 | Classification loss: 0.06268 | Regression loss: 0.12280 | Running loss: 0.30874\n",
            "Epoch: 11 | Iteration: 1095 | Classification loss: 0.10067 | Regression loss: 0.32979 | Running loss: 0.30901\n",
            "Epoch: 11 | Iteration: 1096 | Classification loss: 0.06645 | Regression loss: 0.11603 | Running loss: 0.30881\n",
            "Epoch: 11 | Iteration: 1097 | Classification loss: 0.07802 | Regression loss: 0.11347 | Running loss: 0.30868\n",
            "Epoch: 11 | Iteration: 1098 | Classification loss: 0.10718 | Regression loss: 0.27752 | Running loss: 0.30861\n",
            "Epoch: 11 | Iteration: 1099 | Classification loss: 0.09873 | Regression loss: 0.25037 | Running loss: 0.30854\n",
            "Epoch: 11 | Iteration: 1100 | Classification loss: 0.12328 | Regression loss: 0.20171 | Running loss: 0.30893\n",
            "Epoch: 11 | Iteration: 1101 | Classification loss: 0.05978 | Regression loss: 0.20397 | Running loss: 0.30898\n",
            "Epoch: 11 | Iteration: 1102 | Classification loss: 0.07468 | Regression loss: 0.24306 | Running loss: 0.30924\n",
            "Epoch: 11 | Iteration: 1103 | Classification loss: 0.07199 | Regression loss: 0.24482 | Running loss: 0.30925\n",
            "Epoch: 11 | Iteration: 1104 | Classification loss: 0.11117 | Regression loss: 0.27112 | Running loss: 0.30905\n",
            "Epoch: 11 | Iteration: 1105 | Classification loss: 0.06772 | Regression loss: 0.15780 | Running loss: 0.30890\n",
            "Epoch: 11 | Iteration: 1106 | Classification loss: 0.07371 | Regression loss: 0.20258 | Running loss: 0.30899\n",
            "Epoch: 11 | Iteration: 1107 | Classification loss: 0.24358 | Regression loss: 0.37936 | Running loss: 0.30938\n",
            "Epoch: 11 | Iteration: 1108 | Classification loss: 0.13162 | Regression loss: 0.24372 | Running loss: 0.30947\n",
            "Epoch: 11 | Iteration: 1109 | Classification loss: 0.10070 | Regression loss: 0.20687 | Running loss: 0.30967\n",
            "Epoch: 11 | Iteration: 1110 | Classification loss: 0.04395 | Regression loss: 0.14292 | Running loss: 0.30975\n",
            "Epoch: 11 | Iteration: 1111 | Classification loss: 0.09116 | Regression loss: 0.21517 | Running loss: 0.30946\n",
            "Epoch: 11 | Iteration: 1112 | Classification loss: 0.14671 | Regression loss: 0.32259 | Running loss: 0.31003\n",
            "Epoch: 11 | Iteration: 1113 | Classification loss: 0.16467 | Regression loss: 0.33616 | Running loss: 0.31020\n",
            "Epoch: 11 | Iteration: 1114 | Classification loss: 0.10181 | Regression loss: 0.19443 | Running loss: 0.31050\n",
            "Epoch: 11 | Iteration: 1115 | Classification loss: 0.05932 | Regression loss: 0.19444 | Running loss: 0.31051\n",
            "Epoch: 11 | Iteration: 1116 | Classification loss: 0.03644 | Regression loss: 0.15568 | Running loss: 0.31033\n",
            "Epoch: 11 | Iteration: 1117 | Classification loss: 0.08197 | Regression loss: 0.14776 | Running loss: 0.31015\n",
            "Epoch: 11 | Iteration: 1118 | Classification loss: 0.09801 | Regression loss: 0.17953 | Running loss: 0.31013\n",
            "Epoch: 11 | Iteration: 1119 | Classification loss: 0.09887 | Regression loss: 0.25769 | Running loss: 0.30962\n",
            "Epoch: 11 | Iteration: 1120 | Classification loss: 0.02190 | Regression loss: 0.09588 | Running loss: 0.30966\n",
            "Epoch: 11 | Iteration: 1121 | Classification loss: 0.09405 | Regression loss: 0.28883 | Running loss: 0.30961\n",
            "Epoch: 11 | Iteration: 1122 | Classification loss: 0.15882 | Regression loss: 0.26082 | Running loss: 0.30960\n",
            "Epoch: 11 | Iteration: 1123 | Classification loss: 0.04967 | Regression loss: 0.15899 | Running loss: 0.30947\n",
            "Epoch: 11 | Iteration: 1124 | Classification loss: 0.22916 | Regression loss: 0.44933 | Running loss: 0.31029\n",
            "Epoch: 11 | Iteration: 1125 | Classification loss: 0.08259 | Regression loss: 0.11776 | Running loss: 0.30992\n",
            "Epoch: 11 | Iteration: 1126 | Classification loss: 0.03781 | Regression loss: 0.10713 | Running loss: 0.30907\n",
            "Epoch: 11 | Iteration: 1127 | Classification loss: 0.12035 | Regression loss: 0.39821 | Running loss: 0.30958\n",
            "Epoch: 11 | Iteration: 1128 | Classification loss: 0.03956 | Regression loss: 0.08094 | Running loss: 0.30898\n",
            "Epoch: 11 | Iteration: 1129 | Classification loss: 0.11758 | Regression loss: 0.16329 | Running loss: 0.30916\n",
            "Epoch: 11 | Iteration: 1130 | Classification loss: 0.09465 | Regression loss: 0.23137 | Running loss: 0.30905\n",
            "Epoch: 11 | Iteration: 1131 | Classification loss: 0.16980 | Regression loss: 0.32093 | Running loss: 0.30938\n",
            "Epoch: 11 | Iteration: 1132 | Classification loss: 0.13884 | Regression loss: 0.27901 | Running loss: 0.30966\n",
            "Epoch: 11 | Iteration: 1133 | Classification loss: 0.05685 | Regression loss: 0.21682 | Running loss: 0.30980\n",
            "Epoch: 11 | Iteration: 1134 | Classification loss: 0.04583 | Regression loss: 0.16432 | Running loss: 0.30963\n",
            "Epoch: 11 | Iteration: 1135 | Classification loss: 0.13001 | Regression loss: 0.17112 | Running loss: 0.30973\n",
            "Epoch: 11 | Iteration: 1136 | Classification loss: 0.04789 | Regression loss: 0.13078 | Running loss: 0.30898\n",
            "Epoch: 11 | Iteration: 1137 | Classification loss: 0.19012 | Regression loss: 0.20397 | Running loss: 0.30914\n",
            "Epoch: 11 | Iteration: 1138 | Classification loss: 0.11713 | Regression loss: 0.18733 | Running loss: 0.30928\n",
            "Epoch: 11 | Iteration: 1139 | Classification loss: 0.08470 | Regression loss: 0.20681 | Running loss: 0.30925\n",
            "Epoch: 11 | Iteration: 1140 | Classification loss: 0.09958 | Regression loss: 0.21916 | Running loss: 0.30931\n",
            "Epoch: 11 | Iteration: 1141 | Classification loss: 0.10857 | Regression loss: 0.29131 | Running loss: 0.30941\n",
            "Epoch: 11 | Iteration: 1142 | Classification loss: 0.07322 | Regression loss: 0.21889 | Running loss: 0.30930\n",
            "Epoch: 11 | Iteration: 1143 | Classification loss: 0.14846 | Regression loss: 0.27685 | Running loss: 0.30955\n",
            "Epoch: 11 | Iteration: 1144 | Classification loss: 0.10193 | Regression loss: 0.26461 | Running loss: 0.30954\n",
            "Epoch: 11 | Iteration: 1145 | Classification loss: 0.11716 | Regression loss: 0.14172 | Running loss: 0.30922\n",
            "Epoch: 11 | Iteration: 1146 | Classification loss: 0.16911 | Regression loss: 0.28997 | Running loss: 0.30972\n",
            "Epoch: 11 | Iteration: 1147 | Classification loss: 0.06134 | Regression loss: 0.15475 | Running loss: 0.30947\n",
            "Epoch: 11 | Iteration: 1148 | Classification loss: 0.09635 | Regression loss: 0.14929 | Running loss: 0.30952\n",
            "Epoch: 11 | Iteration: 1149 | Classification loss: 0.12127 | Regression loss: 0.18234 | Running loss: 0.30923\n",
            "Epoch: 11 | Iteration: 1150 | Classification loss: 0.10319 | Regression loss: 0.37151 | Running loss: 0.30977\n",
            "Epoch: 11 | Iteration: 1151 | Classification loss: 0.07526 | Regression loss: 0.21832 | Running loss: 0.30974\n",
            "Epoch: 11 | Iteration: 1152 | Classification loss: 0.05424 | Regression loss: 0.12835 | Running loss: 0.30971\n",
            "Epoch: 11 | Iteration: 1153 | Classification loss: 0.14734 | Regression loss: 0.28954 | Running loss: 0.30998\n",
            "Epoch: 11 | Iteration: 1154 | Classification loss: 0.02555 | Regression loss: 0.05859 | Running loss: 0.30918\n",
            "Epoch: 11 | Iteration: 1155 | Classification loss: 0.05609 | Regression loss: 0.22048 | Running loss: 0.30923\n",
            "Epoch: 11 | Iteration: 1156 | Classification loss: 0.12457 | Regression loss: 0.15722 | Running loss: 0.30942\n",
            "Epoch: 11 | Iteration: 1157 | Classification loss: 0.17322 | Regression loss: 0.25665 | Running loss: 0.30991\n",
            "Epoch: 11 | Iteration: 1158 | Classification loss: 0.11405 | Regression loss: 0.24601 | Running loss: 0.30989\n",
            "Epoch: 11 | Iteration: 1159 | Classification loss: 0.12637 | Regression loss: 0.28408 | Running loss: 0.30970\n",
            "Epoch: 11 | Iteration: 1160 | Classification loss: 0.19995 | Regression loss: 0.35194 | Running loss: 0.30981\n",
            "Epoch: 11 | Iteration: 1161 | Classification loss: 0.04177 | Regression loss: 0.08978 | Running loss: 0.30948\n",
            "Epoch: 11 | Iteration: 1162 | Classification loss: 0.08425 | Regression loss: 0.25732 | Running loss: 0.30941\n",
            "Epoch: 11 | Iteration: 1163 | Classification loss: 0.07901 | Regression loss: 0.15418 | Running loss: 0.30902\n",
            "Epoch: 11 | Iteration: 1164 | Classification loss: 0.11914 | Regression loss: 0.28657 | Running loss: 0.30950\n",
            "Epoch: 11 | Iteration: 1165 | Classification loss: 0.10471 | Regression loss: 0.21587 | Running loss: 0.30920\n",
            "Epoch: 11 | Iteration: 1166 | Classification loss: 0.14301 | Regression loss: 0.29129 | Running loss: 0.30992\n",
            "Epoch: 11 | Iteration: 1167 | Classification loss: 0.07527 | Regression loss: 0.17345 | Running loss: 0.30963\n",
            "Epoch: 11 | Iteration: 1168 | Classification loss: 0.06943 | Regression loss: 0.16209 | Running loss: 0.30921\n",
            "Epoch: 11 | Iteration: 1169 | Classification loss: 0.17688 | Regression loss: 0.21565 | Running loss: 0.30932\n",
            "Epoch: 11 | Iteration: 1170 | Classification loss: 0.08699 | Regression loss: 0.19104 | Running loss: 0.30898\n",
            "Epoch: 11 | Iteration: 1171 | Classification loss: 0.14606 | Regression loss: 0.35468 | Running loss: 0.30967\n",
            "Epoch: 11 | Iteration: 1172 | Classification loss: 0.06533 | Regression loss: 0.24383 | Running loss: 0.30967\n",
            "Epoch: 11 | Iteration: 1173 | Classification loss: 0.04906 | Regression loss: 0.11887 | Running loss: 0.30966\n",
            "Epoch: 11 | Iteration: 1174 | Classification loss: 0.01207 | Regression loss: 0.07283 | Running loss: 0.30944\n",
            "Epoch: 11 | Iteration: 1175 | Classification loss: 0.11768 | Regression loss: 0.29061 | Running loss: 0.30951\n",
            "Epoch: 11 | Iteration: 1176 | Classification loss: 0.10526 | Regression loss: 0.12595 | Running loss: 0.30895\n",
            "Epoch: 11 | Iteration: 1177 | Classification loss: 0.02644 | Regression loss: 0.10295 | Running loss: 0.30874\n",
            "Epoch: 11 | Iteration: 1178 | Classification loss: 0.13004 | Regression loss: 0.28697 | Running loss: 0.30876\n",
            "Epoch: 11 | Iteration: 1179 | Classification loss: 0.05539 | Regression loss: 0.17172 | Running loss: 0.30867\n",
            "Epoch: 11 | Iteration: 1180 | Classification loss: 0.15957 | Regression loss: 0.24886 | Running loss: 0.30889\n",
            "Epoch: 11 | Iteration: 1181 | Classification loss: 0.04792 | Regression loss: 0.14313 | Running loss: 0.30879\n",
            "Epoch: 11 | Iteration: 1182 | Classification loss: 0.07650 | Regression loss: 0.18396 | Running loss: 0.30885\n",
            "Epoch: 11 | Iteration: 1183 | Classification loss: 0.20887 | Regression loss: 0.35729 | Running loss: 0.30969\n",
            "Epoch: 11 | Iteration: 1184 | Classification loss: 0.05065 | Regression loss: 0.21010 | Running loss: 0.30969\n",
            "Epoch: 11 | Iteration: 1185 | Classification loss: 0.08261 | Regression loss: 0.20867 | Running loss: 0.30962\n",
            "Epoch: 11 | Iteration: 1186 | Classification loss: 0.08870 | Regression loss: 0.28422 | Running loss: 0.30993\n",
            "Epoch: 11 | Iteration: 1187 | Classification loss: 0.05243 | Regression loss: 0.14670 | Running loss: 0.30980\n",
            "Epoch: 11 | Iteration: 1188 | Classification loss: 0.10906 | Regression loss: 0.19491 | Running loss: 0.30930\n",
            "Epoch: 11 | Iteration: 1189 | Classification loss: 0.11129 | Regression loss: 0.15009 | Running loss: 0.30919\n",
            "Epoch: 11 | Iteration: 1190 | Classification loss: 0.07105 | Regression loss: 0.16022 | Running loss: 0.30913\n",
            "Epoch: 11 | Iteration: 1191 | Classification loss: 0.03143 | Regression loss: 0.18904 | Running loss: 0.30902\n",
            "Epoch: 11 | Iteration: 1192 | Classification loss: 0.09291 | Regression loss: 0.27089 | Running loss: 0.30912\n",
            "Epoch: 11 | Iteration: 1193 | Classification loss: 0.14346 | Regression loss: 0.20763 | Running loss: 0.30949\n",
            "Epoch: 11 | Iteration: 1194 | Classification loss: 0.14359 | Regression loss: 0.27689 | Running loss: 0.30920\n",
            "Epoch: 11 | Iteration: 1195 | Classification loss: 0.12479 | Regression loss: 0.17287 | Running loss: 0.30870\n",
            "Epoch: 11 | Iteration: 1196 | Classification loss: 0.03844 | Regression loss: 0.17296 | Running loss: 0.30869\n",
            "Epoch: 11 | Iteration: 1197 | Classification loss: 0.12904 | Regression loss: 0.29051 | Running loss: 0.30884\n",
            "Epoch: 11 | Iteration: 1198 | Classification loss: 0.07598 | Regression loss: 0.26556 | Running loss: 0.30910\n",
            "Epoch: 11 | Iteration: 1199 | Classification loss: 0.10977 | Regression loss: 0.26778 | Running loss: 0.30882\n",
            "Evaluating dataset\n",
            "\n",
            "mAP:\n",
            "ambulance: 0.05686274509803921\n",
            "auto rickshaw: 0.3259176300747717\n",
            "bicycle: 0.33505107472555906\n",
            "bus: 0.6600872232337361\n",
            "car: 0.6335385253669542\n",
            "garbage van: 0\n",
            "human hauler: 0.10185396916039924\n",
            "minibus: 0.046426166426166426\n",
            "minivan: 0.21080778596663868\n",
            "motorbike: 0.5631418932592218\n",
            "pickup: 0.2745291113823996\n",
            "army vehicle: 0.6273721340388008\n",
            "policecar: 0.00697192387412851\n",
            "rickshaw: 0.5119589954214768\n",
            "scooter: 0.125\n",
            "suv: 0.1756422369568595\n",
            "taxi: 0.3875718390804597\n",
            "three wheelers (CNG): 0.5879837688024072\n",
            "truck: 0.6137777795340861\n",
            "van: 0.21038455325632202\n",
            "wheelbarrow: 0.036304511492111884\n",
            "Epoch: 12 | Iteration: 0 | Classification loss: 0.17693 | Regression loss: 0.22197 | Running loss: 0.30899\n",
            "Epoch: 12 | Iteration: 1 | Classification loss: 0.02627 | Regression loss: 0.12641 | Running loss: 0.30892\n",
            "Epoch: 12 | Iteration: 2 | Classification loss: 0.06514 | Regression loss: 0.19144 | Running loss: 0.30912\n",
            "Epoch: 12 | Iteration: 3 | Classification loss: 0.11620 | Regression loss: 0.21328 | Running loss: 0.30901\n",
            "Epoch: 12 | Iteration: 4 | Classification loss: 0.07230 | Regression loss: 0.16270 | Running loss: 0.30898\n",
            "Epoch: 12 | Iteration: 5 | Classification loss: 0.05260 | Regression loss: 0.18611 | Running loss: 0.30876\n",
            "Epoch: 12 | Iteration: 6 | Classification loss: 0.07414 | Regression loss: 0.17555 | Running loss: 0.30844\n",
            "Epoch: 12 | Iteration: 7 | Classification loss: 0.12167 | Regression loss: 0.28885 | Running loss: 0.30846\n",
            "Epoch: 12 | Iteration: 8 | Classification loss: 0.10927 | Regression loss: 0.22320 | Running loss: 0.30886\n",
            "Epoch: 12 | Iteration: 9 | Classification loss: 0.11499 | Regression loss: 0.31603 | Running loss: 0.30881\n",
            "Epoch: 12 | Iteration: 10 | Classification loss: 0.04917 | Regression loss: 0.16090 | Running loss: 0.30880\n",
            "Epoch: 12 | Iteration: 11 | Classification loss: 0.14642 | Regression loss: 0.29224 | Running loss: 0.30827\n",
            "Epoch: 12 | Iteration: 12 | Classification loss: 0.06849 | Regression loss: 0.24262 | Running loss: 0.30810\n",
            "Epoch: 12 | Iteration: 13 | Classification loss: 0.12678 | Regression loss: 0.28734 | Running loss: 0.30836\n",
            "Epoch: 12 | Iteration: 14 | Classification loss: 0.14755 | Regression loss: 0.23808 | Running loss: 0.30873\n",
            "Epoch: 12 | Iteration: 15 | Classification loss: 0.08553 | Regression loss: 0.20375 | Running loss: 0.30889\n",
            "Epoch: 12 | Iteration: 16 | Classification loss: 0.15029 | Regression loss: 0.18477 | Running loss: 0.30910\n",
            "Epoch: 12 | Iteration: 17 | Classification loss: 0.07587 | Regression loss: 0.18553 | Running loss: 0.30907\n",
            "Epoch: 12 | Iteration: 18 | Classification loss: 0.06673 | Regression loss: 0.24104 | Running loss: 0.30898\n",
            "Epoch: 12 | Iteration: 19 | Classification loss: 0.09051 | Regression loss: 0.22847 | Running loss: 0.30879\n",
            "Epoch: 12 | Iteration: 20 | Classification loss: 0.06219 | Regression loss: 0.16103 | Running loss: 0.30864\n",
            "Epoch: 12 | Iteration: 21 | Classification loss: 0.22355 | Regression loss: 0.35016 | Running loss: 0.30942\n",
            "Epoch: 12 | Iteration: 22 | Classification loss: 0.13775 | Regression loss: 0.24684 | Running loss: 0.30941\n",
            "Epoch: 12 | Iteration: 23 | Classification loss: 0.04688 | Regression loss: 0.18359 | Running loss: 0.30903\n",
            "Epoch: 12 | Iteration: 24 | Classification loss: 0.11717 | Regression loss: 0.27646 | Running loss: 0.30900\n",
            "Epoch: 12 | Iteration: 25 | Classification loss: 0.09319 | Regression loss: 0.26678 | Running loss: 0.30918\n",
            "Epoch: 12 | Iteration: 26 | Classification loss: 0.06563 | Regression loss: 0.13315 | Running loss: 0.30896\n",
            "Epoch: 12 | Iteration: 27 | Classification loss: 0.07990 | Regression loss: 0.14429 | Running loss: 0.30899\n",
            "Epoch: 12 | Iteration: 28 | Classification loss: 0.04531 | Regression loss: 0.13821 | Running loss: 0.30900\n",
            "Epoch: 12 | Iteration: 29 | Classification loss: 0.05270 | Regression loss: 0.22385 | Running loss: 0.30874\n",
            "Epoch: 12 | Iteration: 30 | Classification loss: 0.02609 | Regression loss: 0.14921 | Running loss: 0.30871\n",
            "Epoch: 12 | Iteration: 31 | Classification loss: 0.11809 | Regression loss: 0.21252 | Running loss: 0.30871\n",
            "Epoch: 12 | Iteration: 32 | Classification loss: 0.05187 | Regression loss: 0.14199 | Running loss: 0.30869\n",
            "Epoch: 12 | Iteration: 33 | Classification loss: 0.05477 | Regression loss: 0.18430 | Running loss: 0.30829\n",
            "Epoch: 12 | Iteration: 34 | Classification loss: 0.04765 | Regression loss: 0.16204 | Running loss: 0.30784\n",
            "Epoch: 12 | Iteration: 35 | Classification loss: 0.06161 | Regression loss: 0.15871 | Running loss: 0.30760\n",
            "Epoch: 12 | Iteration: 36 | Classification loss: 0.10688 | Regression loss: 0.21066 | Running loss: 0.30752\n",
            "Epoch: 12 | Iteration: 37 | Classification loss: 0.02731 | Regression loss: 0.12707 | Running loss: 0.30696\n",
            "Epoch: 12 | Iteration: 38 | Classification loss: 0.07608 | Regression loss: 0.24850 | Running loss: 0.30713\n",
            "Epoch: 12 | Iteration: 39 | Classification loss: 0.11129 | Regression loss: 0.33008 | Running loss: 0.30744\n",
            "Epoch: 12 | Iteration: 40 | Classification loss: 0.02941 | Regression loss: 0.20448 | Running loss: 0.30773\n",
            "Epoch: 12 | Iteration: 41 | Classification loss: 0.05930 | Regression loss: 0.14848 | Running loss: 0.30755\n",
            "Epoch: 12 | Iteration: 42 | Classification loss: 0.10302 | Regression loss: 0.18404 | Running loss: 0.30784\n",
            "Epoch: 12 | Iteration: 43 | Classification loss: 0.03486 | Regression loss: 0.15104 | Running loss: 0.30722\n",
            "Epoch: 12 | Iteration: 44 | Classification loss: 0.04441 | Regression loss: 0.16782 | Running loss: 0.30649\n",
            "Epoch: 12 | Iteration: 45 | Classification loss: 0.07477 | Regression loss: 0.23742 | Running loss: 0.30651\n",
            "Epoch: 12 | Iteration: 46 | Classification loss: 0.03923 | Regression loss: 0.10794 | Running loss: 0.30597\n",
            "Epoch: 12 | Iteration: 47 | Classification loss: 0.11229 | Regression loss: 0.22640 | Running loss: 0.30598\n",
            "Epoch: 12 | Iteration: 48 | Classification loss: 0.11348 | Regression loss: 0.13272 | Running loss: 0.30519\n",
            "Epoch: 12 | Iteration: 49 | Classification loss: 0.04249 | Regression loss: 0.17083 | Running loss: 0.30512\n",
            "Epoch: 12 | Iteration: 50 | Classification loss: 0.12315 | Regression loss: 0.31664 | Running loss: 0.30504\n",
            "Epoch: 12 | Iteration: 51 | Classification loss: 0.07773 | Regression loss: 0.22621 | Running loss: 0.30485\n",
            "Epoch: 12 | Iteration: 52 | Classification loss: 0.05825 | Regression loss: 0.11346 | Running loss: 0.30463\n",
            "Epoch: 12 | Iteration: 53 | Classification loss: 0.09411 | Regression loss: 0.17456 | Running loss: 0.30485\n",
            "Epoch: 12 | Iteration: 54 | Classification loss: 0.03781 | Regression loss: 0.12360 | Running loss: 0.30437\n",
            "Epoch: 12 | Iteration: 55 | Classification loss: 0.04339 | Regression loss: 0.17663 | Running loss: 0.30474\n",
            "Epoch: 12 | Iteration: 56 | Classification loss: 0.05549 | Regression loss: 0.16642 | Running loss: 0.30417\n",
            "Epoch: 12 | Iteration: 57 | Classification loss: 0.05466 | Regression loss: 0.14357 | Running loss: 0.30400\n",
            "Epoch: 12 | Iteration: 58 | Classification loss: 0.03748 | Regression loss: 0.11312 | Running loss: 0.30369\n",
            "Epoch: 12 | Iteration: 59 | Classification loss: 0.21726 | Regression loss: 0.27273 | Running loss: 0.30389\n",
            "Epoch: 12 | Iteration: 60 | Classification loss: 0.07420 | Regression loss: 0.16455 | Running loss: 0.30383\n",
            "Epoch: 12 | Iteration: 61 | Classification loss: 0.10846 | Regression loss: 0.29101 | Running loss: 0.30394\n",
            "Epoch: 12 | Iteration: 62 | Classification loss: 0.07164 | Regression loss: 0.14366 | Running loss: 0.30336\n",
            "Epoch: 12 | Iteration: 63 | Classification loss: 0.03128 | Regression loss: 0.12965 | Running loss: 0.30327\n",
            "Epoch: 12 | Iteration: 64 | Classification loss: 0.09745 | Regression loss: 0.31307 | Running loss: 0.30349\n",
            "Epoch: 12 | Iteration: 65 | Classification loss: 0.05174 | Regression loss: 0.14330 | Running loss: 0.30315\n",
            "Epoch: 12 | Iteration: 66 | Classification loss: 0.07128 | Regression loss: 0.21552 | Running loss: 0.30290\n",
            "Epoch: 12 | Iteration: 67 | Classification loss: 0.16867 | Regression loss: 0.31965 | Running loss: 0.30328\n",
            "Epoch: 12 | Iteration: 68 | Classification loss: 0.06767 | Regression loss: 0.12335 | Running loss: 0.30323\n",
            "Epoch: 12 | Iteration: 69 | Classification loss: 0.13348 | Regression loss: 0.25317 | Running loss: 0.30351\n",
            "Epoch: 12 | Iteration: 70 | Classification loss: 0.03591 | Regression loss: 0.10953 | Running loss: 0.30321\n",
            "Epoch: 12 | Iteration: 71 | Classification loss: 0.09837 | Regression loss: 0.23990 | Running loss: 0.30303\n",
            "Epoch: 12 | Iteration: 72 | Classification loss: 0.08537 | Regression loss: 0.17027 | Running loss: 0.30257\n",
            "Epoch: 12 | Iteration: 73 | Classification loss: 0.10533 | Regression loss: 0.22349 | Running loss: 0.30270\n",
            "Epoch: 12 | Iteration: 74 | Classification loss: 0.08106 | Regression loss: 0.20789 | Running loss: 0.30261\n",
            "Epoch: 12 | Iteration: 75 | Classification loss: 0.08849 | Regression loss: 0.16981 | Running loss: 0.30234\n",
            "Epoch: 12 | Iteration: 76 | Classification loss: 0.08719 | Regression loss: 0.18676 | Running loss: 0.30249\n",
            "Epoch: 12 | Iteration: 77 | Classification loss: 0.11447 | Regression loss: 0.25829 | Running loss: 0.30284\n",
            "Epoch: 12 | Iteration: 78 | Classification loss: 0.08016 | Regression loss: 0.16088 | Running loss: 0.30237\n",
            "Epoch: 12 | Iteration: 79 | Classification loss: 0.04987 | Regression loss: 0.23477 | Running loss: 0.30256\n",
            "Epoch: 12 | Iteration: 80 | Classification loss: 0.07349 | Regression loss: 0.19426 | Running loss: 0.30239\n",
            "Epoch: 12 | Iteration: 81 | Classification loss: 0.12275 | Regression loss: 0.27497 | Running loss: 0.30227\n",
            "Epoch: 12 | Iteration: 82 | Classification loss: 0.07270 | Regression loss: 0.23894 | Running loss: 0.30180\n",
            "Epoch: 12 | Iteration: 83 | Classification loss: 0.07852 | Regression loss: 0.12475 | Running loss: 0.30161\n",
            "Epoch: 12 | Iteration: 84 | Classification loss: 0.08023 | Regression loss: 0.22720 | Running loss: 0.30160\n",
            "Epoch: 12 | Iteration: 85 | Classification loss: 0.07456 | Regression loss: 0.24350 | Running loss: 0.30117\n",
            "Epoch: 12 | Iteration: 86 | Classification loss: 0.08529 | Regression loss: 0.12634 | Running loss: 0.30092\n",
            "Epoch: 12 | Iteration: 87 | Classification loss: 0.05042 | Regression loss: 0.11510 | Running loss: 0.30088\n",
            "Epoch: 12 | Iteration: 88 | Classification loss: 0.10058 | Regression loss: 0.13327 | Running loss: 0.30075\n",
            "Epoch: 12 | Iteration: 89 | Classification loss: 0.07743 | Regression loss: 0.17256 | Running loss: 0.30027\n",
            "Epoch: 12 | Iteration: 90 | Classification loss: 0.08437 | Regression loss: 0.23556 | Running loss: 0.30018\n",
            "Epoch: 12 | Iteration: 91 | Classification loss: 0.07970 | Regression loss: 0.17239 | Running loss: 0.30007\n",
            "Epoch: 12 | Iteration: 92 | Classification loss: 0.15841 | Regression loss: 0.20827 | Running loss: 0.30007\n",
            "Epoch: 12 | Iteration: 93 | Classification loss: 0.05464 | Regression loss: 0.12465 | Running loss: 0.29991\n",
            "Epoch: 12 | Iteration: 94 | Classification loss: 0.13436 | Regression loss: 0.26643 | Running loss: 0.30012\n",
            "Epoch: 12 | Iteration: 95 | Classification loss: 0.15264 | Regression loss: 0.28683 | Running loss: 0.30058\n",
            "Epoch: 12 | Iteration: 96 | Classification loss: 0.13181 | Regression loss: 0.30369 | Running loss: 0.30087\n",
            "Epoch: 12 | Iteration: 97 | Classification loss: 0.06261 | Regression loss: 0.11281 | Running loss: 0.30046\n",
            "Epoch: 12 | Iteration: 98 | Classification loss: 0.10349 | Regression loss: 0.25324 | Running loss: 0.30015\n",
            "Epoch: 12 | Iteration: 99 | Classification loss: 0.11002 | Regression loss: 0.30064 | Running loss: 0.30031\n",
            "Epoch: 12 | Iteration: 100 | Classification loss: 0.03722 | Regression loss: 0.17508 | Running loss: 0.29962\n",
            "Epoch: 12 | Iteration: 101 | Classification loss: 0.04735 | Regression loss: 0.13028 | Running loss: 0.29929\n",
            "Epoch: 12 | Iteration: 102 | Classification loss: 0.07561 | Regression loss: 0.13353 | Running loss: 0.29913\n",
            "Epoch: 12 | Iteration: 103 | Classification loss: 0.05964 | Regression loss: 0.11466 | Running loss: 0.29877\n",
            "Epoch: 12 | Iteration: 104 | Classification loss: 0.11705 | Regression loss: 0.18893 | Running loss: 0.29901\n",
            "Epoch: 12 | Iteration: 105 | Classification loss: 0.05155 | Regression loss: 0.23081 | Running loss: 0.29889\n",
            "Epoch: 12 | Iteration: 106 | Classification loss: 0.18077 | Regression loss: 0.29601 | Running loss: 0.29958\n",
            "Epoch: 12 | Iteration: 107 | Classification loss: 0.16344 | Regression loss: 0.38044 | Running loss: 0.30030\n",
            "Epoch: 12 | Iteration: 108 | Classification loss: 0.07969 | Regression loss: 0.21475 | Running loss: 0.30027\n",
            "Epoch: 12 | Iteration: 109 | Classification loss: 0.12349 | Regression loss: 0.26737 | Running loss: 0.30019\n",
            "Epoch: 12 | Iteration: 110 | Classification loss: 0.09702 | Regression loss: 0.19046 | Running loss: 0.29991\n",
            "Epoch: 12 | Iteration: 111 | Classification loss: 0.03669 | Regression loss: 0.16417 | Running loss: 0.29939\n",
            "Epoch: 12 | Iteration: 112 | Classification loss: 0.06537 | Regression loss: 0.20885 | Running loss: 0.29952\n",
            "Epoch: 12 | Iteration: 113 | Classification loss: 0.04119 | Regression loss: 0.14921 | Running loss: 0.29904\n",
            "Epoch: 12 | Iteration: 114 | Classification loss: 0.21761 | Regression loss: 0.24355 | Running loss: 0.29939\n",
            "Epoch: 12 | Iteration: 115 | Classification loss: 0.18427 | Regression loss: 0.22441 | Running loss: 0.29960\n",
            "Epoch: 12 | Iteration: 116 | Classification loss: 0.04252 | Regression loss: 0.04644 | Running loss: 0.29928\n",
            "Epoch: 12 | Iteration: 117 | Classification loss: 0.12930 | Regression loss: 0.26297 | Running loss: 0.29953\n",
            "Epoch: 12 | Iteration: 118 | Classification loss: 0.08760 | Regression loss: 0.14491 | Running loss: 0.29926\n",
            "Epoch: 12 | Iteration: 119 | Classification loss: 0.06813 | Regression loss: 0.15641 | Running loss: 0.29936\n",
            "Epoch: 12 | Iteration: 120 | Classification loss: 0.08741 | Regression loss: 0.21266 | Running loss: 0.29917\n",
            "Epoch: 12 | Iteration: 121 | Classification loss: 0.06778 | Regression loss: 0.15575 | Running loss: 0.29926\n",
            "Epoch: 12 | Iteration: 122 | Classification loss: 0.11745 | Regression loss: 0.19604 | Running loss: 0.29843\n",
            "Epoch: 12 | Iteration: 123 | Classification loss: 0.05737 | Regression loss: 0.11334 | Running loss: 0.29838\n",
            "Epoch: 12 | Iteration: 124 | Classification loss: 0.02384 | Regression loss: 0.10059 | Running loss: 0.29787\n",
            "Epoch: 12 | Iteration: 125 | Classification loss: 0.06018 | Regression loss: 0.12858 | Running loss: 0.29774\n",
            "Epoch: 12 | Iteration: 126 | Classification loss: 0.07955 | Regression loss: 0.21758 | Running loss: 0.29780\n",
            "Epoch: 12 | Iteration: 127 | Classification loss: 0.12957 | Regression loss: 0.29748 | Running loss: 0.29792\n",
            "Epoch: 12 | Iteration: 128 | Classification loss: 0.10707 | Regression loss: 0.15978 | Running loss: 0.29772\n",
            "Epoch: 12 | Iteration: 129 | Classification loss: 0.20582 | Regression loss: 0.36720 | Running loss: 0.29820\n",
            "Epoch: 12 | Iteration: 130 | Classification loss: 0.12152 | Regression loss: 0.27019 | Running loss: 0.29838\n",
            "Epoch: 12 | Iteration: 131 | Classification loss: 0.13329 | Regression loss: 0.17875 | Running loss: 0.29861\n",
            "Epoch: 12 | Iteration: 132 | Classification loss: 0.11602 | Regression loss: 0.18321 | Running loss: 0.29865\n",
            "Epoch: 12 | Iteration: 133 | Classification loss: 0.07336 | Regression loss: 0.19379 | Running loss: 0.29807\n",
            "Epoch: 12 | Iteration: 134 | Classification loss: 0.09629 | Regression loss: 0.20863 | Running loss: 0.29789\n",
            "Epoch: 12 | Iteration: 135 | Classification loss: 0.08533 | Regression loss: 0.18920 | Running loss: 0.29793\n",
            "Epoch: 12 | Iteration: 136 | Classification loss: 0.05252 | Regression loss: 0.10687 | Running loss: 0.29744\n",
            "Epoch: 12 | Iteration: 137 | Classification loss: 0.04091 | Regression loss: 0.13595 | Running loss: 0.29706\n",
            "Epoch: 12 | Iteration: 138 | Classification loss: 0.11061 | Regression loss: 0.13713 | Running loss: 0.29702\n",
            "Epoch: 12 | Iteration: 139 | Classification loss: 0.17989 | Regression loss: 0.10841 | Running loss: 0.29707\n",
            "Epoch: 12 | Iteration: 140 | Classification loss: 0.03836 | Regression loss: 0.10926 | Running loss: 0.29698\n",
            "Epoch: 12 | Iteration: 141 | Classification loss: 0.07099 | Regression loss: 0.17833 | Running loss: 0.29648\n",
            "Epoch: 12 | Iteration: 142 | Classification loss: 0.08894 | Regression loss: 0.20476 | Running loss: 0.29647\n",
            "Epoch: 12 | Iteration: 143 | Classification loss: 0.27182 | Regression loss: 0.37052 | Running loss: 0.29714\n",
            "Epoch: 12 | Iteration: 144 | Classification loss: 0.14402 | Regression loss: 0.19947 | Running loss: 0.29726\n",
            "Epoch: 12 | Iteration: 145 | Classification loss: 0.07378 | Regression loss: 0.16009 | Running loss: 0.29731\n",
            "Epoch: 12 | Iteration: 146 | Classification loss: 0.10347 | Regression loss: 0.16657 | Running loss: 0.29738\n",
            "Epoch: 12 | Iteration: 147 | Classification loss: 0.09248 | Regression loss: 0.24902 | Running loss: 0.29758\n",
            "Epoch: 12 | Iteration: 148 | Classification loss: 0.06454 | Regression loss: 0.16744 | Running loss: 0.29763\n",
            "Epoch: 12 | Iteration: 149 | Classification loss: 0.06349 | Regression loss: 0.20358 | Running loss: 0.29747\n",
            "Epoch: 12 | Iteration: 150 | Classification loss: 0.05151 | Regression loss: 0.14688 | Running loss: 0.29721\n",
            "Epoch: 12 | Iteration: 151 | Classification loss: 0.09027 | Regression loss: 0.20379 | Running loss: 0.29736\n",
            "Epoch: 12 | Iteration: 152 | Classification loss: 0.15205 | Regression loss: 0.15896 | Running loss: 0.29743\n",
            "Epoch: 12 | Iteration: 153 | Classification loss: 0.04771 | Regression loss: 0.23766 | Running loss: 0.29721\n",
            "Epoch: 12 | Iteration: 154 | Classification loss: 0.01884 | Regression loss: 0.07969 | Running loss: 0.29689\n",
            "Epoch: 12 | Iteration: 155 | Classification loss: 0.06656 | Regression loss: 0.22941 | Running loss: 0.29703\n",
            "Epoch: 12 | Iteration: 156 | Classification loss: 0.03910 | Regression loss: 0.13888 | Running loss: 0.29671\n",
            "Epoch: 12 | Iteration: 157 | Classification loss: 0.16981 | Regression loss: 0.33248 | Running loss: 0.29732\n",
            "Epoch: 12 | Iteration: 158 | Classification loss: 0.06648 | Regression loss: 0.19752 | Running loss: 0.29689\n",
            "Epoch: 12 | Iteration: 159 | Classification loss: 0.06719 | Regression loss: 0.18105 | Running loss: 0.29696\n",
            "Epoch: 12 | Iteration: 160 | Classification loss: 0.10178 | Regression loss: 0.28126 | Running loss: 0.29709\n",
            "Epoch: 12 | Iteration: 161 | Classification loss: 0.08460 | Regression loss: 0.21856 | Running loss: 0.29744\n",
            "Epoch: 12 | Iteration: 162 | Classification loss: 0.07009 | Regression loss: 0.23081 | Running loss: 0.29717\n",
            "Epoch: 12 | Iteration: 163 | Classification loss: 0.02506 | Regression loss: 0.12054 | Running loss: 0.29676\n",
            "Epoch: 12 | Iteration: 164 | Classification loss: 0.05764 | Regression loss: 0.17547 | Running loss: 0.29669\n",
            "Epoch: 12 | Iteration: 165 | Classification loss: 0.04555 | Regression loss: 0.12588 | Running loss: 0.29655\n",
            "Epoch: 12 | Iteration: 166 | Classification loss: 0.03542 | Regression loss: 0.17157 | Running loss: 0.29648\n",
            "Epoch: 12 | Iteration: 167 | Classification loss: 0.10612 | Regression loss: 0.22132 | Running loss: 0.29689\n",
            "Epoch: 12 | Iteration: 168 | Classification loss: 0.10749 | Regression loss: 0.17988 | Running loss: 0.29721\n",
            "Epoch: 12 | Iteration: 169 | Classification loss: 0.04160 | Regression loss: 0.17953 | Running loss: 0.29712\n",
            "Epoch: 12 | Iteration: 170 | Classification loss: 0.02330 | Regression loss: 0.11530 | Running loss: 0.29678\n",
            "Epoch: 12 | Iteration: 171 | Classification loss: 0.10150 | Regression loss: 0.12508 | Running loss: 0.29682\n",
            "Epoch: 12 | Iteration: 172 | Classification loss: 0.06444 | Regression loss: 0.17812 | Running loss: 0.29618\n",
            "Epoch: 12 | Iteration: 173 | Classification loss: 0.12911 | Regression loss: 0.35908 | Running loss: 0.29556\n",
            "Epoch: 12 | Iteration: 174 | Classification loss: 0.06423 | Regression loss: 0.20363 | Running loss: 0.29530\n",
            "Epoch: 12 | Iteration: 175 | Classification loss: 0.03102 | Regression loss: 0.11609 | Running loss: 0.29492\n",
            "Epoch: 12 | Iteration: 176 | Classification loss: 0.16070 | Regression loss: 0.25003 | Running loss: 0.29528\n",
            "Epoch: 12 | Iteration: 177 | Classification loss: 0.18759 | Regression loss: 0.34888 | Running loss: 0.29582\n",
            "Epoch: 12 | Iteration: 178 | Classification loss: 0.04942 | Regression loss: 0.08525 | Running loss: 0.29576\n",
            "Epoch: 12 | Iteration: 179 | Classification loss: 0.01998 | Regression loss: 0.13431 | Running loss: 0.29460\n",
            "Epoch: 12 | Iteration: 180 | Classification loss: 0.11035 | Regression loss: 0.19774 | Running loss: 0.29499\n",
            "Epoch: 12 | Iteration: 181 | Classification loss: 0.02000 | Regression loss: 0.10603 | Running loss: 0.29478\n",
            "Epoch: 12 | Iteration: 182 | Classification loss: 0.14868 | Regression loss: 0.23483 | Running loss: 0.29437\n",
            "Epoch: 12 | Iteration: 183 | Classification loss: 0.02375 | Regression loss: 0.10413 | Running loss: 0.29413\n",
            "Epoch: 12 | Iteration: 184 | Classification loss: 0.13160 | Regression loss: 0.20570 | Running loss: 0.29429\n",
            "Epoch: 12 | Iteration: 185 | Classification loss: 0.10280 | Regression loss: 0.19202 | Running loss: 0.29434\n",
            "Epoch: 12 | Iteration: 186 | Classification loss: 0.09846 | Regression loss: 0.21436 | Running loss: 0.29436\n",
            "Epoch: 12 | Iteration: 187 | Classification loss: 0.05346 | Regression loss: 0.17491 | Running loss: 0.29424\n",
            "Epoch: 12 | Iteration: 188 | Classification loss: 0.11226 | Regression loss: 0.25715 | Running loss: 0.29452\n",
            "Epoch: 12 | Iteration: 189 | Classification loss: 0.05642 | Regression loss: 0.17086 | Running loss: 0.29459\n",
            "Epoch: 12 | Iteration: 190 | Classification loss: 0.02729 | Regression loss: 0.10579 | Running loss: 0.29427\n",
            "Epoch: 12 | Iteration: 191 | Classification loss: 0.01294 | Regression loss: 0.06871 | Running loss: 0.29347\n",
            "Epoch: 12 | Iteration: 192 | Classification loss: 0.06236 | Regression loss: 0.13162 | Running loss: 0.29319\n",
            "Epoch: 12 | Iteration: 193 | Classification loss: 0.06402 | Regression loss: 0.13831 | Running loss: 0.29295\n",
            "Epoch: 12 | Iteration: 194 | Classification loss: 0.04290 | Regression loss: 0.12711 | Running loss: 0.29285\n",
            "Epoch: 12 | Iteration: 195 | Classification loss: 0.04361 | Regression loss: 0.12440 | Running loss: 0.29263\n",
            "Epoch: 12 | Iteration: 196 | Classification loss: 0.05121 | Regression loss: 0.15472 | Running loss: 0.29275\n",
            "Epoch: 12 | Iteration: 197 | Classification loss: 0.16634 | Regression loss: 0.34875 | Running loss: 0.29298\n",
            "Epoch: 12 | Iteration: 198 | Classification loss: 0.06178 | Regression loss: 0.22402 | Running loss: 0.29312\n",
            "Epoch: 12 | Iteration: 199 | Classification loss: 0.04972 | Regression loss: 0.23365 | Running loss: 0.29310\n",
            "Epoch: 12 | Iteration: 200 | Classification loss: 0.13511 | Regression loss: 0.33492 | Running loss: 0.29368\n",
            "Epoch: 12 | Iteration: 201 | Classification loss: 0.08351 | Regression loss: 0.15640 | Running loss: 0.29350\n",
            "Epoch: 12 | Iteration: 202 | Classification loss: 0.02522 | Regression loss: 0.14648 | Running loss: 0.29338\n",
            "Epoch: 12 | Iteration: 203 | Classification loss: 0.05843 | Regression loss: 0.19236 | Running loss: 0.29359\n",
            "Epoch: 12 | Iteration: 204 | Classification loss: 0.14903 | Regression loss: 0.23076 | Running loss: 0.29385\n",
            "Epoch: 12 | Iteration: 205 | Classification loss: 0.05841 | Regression loss: 0.16446 | Running loss: 0.29409\n",
            "Epoch: 12 | Iteration: 206 | Classification loss: 0.07797 | Regression loss: 0.15734 | Running loss: 0.29415\n",
            "Epoch: 12 | Iteration: 207 | Classification loss: 0.09422 | Regression loss: 0.26081 | Running loss: 0.29443\n",
            "Epoch: 12 | Iteration: 208 | Classification loss: 0.06029 | Regression loss: 0.22864 | Running loss: 0.29423\n",
            "Epoch: 12 | Iteration: 209 | Classification loss: 0.02661 | Regression loss: 0.10404 | Running loss: 0.29408\n",
            "Epoch: 12 | Iteration: 210 | Classification loss: 0.08436 | Regression loss: 0.12535 | Running loss: 0.29394\n",
            "Epoch: 12 | Iteration: 211 | Classification loss: 0.03468 | Regression loss: 0.13899 | Running loss: 0.29354\n",
            "Epoch: 12 | Iteration: 212 | Classification loss: 0.04807 | Regression loss: 0.17731 | Running loss: 0.29365\n",
            "Epoch: 12 | Iteration: 213 | Classification loss: 0.12418 | Regression loss: 0.16758 | Running loss: 0.29325\n",
            "Epoch: 12 | Iteration: 214 | Classification loss: 0.10868 | Regression loss: 0.19477 | Running loss: 0.29308\n",
            "Epoch: 12 | Iteration: 215 | Classification loss: 0.26082 | Regression loss: 0.41327 | Running loss: 0.29333\n",
            "Epoch: 12 | Iteration: 216 | Classification loss: 0.09414 | Regression loss: 0.19017 | Running loss: 0.29328\n",
            "Epoch: 12 | Iteration: 217 | Classification loss: 0.20239 | Regression loss: 0.38232 | Running loss: 0.29348\n",
            "Epoch: 12 | Iteration: 218 | Classification loss: 0.08419 | Regression loss: 0.20957 | Running loss: 0.29344\n",
            "Epoch: 12 | Iteration: 219 | Classification loss: 0.07721 | Regression loss: 0.16437 | Running loss: 0.29341\n",
            "Epoch: 12 | Iteration: 220 | Classification loss: 0.04633 | Regression loss: 0.17111 | Running loss: 0.29294\n",
            "Epoch: 12 | Iteration: 221 | Classification loss: 0.01835 | Regression loss: 0.14432 | Running loss: 0.29236\n",
            "Epoch: 12 | Iteration: 222 | Classification loss: 0.22242 | Regression loss: 0.40923 | Running loss: 0.29266\n",
            "Epoch: 12 | Iteration: 223 | Classification loss: 0.08077 | Regression loss: 0.17801 | Running loss: 0.29228\n",
            "Epoch: 12 | Iteration: 224 | Classification loss: 0.14890 | Regression loss: 0.24912 | Running loss: 0.29205\n",
            "Epoch: 12 | Iteration: 225 | Classification loss: 0.10247 | Regression loss: 0.12266 | Running loss: 0.29206\n",
            "Epoch: 12 | Iteration: 226 | Classification loss: 0.17314 | Regression loss: 0.20156 | Running loss: 0.29217\n",
            "Epoch: 12 | Iteration: 227 | Classification loss: 0.14221 | Regression loss: 0.25856 | Running loss: 0.29240\n",
            "Epoch: 12 | Iteration: 228 | Classification loss: 0.12585 | Regression loss: 0.21996 | Running loss: 0.29240\n",
            "Epoch: 12 | Iteration: 229 | Classification loss: 0.22487 | Regression loss: 0.07900 | Running loss: 0.29265\n",
            "Epoch: 12 | Iteration: 230 | Classification loss: 0.04881 | Regression loss: 0.11689 | Running loss: 0.29239\n",
            "Epoch: 12 | Iteration: 231 | Classification loss: 0.07068 | Regression loss: 0.18493 | Running loss: 0.29233\n",
            "Epoch: 12 | Iteration: 232 | Classification loss: 0.03985 | Regression loss: 0.15329 | Running loss: 0.29191\n",
            "Epoch: 12 | Iteration: 233 | Classification loss: 0.10180 | Regression loss: 0.28263 | Running loss: 0.29200\n",
            "Epoch: 12 | Iteration: 234 | Classification loss: 0.11999 | Regression loss: 0.28107 | Running loss: 0.29226\n",
            "Epoch: 12 | Iteration: 235 | Classification loss: 0.10140 | Regression loss: 0.23142 | Running loss: 0.29260\n",
            "Epoch: 12 | Iteration: 236 | Classification loss: 0.08586 | Regression loss: 0.21857 | Running loss: 0.29271\n",
            "Epoch: 12 | Iteration: 237 | Classification loss: 0.08762 | Regression loss: 0.16846 | Running loss: 0.29267\n",
            "Epoch: 12 | Iteration: 238 | Classification loss: 0.14045 | Regression loss: 0.29638 | Running loss: 0.29312\n",
            "Epoch: 12 | Iteration: 239 | Classification loss: 0.03006 | Regression loss: 0.12209 | Running loss: 0.29307\n",
            "Epoch: 12 | Iteration: 240 | Classification loss: 0.06144 | Regression loss: 0.18473 | Running loss: 0.29281\n",
            "Epoch: 12 | Iteration: 241 | Classification loss: 0.16855 | Regression loss: 0.32186 | Running loss: 0.29289\n",
            "Epoch: 12 | Iteration: 242 | Classification loss: 0.11076 | Regression loss: 0.28769 | Running loss: 0.29343\n",
            "Epoch: 12 | Iteration: 243 | Classification loss: 0.09123 | Regression loss: 0.17436 | Running loss: 0.29344\n",
            "Epoch: 12 | Iteration: 244 | Classification loss: 0.08637 | Regression loss: 0.17750 | Running loss: 0.29317\n",
            "Epoch: 12 | Iteration: 245 | Classification loss: 0.06859 | Regression loss: 0.20835 | Running loss: 0.29331\n",
            "Epoch: 12 | Iteration: 246 | Classification loss: 0.09368 | Regression loss: 0.27799 | Running loss: 0.29336\n",
            "Epoch: 12 | Iteration: 247 | Classification loss: 0.06600 | Regression loss: 0.15930 | Running loss: 0.29347\n",
            "Epoch: 12 | Iteration: 248 | Classification loss: 0.04981 | Regression loss: 0.13317 | Running loss: 0.29342\n",
            "Epoch: 12 | Iteration: 249 | Classification loss: 0.10790 | Regression loss: 0.14175 | Running loss: 0.29326\n",
            "Epoch: 12 | Iteration: 250 | Classification loss: 0.05909 | Regression loss: 0.11216 | Running loss: 0.29324\n",
            "Epoch: 12 | Iteration: 251 | Classification loss: 0.04975 | Regression loss: 0.11295 | Running loss: 0.29286\n",
            "Epoch: 12 | Iteration: 252 | Classification loss: 0.03231 | Regression loss: 0.13609 | Running loss: 0.29245\n",
            "Epoch: 12 | Iteration: 253 | Classification loss: 0.07392 | Regression loss: 0.21809 | Running loss: 0.29241\n",
            "Epoch: 12 | Iteration: 254 | Classification loss: 0.11479 | Regression loss: 0.28517 | Running loss: 0.29267\n",
            "Epoch: 12 | Iteration: 255 | Classification loss: 0.04402 | Regression loss: 0.14071 | Running loss: 0.29241\n",
            "Epoch: 12 | Iteration: 256 | Classification loss: 0.33427 | Regression loss: 0.49972 | Running loss: 0.29372\n",
            "Epoch: 12 | Iteration: 257 | Classification loss: 0.05489 | Regression loss: 0.16311 | Running loss: 0.29377\n",
            "Epoch: 12 | Iteration: 258 | Classification loss: 0.06201 | Regression loss: 0.10815 | Running loss: 0.29368\n",
            "Epoch: 12 | Iteration: 259 | Classification loss: 0.12342 | Regression loss: 0.20634 | Running loss: 0.29366\n",
            "Epoch: 12 | Iteration: 260 | Classification loss: 0.07732 | Regression loss: 0.16549 | Running loss: 0.29352\n",
            "Epoch: 12 | Iteration: 261 | Classification loss: 0.03551 | Regression loss: 0.12013 | Running loss: 0.29334\n",
            "Epoch: 12 | Iteration: 262 | Classification loss: 0.07013 | Regression loss: 0.18481 | Running loss: 0.29328\n",
            "Epoch: 12 | Iteration: 263 | Classification loss: 0.05525 | Regression loss: 0.19063 | Running loss: 0.29313\n",
            "Epoch: 12 | Iteration: 264 | Classification loss: 0.08922 | Regression loss: 0.19221 | Running loss: 0.29308\n",
            "Epoch: 12 | Iteration: 265 | Classification loss: 0.05491 | Regression loss: 0.19840 | Running loss: 0.29321\n",
            "Epoch: 12 | Iteration: 266 | Classification loss: 0.08516 | Regression loss: 0.18493 | Running loss: 0.29321\n",
            "Epoch: 12 | Iteration: 267 | Classification loss: 0.17233 | Regression loss: 0.36045 | Running loss: 0.29360\n",
            "Epoch: 12 | Iteration: 268 | Classification loss: 0.05032 | Regression loss: 0.13136 | Running loss: 0.29316\n",
            "Epoch: 12 | Iteration: 269 | Classification loss: 0.03576 | Regression loss: 0.12337 | Running loss: 0.29321\n",
            "Epoch: 12 | Iteration: 270 | Classification loss: 0.09189 | Regression loss: 0.26086 | Running loss: 0.29359\n",
            "Epoch: 12 | Iteration: 271 | Classification loss: 0.20873 | Regression loss: 0.36667 | Running loss: 0.29448\n",
            "Epoch: 12 | Iteration: 272 | Classification loss: 0.03814 | Regression loss: 0.09562 | Running loss: 0.29421\n",
            "Epoch: 12 | Iteration: 273 | Classification loss: 0.04643 | Regression loss: 0.14955 | Running loss: 0.29424\n",
            "Epoch: 12 | Iteration: 274 | Classification loss: 0.05665 | Regression loss: 0.18800 | Running loss: 0.29434\n",
            "Epoch: 12 | Iteration: 275 | Classification loss: 0.05152 | Regression loss: 0.18580 | Running loss: 0.29452\n",
            "Epoch: 12 | Iteration: 276 | Classification loss: 0.12232 | Regression loss: 0.27277 | Running loss: 0.29462\n",
            "Epoch: 12 | Iteration: 277 | Classification loss: 0.04360 | Regression loss: 0.17031 | Running loss: 0.29416\n",
            "Epoch: 12 | Iteration: 278 | Classification loss: 0.12681 | Regression loss: 0.20259 | Running loss: 0.29446\n",
            "Epoch: 12 | Iteration: 279 | Classification loss: 0.05017 | Regression loss: 0.17121 | Running loss: 0.29445\n",
            "Epoch: 12 | Iteration: 280 | Classification loss: 0.21492 | Regression loss: 0.16009 | Running loss: 0.29461\n",
            "Epoch: 12 | Iteration: 281 | Classification loss: 0.07383 | Regression loss: 0.22685 | Running loss: 0.29450\n",
            "Epoch: 12 | Iteration: 282 | Classification loss: 0.03150 | Regression loss: 0.12604 | Running loss: 0.29445\n",
            "Epoch: 12 | Iteration: 283 | Classification loss: 0.03053 | Regression loss: 0.06253 | Running loss: 0.29381\n",
            "Epoch: 12 | Iteration: 284 | Classification loss: 0.06934 | Regression loss: 0.21674 | Running loss: 0.29371\n",
            "Epoch: 12 | Iteration: 285 | Classification loss: 0.04844 | Regression loss: 0.12536 | Running loss: 0.29360\n",
            "Epoch: 12 | Iteration: 286 | Classification loss: 0.12008 | Regression loss: 0.24182 | Running loss: 0.29376\n",
            "Epoch: 12 | Iteration: 287 | Classification loss: 0.08428 | Regression loss: 0.20060 | Running loss: 0.29392\n",
            "Epoch: 12 | Iteration: 288 | Classification loss: 0.08052 | Regression loss: 0.20381 | Running loss: 0.29351\n",
            "Epoch: 12 | Iteration: 289 | Classification loss: 0.09533 | Regression loss: 0.21322 | Running loss: 0.29367\n",
            "Epoch: 12 | Iteration: 290 | Classification loss: 0.14710 | Regression loss: 0.31009 | Running loss: 0.29415\n",
            "Epoch: 12 | Iteration: 291 | Classification loss: 0.07209 | Regression loss: 0.13098 | Running loss: 0.29417\n",
            "Epoch: 12 | Iteration: 292 | Classification loss: 0.04321 | Regression loss: 0.13698 | Running loss: 0.29419\n",
            "Epoch: 12 | Iteration: 293 | Classification loss: 0.11075 | Regression loss: 0.10348 | Running loss: 0.29426\n",
            "Epoch: 12 | Iteration: 294 | Classification loss: 0.08616 | Regression loss: 0.30757 | Running loss: 0.29454\n",
            "Epoch: 12 | Iteration: 295 | Classification loss: 0.05881 | Regression loss: 0.15961 | Running loss: 0.29427\n",
            "Epoch: 12 | Iteration: 296 | Classification loss: 0.08719 | Regression loss: 0.18164 | Running loss: 0.29402\n",
            "Epoch: 12 | Iteration: 297 | Classification loss: 0.03762 | Regression loss: 0.21253 | Running loss: 0.29398\n",
            "Epoch: 12 | Iteration: 298 | Classification loss: 0.11194 | Regression loss: 0.29551 | Running loss: 0.29389\n",
            "Epoch: 12 | Iteration: 299 | Classification loss: 0.03826 | Regression loss: 0.17783 | Running loss: 0.29393\n",
            "Epoch: 12 | Iteration: 300 | Classification loss: 0.14243 | Regression loss: 0.32893 | Running loss: 0.29425\n",
            "Epoch: 12 | Iteration: 301 | Classification loss: 0.04551 | Regression loss: 0.18089 | Running loss: 0.29389\n",
            "Epoch: 12 | Iteration: 302 | Classification loss: 0.12243 | Regression loss: 0.22788 | Running loss: 0.29409\n",
            "Epoch: 12 | Iteration: 303 | Classification loss: 0.09255 | Regression loss: 0.24749 | Running loss: 0.29450\n",
            "Epoch: 12 | Iteration: 304 | Classification loss: 0.24465 | Regression loss: 0.37077 | Running loss: 0.29507\n",
            "Epoch: 12 | Iteration: 305 | Classification loss: 0.09071 | Regression loss: 0.19648 | Running loss: 0.29525\n",
            "Epoch: 12 | Iteration: 306 | Classification loss: 0.10731 | Regression loss: 0.17494 | Running loss: 0.29478\n",
            "Epoch: 12 | Iteration: 307 | Classification loss: 0.08029 | Regression loss: 0.20853 | Running loss: 0.29479\n",
            "Epoch: 12 | Iteration: 308 | Classification loss: 0.06659 | Regression loss: 0.14906 | Running loss: 0.29468\n",
            "Epoch: 12 | Iteration: 309 | Classification loss: 0.10583 | Regression loss: 0.20750 | Running loss: 0.29453\n",
            "Epoch: 12 | Iteration: 310 | Classification loss: 0.21331 | Regression loss: 0.37195 | Running loss: 0.29515\n",
            "Epoch: 12 | Iteration: 311 | Classification loss: 0.04876 | Regression loss: 0.10157 | Running loss: 0.29521\n",
            "Epoch: 12 | Iteration: 312 | Classification loss: 0.05004 | Regression loss: 0.20129 | Running loss: 0.29498\n",
            "Epoch: 12 | Iteration: 313 | Classification loss: 0.15212 | Regression loss: 0.30810 | Running loss: 0.29555\n",
            "Epoch: 12 | Iteration: 314 | Classification loss: 0.13204 | Regression loss: 0.24397 | Running loss: 0.29535\n",
            "Epoch: 12 | Iteration: 315 | Classification loss: 0.19848 | Regression loss: 0.32601 | Running loss: 0.29569\n",
            "Epoch: 12 | Iteration: 316 | Classification loss: 0.09580 | Regression loss: 0.19237 | Running loss: 0.29599\n",
            "Epoch: 12 | Iteration: 317 | Classification loss: 0.09579 | Regression loss: 0.16307 | Running loss: 0.29612\n",
            "Epoch: 12 | Iteration: 318 | Classification loss: 0.10279 | Regression loss: 0.15662 | Running loss: 0.29597\n",
            "Epoch: 12 | Iteration: 319 | Classification loss: 0.03089 | Regression loss: 0.08574 | Running loss: 0.29595\n",
            "Epoch: 12 | Iteration: 320 | Classification loss: 0.07607 | Regression loss: 0.21661 | Running loss: 0.29597\n",
            "Epoch: 12 | Iteration: 321 | Classification loss: 0.00472 | Regression loss: 0.10031 | Running loss: 0.29549\n",
            "Epoch: 12 | Iteration: 322 | Classification loss: 0.07571 | Regression loss: 0.29993 | Running loss: 0.29595\n",
            "Epoch: 12 | Iteration: 323 | Classification loss: 0.10030 | Regression loss: 0.24642 | Running loss: 0.29609\n",
            "Epoch: 12 | Iteration: 324 | Classification loss: 0.06588 | Regression loss: 0.11833 | Running loss: 0.29576\n",
            "Epoch: 12 | Iteration: 325 | Classification loss: 0.05178 | Regression loss: 0.10861 | Running loss: 0.29544\n",
            "Epoch: 12 | Iteration: 326 | Classification loss: 0.06463 | Regression loss: 0.09903 | Running loss: 0.29493\n",
            "Epoch: 12 | Iteration: 327 | Classification loss: 0.10205 | Regression loss: 0.21677 | Running loss: 0.29517\n",
            "Epoch: 12 | Iteration: 328 | Classification loss: 0.04052 | Regression loss: 0.18668 | Running loss: 0.29515\n",
            "Epoch: 12 | Iteration: 329 | Classification loss: 0.16475 | Regression loss: 0.25181 | Running loss: 0.29539\n",
            "Epoch: 12 | Iteration: 330 | Classification loss: 0.12625 | Regression loss: 0.26676 | Running loss: 0.29566\n",
            "Epoch: 12 | Iteration: 331 | Classification loss: 0.09421 | Regression loss: 0.24194 | Running loss: 0.29584\n",
            "Epoch: 12 | Iteration: 332 | Classification loss: 0.02960 | Regression loss: 0.14371 | Running loss: 0.29554\n",
            "Epoch: 12 | Iteration: 333 | Classification loss: 0.05524 | Regression loss: 0.14566 | Running loss: 0.29495\n",
            "Epoch: 12 | Iteration: 334 | Classification loss: 0.03272 | Regression loss: 0.11826 | Running loss: 0.29472\n",
            "Epoch: 12 | Iteration: 335 | Classification loss: 0.08350 | Regression loss: 0.17603 | Running loss: 0.29470\n",
            "Epoch: 12 | Iteration: 336 | Classification loss: 0.06320 | Regression loss: 0.17249 | Running loss: 0.29451\n",
            "Epoch: 12 | Iteration: 337 | Classification loss: 0.07109 | Regression loss: 0.22187 | Running loss: 0.29454\n",
            "Epoch: 12 | Iteration: 338 | Classification loss: 0.10408 | Regression loss: 0.22289 | Running loss: 0.29484\n",
            "Epoch: 12 | Iteration: 339 | Classification loss: 0.03745 | Regression loss: 0.15744 | Running loss: 0.29487\n",
            "Epoch: 12 | Iteration: 340 | Classification loss: 0.02472 | Regression loss: 0.09480 | Running loss: 0.29405\n",
            "Epoch: 12 | Iteration: 341 | Classification loss: 0.07691 | Regression loss: 0.22834 | Running loss: 0.29390\n",
            "Epoch: 12 | Iteration: 342 | Classification loss: 0.12002 | Regression loss: 0.30865 | Running loss: 0.29372\n",
            "Epoch: 12 | Iteration: 343 | Classification loss: 0.05628 | Regression loss: 0.15284 | Running loss: 0.29348\n",
            "Epoch: 12 | Iteration: 344 | Classification loss: 0.09005 | Regression loss: 0.17404 | Running loss: 0.29315\n",
            "Epoch: 12 | Iteration: 345 | Classification loss: 0.04484 | Regression loss: 0.16085 | Running loss: 0.29308\n",
            "Epoch: 12 | Iteration: 346 | Classification loss: 0.12582 | Regression loss: 0.25917 | Running loss: 0.29341\n",
            "Epoch: 12 | Iteration: 347 | Classification loss: 0.09296 | Regression loss: 0.23319 | Running loss: 0.29330\n",
            "Epoch: 12 | Iteration: 348 | Classification loss: 0.11682 | Regression loss: 0.07939 | Running loss: 0.29296\n",
            "Epoch: 12 | Iteration: 349 | Classification loss: 0.16933 | Regression loss: 0.40862 | Running loss: 0.29379\n",
            "Epoch: 12 | Iteration: 350 | Classification loss: 0.09543 | Regression loss: 0.24485 | Running loss: 0.29379\n",
            "Epoch: 12 | Iteration: 351 | Classification loss: 0.07772 | Regression loss: 0.18534 | Running loss: 0.29393\n",
            "Epoch: 12 | Iteration: 352 | Classification loss: 0.12704 | Regression loss: 0.18926 | Running loss: 0.29405\n",
            "Epoch: 12 | Iteration: 353 | Classification loss: 0.04038 | Regression loss: 0.12280 | Running loss: 0.29364\n",
            "Epoch: 12 | Iteration: 354 | Classification loss: 0.14003 | Regression loss: 0.24765 | Running loss: 0.29401\n",
            "Epoch: 12 | Iteration: 355 | Classification loss: 0.04667 | Regression loss: 0.12401 | Running loss: 0.29377\n",
            "Epoch: 12 | Iteration: 356 | Classification loss: 0.11928 | Regression loss: 0.18297 | Running loss: 0.29392\n",
            "Epoch: 12 | Iteration: 357 | Classification loss: 0.04411 | Regression loss: 0.11782 | Running loss: 0.29382\n",
            "Epoch: 12 | Iteration: 358 | Classification loss: 0.19217 | Regression loss: 0.24396 | Running loss: 0.29404\n",
            "Epoch: 12 | Iteration: 359 | Classification loss: 0.05678 | Regression loss: 0.17380 | Running loss: 0.29398\n",
            "Epoch: 12 | Iteration: 360 | Classification loss: 0.04308 | Regression loss: 0.11548 | Running loss: 0.29377\n",
            "Epoch: 12 | Iteration: 361 | Classification loss: 0.10138 | Regression loss: 0.22996 | Running loss: 0.29369\n",
            "Epoch: 12 | Iteration: 362 | Classification loss: 0.11064 | Regression loss: 0.22146 | Running loss: 0.29374\n",
            "Epoch: 12 | Iteration: 363 | Classification loss: 0.09878 | Regression loss: 0.29729 | Running loss: 0.29347\n",
            "Epoch: 12 | Iteration: 364 | Classification loss: 0.04929 | Regression loss: 0.14639 | Running loss: 0.29330\n",
            "Epoch: 12 | Iteration: 365 | Classification loss: 0.06724 | Regression loss: 0.19088 | Running loss: 0.29315\n",
            "Epoch: 12 | Iteration: 366 | Classification loss: 0.15784 | Regression loss: 0.32719 | Running loss: 0.29364\n",
            "Epoch: 12 | Iteration: 367 | Classification loss: 0.07295 | Regression loss: 0.15101 | Running loss: 0.29337\n",
            "Epoch: 12 | Iteration: 368 | Classification loss: 0.16112 | Regression loss: 0.38594 | Running loss: 0.29391\n",
            "Epoch: 12 | Iteration: 369 | Classification loss: 0.03232 | Regression loss: 0.12055 | Running loss: 0.29357\n",
            "Epoch: 12 | Iteration: 370 | Classification loss: 0.14893 | Regression loss: 0.28708 | Running loss: 0.29349\n",
            "Epoch: 12 | Iteration: 371 | Classification loss: 0.09723 | Regression loss: 0.11718 | Running loss: 0.29347\n",
            "Epoch: 12 | Iteration: 372 | Classification loss: 0.04265 | Regression loss: 0.09842 | Running loss: 0.29354\n",
            "Epoch: 12 | Iteration: 373 | Classification loss: 0.06152 | Regression loss: 0.21760 | Running loss: 0.29367\n",
            "Epoch: 12 | Iteration: 374 | Classification loss: 0.10461 | Regression loss: 0.22229 | Running loss: 0.29334\n",
            "Epoch: 12 | Iteration: 375 | Classification loss: 0.10083 | Regression loss: 0.25854 | Running loss: 0.29350\n",
            "Epoch: 12 | Iteration: 376 | Classification loss: 0.10717 | Regression loss: 0.12541 | Running loss: 0.29326\n",
            "Epoch: 12 | Iteration: 377 | Classification loss: 0.07354 | Regression loss: 0.27008 | Running loss: 0.29357\n",
            "Epoch: 12 | Iteration: 378 | Classification loss: 0.24328 | Regression loss: 0.38823 | Running loss: 0.29438\n",
            "Epoch: 12 | Iteration: 379 | Classification loss: 0.09734 | Regression loss: 0.24260 | Running loss: 0.29450\n",
            "Epoch: 12 | Iteration: 380 | Classification loss: 0.09465 | Regression loss: 0.24332 | Running loss: 0.29471\n",
            "Epoch: 12 | Iteration: 381 | Classification loss: 0.17419 | Regression loss: 0.29868 | Running loss: 0.29492\n",
            "Epoch: 12 | Iteration: 382 | Classification loss: 0.13548 | Regression loss: 0.24472 | Running loss: 0.29501\n",
            "Epoch: 12 | Iteration: 383 | Classification loss: 0.10410 | Regression loss: 0.25843 | Running loss: 0.29510\n",
            "Epoch: 12 | Iteration: 384 | Classification loss: 0.06399 | Regression loss: 0.24186 | Running loss: 0.29506\n",
            "Epoch: 12 | Iteration: 385 | Classification loss: 0.06722 | Regression loss: 0.16051 | Running loss: 0.29484\n",
            "Epoch: 12 | Iteration: 386 | Classification loss: 0.07143 | Regression loss: 0.18947 | Running loss: 0.29499\n",
            "Epoch: 12 | Iteration: 387 | Classification loss: 0.05434 | Regression loss: 0.18514 | Running loss: 0.29472\n",
            "Epoch: 12 | Iteration: 388 | Classification loss: 0.12300 | Regression loss: 0.31213 | Running loss: 0.29422\n",
            "Epoch: 12 | Iteration: 389 | Classification loss: 0.14961 | Regression loss: 0.27002 | Running loss: 0.29457\n",
            "Epoch: 12 | Iteration: 390 | Classification loss: 0.06570 | Regression loss: 0.24639 | Running loss: 0.29453\n",
            "Epoch: 12 | Iteration: 391 | Classification loss: 0.11279 | Regression loss: 0.19334 | Running loss: 0.29428\n",
            "Epoch: 12 | Iteration: 392 | Classification loss: 0.03546 | Regression loss: 0.16059 | Running loss: 0.29404\n",
            "Epoch: 12 | Iteration: 393 | Classification loss: 0.11549 | Regression loss: 0.20262 | Running loss: 0.29428\n",
            "Epoch: 12 | Iteration: 394 | Classification loss: 0.13192 | Regression loss: 0.18981 | Running loss: 0.29455\n",
            "Epoch: 12 | Iteration: 395 | Classification loss: 0.13091 | Regression loss: 0.23540 | Running loss: 0.29443\n",
            "Epoch: 12 | Iteration: 396 | Classification loss: 0.04095 | Regression loss: 0.15509 | Running loss: 0.29445\n",
            "Epoch: 12 | Iteration: 397 | Classification loss: 0.07834 | Regression loss: 0.17903 | Running loss: 0.29458\n",
            "Epoch: 12 | Iteration: 398 | Classification loss: 0.07523 | Regression loss: 0.14900 | Running loss: 0.29426\n",
            "Epoch: 12 | Iteration: 399 | Classification loss: 0.21503 | Regression loss: 0.32340 | Running loss: 0.29464\n",
            "Epoch: 12 | Iteration: 400 | Classification loss: 0.07755 | Regression loss: 0.15384 | Running loss: 0.29445\n",
            "Epoch: 12 | Iteration: 401 | Classification loss: 0.07378 | Regression loss: 0.15523 | Running loss: 0.29439\n",
            "Epoch: 12 | Iteration: 402 | Classification loss: 0.03912 | Regression loss: 0.15616 | Running loss: 0.29414\n",
            "Epoch: 12 | Iteration: 403 | Classification loss: 0.01912 | Regression loss: 0.12556 | Running loss: 0.29380\n",
            "Epoch: 12 | Iteration: 404 | Classification loss: 0.09510 | Regression loss: 0.34319 | Running loss: 0.29391\n",
            "Epoch: 12 | Iteration: 405 | Classification loss: 0.12912 | Regression loss: 0.14228 | Running loss: 0.29400\n",
            "Epoch: 12 | Iteration: 406 | Classification loss: 0.08095 | Regression loss: 0.11403 | Running loss: 0.29384\n",
            "Epoch: 12 | Iteration: 407 | Classification loss: 0.07106 | Regression loss: 0.10078 | Running loss: 0.29293\n",
            "Epoch: 12 | Iteration: 408 | Classification loss: 0.11072 | Regression loss: 0.17205 | Running loss: 0.29275\n",
            "Epoch: 12 | Iteration: 409 | Classification loss: 0.06227 | Regression loss: 0.17629 | Running loss: 0.29261\n",
            "Epoch: 12 | Iteration: 410 | Classification loss: 0.09274 | Regression loss: 0.20473 | Running loss: 0.29283\n",
            "Epoch: 12 | Iteration: 411 | Classification loss: 0.07778 | Regression loss: 0.15160 | Running loss: 0.29268\n",
            "Epoch: 12 | Iteration: 412 | Classification loss: 0.06194 | Regression loss: 0.16857 | Running loss: 0.29220\n",
            "Epoch: 12 | Iteration: 413 | Classification loss: 0.02530 | Regression loss: 0.09358 | Running loss: 0.29144\n",
            "Epoch: 12 | Iteration: 414 | Classification loss: 0.16520 | Regression loss: 0.29013 | Running loss: 0.29176\n",
            "Epoch: 12 | Iteration: 415 | Classification loss: 0.10113 | Regression loss: 0.27617 | Running loss: 0.29200\n",
            "Epoch: 12 | Iteration: 416 | Classification loss: 0.09751 | Regression loss: 0.23857 | Running loss: 0.29229\n",
            "Epoch: 12 | Iteration: 417 | Classification loss: 0.02318 | Regression loss: 0.11007 | Running loss: 0.29210\n",
            "Epoch: 12 | Iteration: 418 | Classification loss: 0.06355 | Regression loss: 0.12813 | Running loss: 0.29193\n",
            "Epoch: 12 | Iteration: 419 | Classification loss: 0.07073 | Regression loss: 0.22292 | Running loss: 0.29180\n",
            "Epoch: 12 | Iteration: 420 | Classification loss: 0.03665 | Regression loss: 0.11144 | Running loss: 0.29186\n",
            "Epoch: 12 | Iteration: 421 | Classification loss: 0.04508 | Regression loss: 0.13094 | Running loss: 0.29145\n",
            "Epoch: 12 | Iteration: 422 | Classification loss: 0.11540 | Regression loss: 0.29510 | Running loss: 0.29143\n",
            "Epoch: 12 | Iteration: 423 | Classification loss: 0.09348 | Regression loss: 0.06595 | Running loss: 0.29133\n",
            "Epoch: 12 | Iteration: 424 | Classification loss: 0.06037 | Regression loss: 0.25225 | Running loss: 0.29060\n",
            "Epoch: 12 | Iteration: 425 | Classification loss: 0.09816 | Regression loss: 0.16563 | Running loss: 0.29073\n",
            "Epoch: 12 | Iteration: 426 | Classification loss: 0.18962 | Regression loss: 0.33245 | Running loss: 0.29148\n",
            "Epoch: 12 | Iteration: 427 | Classification loss: 0.09524 | Regression loss: 0.15984 | Running loss: 0.29095\n",
            "Epoch: 12 | Iteration: 428 | Classification loss: 0.05358 | Regression loss: 0.14059 | Running loss: 0.29110\n",
            "Epoch: 12 | Iteration: 429 | Classification loss: 0.13554 | Regression loss: 0.33170 | Running loss: 0.29147\n",
            "Epoch: 12 | Iteration: 430 | Classification loss: 0.04903 | Regression loss: 0.07089 | Running loss: 0.29106\n",
            "Epoch: 12 | Iteration: 431 | Classification loss: 0.02460 | Regression loss: 0.10556 | Running loss: 0.29034\n",
            "Epoch: 12 | Iteration: 432 | Classification loss: 0.05116 | Regression loss: 0.12901 | Running loss: 0.28986\n",
            "Epoch: 12 | Iteration: 433 | Classification loss: 0.10530 | Regression loss: 0.11923 | Running loss: 0.28977\n",
            "Epoch: 12 | Iteration: 434 | Classification loss: 0.03119 | Regression loss: 0.13554 | Running loss: 0.28968\n",
            "Epoch: 12 | Iteration: 435 | Classification loss: 0.08486 | Regression loss: 0.27689 | Running loss: 0.28980\n",
            "Epoch: 12 | Iteration: 436 | Classification loss: 0.11266 | Regression loss: 0.25802 | Running loss: 0.29018\n",
            "Epoch: 12 | Iteration: 437 | Classification loss: 0.06250 | Regression loss: 0.13379 | Running loss: 0.28979\n",
            "Epoch: 12 | Iteration: 438 | Classification loss: 0.03066 | Regression loss: 0.15582 | Running loss: 0.28955\n",
            "Epoch: 12 | Iteration: 439 | Classification loss: 0.08233 | Regression loss: 0.13461 | Running loss: 0.28940\n",
            "Epoch: 12 | Iteration: 440 | Classification loss: 0.12510 | Regression loss: 0.20310 | Running loss: 0.28942\n",
            "Epoch: 12 | Iteration: 441 | Classification loss: 0.19368 | Regression loss: 0.33111 | Running loss: 0.28967\n",
            "Epoch: 12 | Iteration: 442 | Classification loss: 0.05609 | Regression loss: 0.10386 | Running loss: 0.28941\n",
            "Epoch: 12 | Iteration: 443 | Classification loss: 0.09191 | Regression loss: 0.20400 | Running loss: 0.28915\n",
            "Epoch: 12 | Iteration: 444 | Classification loss: 0.04739 | Regression loss: 0.18989 | Running loss: 0.28889\n",
            "Epoch: 12 | Iteration: 445 | Classification loss: 0.06947 | Regression loss: 0.19030 | Running loss: 0.28889\n",
            "Epoch: 12 | Iteration: 446 | Classification loss: 0.12733 | Regression loss: 0.17910 | Running loss: 0.28859\n",
            "Epoch: 12 | Iteration: 447 | Classification loss: 0.04786 | Regression loss: 0.05557 | Running loss: 0.28836\n",
            "Epoch: 12 | Iteration: 448 | Classification loss: 0.04718 | Regression loss: 0.23513 | Running loss: 0.28844\n",
            "Epoch: 12 | Iteration: 449 | Classification loss: 0.09342 | Regression loss: 0.22632 | Running loss: 0.28847\n",
            "Epoch: 12 | Iteration: 450 | Classification loss: 0.09622 | Regression loss: 0.21611 | Running loss: 0.28814\n",
            "Epoch: 12 | Iteration: 451 | Classification loss: 0.12891 | Regression loss: 0.26231 | Running loss: 0.28834\n",
            "Epoch: 12 | Iteration: 452 | Classification loss: 0.19720 | Regression loss: 0.28530 | Running loss: 0.28894\n",
            "Epoch: 12 | Iteration: 453 | Classification loss: 0.03987 | Regression loss: 0.15352 | Running loss: 0.28845\n",
            "Epoch: 12 | Iteration: 454 | Classification loss: 0.03855 | Regression loss: 0.11059 | Running loss: 0.28858\n",
            "Epoch: 12 | Iteration: 455 | Classification loss: 0.07307 | Regression loss: 0.21669 | Running loss: 0.28861\n",
            "Epoch: 12 | Iteration: 456 | Classification loss: 0.08800 | Regression loss: 0.24436 | Running loss: 0.28871\n",
            "Epoch: 12 | Iteration: 457 | Classification loss: 0.05473 | Regression loss: 0.14719 | Running loss: 0.28825\n",
            "Epoch: 12 | Iteration: 458 | Classification loss: 0.13740 | Regression loss: 0.26409 | Running loss: 0.28834\n",
            "Epoch: 12 | Iteration: 459 | Classification loss: 0.03290 | Regression loss: 0.13812 | Running loss: 0.28786\n",
            "Epoch: 12 | Iteration: 460 | Classification loss: 0.09597 | Regression loss: 0.20820 | Running loss: 0.28736\n",
            "Epoch: 12 | Iteration: 461 | Classification loss: 0.02437 | Regression loss: 0.09924 | Running loss: 0.28735\n",
            "Epoch: 12 | Iteration: 462 | Classification loss: 0.03901 | Regression loss: 0.07182 | Running loss: 0.28688\n",
            "Epoch: 12 | Iteration: 463 | Classification loss: 0.04355 | Regression loss: 0.15169 | Running loss: 0.28681\n",
            "Epoch: 12 | Iteration: 464 | Classification loss: 0.04540 | Regression loss: 0.10927 | Running loss: 0.28631\n",
            "Epoch: 12 | Iteration: 465 | Classification loss: 0.09515 | Regression loss: 0.25254 | Running loss: 0.28636\n",
            "Epoch: 12 | Iteration: 466 | Classification loss: 0.08181 | Regression loss: 0.14971 | Running loss: 0.28595\n",
            "Epoch: 12 | Iteration: 467 | Classification loss: 0.06144 | Regression loss: 0.12532 | Running loss: 0.28583\n",
            "Epoch: 12 | Iteration: 468 | Classification loss: 0.07020 | Regression loss: 0.18343 | Running loss: 0.28587\n",
            "Epoch: 12 | Iteration: 469 | Classification loss: 0.13424 | Regression loss: 0.32197 | Running loss: 0.28600\n",
            "Epoch: 12 | Iteration: 470 | Classification loss: 0.02554 | Regression loss: 0.15262 | Running loss: 0.28580\n",
            "Epoch: 12 | Iteration: 471 | Classification loss: 0.07050 | Regression loss: 0.18616 | Running loss: 0.28531\n",
            "Epoch: 12 | Iteration: 472 | Classification loss: 0.12345 | Regression loss: 0.23015 | Running loss: 0.28540\n",
            "Epoch: 12 | Iteration: 473 | Classification loss: 0.09552 | Regression loss: 0.16155 | Running loss: 0.28558\n",
            "Epoch: 12 | Iteration: 474 | Classification loss: 0.08227 | Regression loss: 0.13485 | Running loss: 0.28585\n",
            "Epoch: 12 | Iteration: 475 | Classification loss: 0.05342 | Regression loss: 0.17282 | Running loss: 0.28548\n",
            "Epoch: 12 | Iteration: 476 | Classification loss: 0.11641 | Regression loss: 0.17498 | Running loss: 0.28560\n",
            "Epoch: 12 | Iteration: 477 | Classification loss: 0.01515 | Regression loss: 0.11964 | Running loss: 0.28561\n",
            "Epoch: 12 | Iteration: 478 | Classification loss: 0.05743 | Regression loss: 0.17346 | Running loss: 0.28524\n",
            "Epoch: 12 | Iteration: 479 | Classification loss: 0.07873 | Regression loss: 0.12432 | Running loss: 0.28519\n",
            "Epoch: 12 | Iteration: 480 | Classification loss: 0.14308 | Regression loss: 0.28394 | Running loss: 0.28523\n",
            "Epoch: 12 | Iteration: 481 | Classification loss: 0.12086 | Regression loss: 0.22854 | Running loss: 0.28555\n",
            "Epoch: 12 | Iteration: 482 | Classification loss: 0.08717 | Regression loss: 0.28253 | Running loss: 0.28576\n",
            "Epoch: 12 | Iteration: 483 | Classification loss: 0.08037 | Regression loss: 0.18798 | Running loss: 0.28517\n",
            "Epoch: 12 | Iteration: 484 | Classification loss: 0.08048 | Regression loss: 0.16818 | Running loss: 0.28514\n",
            "Epoch: 12 | Iteration: 485 | Classification loss: 0.08021 | Regression loss: 0.10928 | Running loss: 0.28494\n",
            "Epoch: 12 | Iteration: 486 | Classification loss: 0.07245 | Regression loss: 0.14788 | Running loss: 0.28464\n",
            "Epoch: 12 | Iteration: 487 | Classification loss: 0.09590 | Regression loss: 0.20501 | Running loss: 0.28484\n",
            "Epoch: 12 | Iteration: 488 | Classification loss: 0.08480 | Regression loss: 0.23182 | Running loss: 0.28487\n",
            "Epoch: 12 | Iteration: 489 | Classification loss: 0.17148 | Regression loss: 0.31558 | Running loss: 0.28532\n",
            "Epoch: 12 | Iteration: 490 | Classification loss: 0.06391 | Regression loss: 0.17977 | Running loss: 0.28534\n",
            "Epoch: 12 | Iteration: 491 | Classification loss: 0.17687 | Regression loss: 0.28699 | Running loss: 0.28583\n",
            "Epoch: 12 | Iteration: 492 | Classification loss: 0.03998 | Regression loss: 0.16664 | Running loss: 0.28551\n",
            "Epoch: 12 | Iteration: 493 | Classification loss: 0.09799 | Regression loss: 0.22229 | Running loss: 0.28545\n",
            "Epoch: 12 | Iteration: 494 | Classification loss: 0.02186 | Regression loss: 0.12557 | Running loss: 0.28491\n",
            "Epoch: 12 | Iteration: 495 | Classification loss: 0.05930 | Regression loss: 0.13731 | Running loss: 0.28470\n",
            "Epoch: 12 | Iteration: 496 | Classification loss: 0.08495 | Regression loss: 0.16444 | Running loss: 0.28478\n",
            "Epoch: 12 | Iteration: 497 | Classification loss: 0.06362 | Regression loss: 0.21807 | Running loss: 0.28450\n",
            "Epoch: 12 | Iteration: 498 | Classification loss: 0.12453 | Regression loss: 0.28035 | Running loss: 0.28463\n",
            "Epoch: 12 | Iteration: 499 | Classification loss: 0.03105 | Regression loss: 0.14994 | Running loss: 0.28424\n",
            "Epoch: 12 | Iteration: 500 | Classification loss: 0.11228 | Regression loss: 0.26683 | Running loss: 0.28420\n",
            "Epoch: 12 | Iteration: 501 | Classification loss: 0.07752 | Regression loss: 0.28245 | Running loss: 0.28461\n",
            "Epoch: 12 | Iteration: 502 | Classification loss: 0.14513 | Regression loss: 0.24279 | Running loss: 0.28488\n",
            "Epoch: 12 | Iteration: 503 | Classification loss: 0.02923 | Regression loss: 0.18426 | Running loss: 0.28464\n",
            "Epoch: 12 | Iteration: 504 | Classification loss: 0.13091 | Regression loss: 0.32821 | Running loss: 0.28509\n",
            "Epoch: 12 | Iteration: 505 | Classification loss: 0.04109 | Regression loss: 0.18480 | Running loss: 0.28507\n",
            "Epoch: 12 | Iteration: 506 | Classification loss: 0.10064 | Regression loss: 0.13556 | Running loss: 0.28504\n",
            "Epoch: 12 | Iteration: 507 | Classification loss: 0.05854 | Regression loss: 0.15985 | Running loss: 0.28465\n",
            "Epoch: 12 | Iteration: 508 | Classification loss: 0.06679 | Regression loss: 0.12469 | Running loss: 0.28437\n",
            "Epoch: 12 | Iteration: 509 | Classification loss: 0.04708 | Regression loss: 0.12736 | Running loss: 0.28386\n",
            "Epoch: 12 | Iteration: 510 | Classification loss: 0.01811 | Regression loss: 0.08162 | Running loss: 0.28364\n",
            "Epoch: 12 | Iteration: 511 | Classification loss: 0.07172 | Regression loss: 0.19127 | Running loss: 0.28329\n",
            "Epoch: 12 | Iteration: 512 | Classification loss: 0.03068 | Regression loss: 0.12379 | Running loss: 0.28297\n",
            "Epoch: 12 | Iteration: 513 | Classification loss: 0.11708 | Regression loss: 0.31475 | Running loss: 0.28301\n",
            "Epoch: 12 | Iteration: 514 | Classification loss: 0.09968 | Regression loss: 0.28144 | Running loss: 0.28300\n",
            "Epoch: 12 | Iteration: 515 | Classification loss: 0.05441 | Regression loss: 0.14643 | Running loss: 0.28282\n",
            "Epoch: 12 | Iteration: 516 | Classification loss: 0.02093 | Regression loss: 0.08461 | Running loss: 0.28236\n",
            "Epoch: 12 | Iteration: 517 | Classification loss: 0.05908 | Regression loss: 0.13787 | Running loss: 0.28224\n",
            "Epoch: 12 | Iteration: 518 | Classification loss: 0.04089 | Regression loss: 0.16373 | Running loss: 0.28203\n",
            "Epoch: 12 | Iteration: 519 | Classification loss: 0.15930 | Regression loss: 0.22950 | Running loss: 0.28217\n",
            "Epoch: 12 | Iteration: 520 | Classification loss: 0.08621 | Regression loss: 0.22085 | Running loss: 0.28234\n",
            "Epoch: 12 | Iteration: 521 | Classification loss: 0.13606 | Regression loss: 0.23443 | Running loss: 0.28193\n",
            "Epoch: 12 | Iteration: 522 | Classification loss: 0.03289 | Regression loss: 0.18057 | Running loss: 0.28159\n",
            "Epoch: 12 | Iteration: 523 | Classification loss: 0.06538 | Regression loss: 0.17376 | Running loss: 0.28161\n",
            "Epoch: 12 | Iteration: 524 | Classification loss: 0.11293 | Regression loss: 0.23631 | Running loss: 0.28152\n",
            "Epoch: 12 | Iteration: 525 | Classification loss: 0.12340 | Regression loss: 0.26981 | Running loss: 0.28158\n",
            "Epoch: 12 | Iteration: 526 | Classification loss: 0.06130 | Regression loss: 0.16350 | Running loss: 0.28164\n",
            "Epoch: 12 | Iteration: 527 | Classification loss: 0.22557 | Regression loss: 0.44036 | Running loss: 0.28252\n",
            "Epoch: 12 | Iteration: 528 | Classification loss: 0.02340 | Regression loss: 0.09347 | Running loss: 0.28239\n",
            "Epoch: 12 | Iteration: 529 | Classification loss: 0.07691 | Regression loss: 0.18058 | Running loss: 0.28235\n",
            "Epoch: 12 | Iteration: 530 | Classification loss: 0.12832 | Regression loss: 0.18808 | Running loss: 0.28263\n",
            "Epoch: 12 | Iteration: 531 | Classification loss: 0.13097 | Regression loss: 0.27534 | Running loss: 0.28278\n",
            "Epoch: 12 | Iteration: 532 | Classification loss: 0.11607 | Regression loss: 0.23362 | Running loss: 0.28309\n",
            "Epoch: 12 | Iteration: 533 | Classification loss: 0.09213 | Regression loss: 0.25014 | Running loss: 0.28330\n",
            "Epoch: 12 | Iteration: 534 | Classification loss: 0.03872 | Regression loss: 0.15308 | Running loss: 0.28326\n",
            "Epoch: 12 | Iteration: 535 | Classification loss: 0.06409 | Regression loss: 0.19109 | Running loss: 0.28333\n",
            "Epoch: 12 | Iteration: 536 | Classification loss: 0.08761 | Regression loss: 0.19359 | Running loss: 0.28326\n",
            "Epoch: 12 | Iteration: 537 | Classification loss: 0.03272 | Regression loss: 0.10909 | Running loss: 0.28324\n",
            "Epoch: 12 | Iteration: 538 | Classification loss: 0.13392 | Regression loss: 0.22259 | Running loss: 0.28330\n",
            "Epoch: 12 | Iteration: 539 | Classification loss: 0.12993 | Regression loss: 0.28390 | Running loss: 0.28324\n",
            "Epoch: 12 | Iteration: 540 | Classification loss: 0.07663 | Regression loss: 0.20896 | Running loss: 0.28335\n",
            "Epoch: 12 | Iteration: 541 | Classification loss: 0.24352 | Regression loss: 0.35552 | Running loss: 0.28413\n",
            "Epoch: 12 | Iteration: 542 | Classification loss: 0.08655 | Regression loss: 0.19938 | Running loss: 0.28413\n",
            "Epoch: 12 | Iteration: 543 | Classification loss: 0.03800 | Regression loss: 0.19128 | Running loss: 0.28421\n",
            "Epoch: 12 | Iteration: 544 | Classification loss: 0.03669 | Regression loss: 0.18254 | Running loss: 0.28423\n",
            "Epoch: 12 | Iteration: 545 | Classification loss: 0.12895 | Regression loss: 0.26735 | Running loss: 0.28440\n",
            "Epoch: 12 | Iteration: 546 | Classification loss: 0.12233 | Regression loss: 0.30541 | Running loss: 0.28496\n",
            "Epoch: 12 | Iteration: 547 | Classification loss: 0.11528 | Regression loss: 0.34429 | Running loss: 0.28520\n",
            "Epoch: 12 | Iteration: 548 | Classification loss: 0.08446 | Regression loss: 0.17553 | Running loss: 0.28523\n",
            "Epoch: 12 | Iteration: 549 | Classification loss: 0.14686 | Regression loss: 0.25136 | Running loss: 0.28560\n",
            "Epoch: 12 | Iteration: 550 | Classification loss: 0.07640 | Regression loss: 0.10108 | Running loss: 0.28507\n",
            "Epoch: 12 | Iteration: 551 | Classification loss: 0.10019 | Regression loss: 0.20430 | Running loss: 0.28507\n",
            "Epoch: 12 | Iteration: 552 | Classification loss: 0.07566 | Regression loss: 0.17382 | Running loss: 0.28523\n",
            "Epoch: 12 | Iteration: 553 | Classification loss: 0.12727 | Regression loss: 0.26038 | Running loss: 0.28547\n",
            "Epoch: 12 | Iteration: 554 | Classification loss: 0.08773 | Regression loss: 0.22733 | Running loss: 0.28577\n",
            "Epoch: 12 | Iteration: 555 | Classification loss: 0.12795 | Regression loss: 0.34364 | Running loss: 0.28628\n",
            "Epoch: 12 | Iteration: 556 | Classification loss: 0.18065 | Regression loss: 0.29895 | Running loss: 0.28679\n",
            "Epoch: 12 | Iteration: 557 | Classification loss: 0.13475 | Regression loss: 0.24334 | Running loss: 0.28715\n",
            "Epoch: 12 | Iteration: 558 | Classification loss: 0.19601 | Regression loss: 0.40249 | Running loss: 0.28805\n",
            "Epoch: 12 | Iteration: 559 | Classification loss: 0.03878 | Regression loss: 0.14492 | Running loss: 0.28744\n",
            "Epoch: 12 | Iteration: 560 | Classification loss: 0.09606 | Regression loss: 0.19980 | Running loss: 0.28755\n",
            "Epoch: 12 | Iteration: 561 | Classification loss: 0.04562 | Regression loss: 0.10686 | Running loss: 0.28706\n",
            "Epoch: 12 | Iteration: 562 | Classification loss: 0.05813 | Regression loss: 0.17755 | Running loss: 0.28710\n",
            "Epoch: 12 | Iteration: 563 | Classification loss: 0.13971 | Regression loss: 0.26421 | Running loss: 0.28758\n",
            "Epoch: 12 | Iteration: 564 | Classification loss: 0.08772 | Regression loss: 0.22163 | Running loss: 0.28738\n",
            "Epoch: 12 | Iteration: 565 | Classification loss: 0.10414 | Regression loss: 0.24212 | Running loss: 0.28768\n",
            "Epoch: 12 | Iteration: 566 | Classification loss: 0.04602 | Regression loss: 0.15730 | Running loss: 0.28752\n",
            "Epoch: 12 | Iteration: 567 | Classification loss: 0.13091 | Regression loss: 0.18427 | Running loss: 0.28717\n",
            "Epoch: 12 | Iteration: 568 | Classification loss: 0.05870 | Regression loss: 0.17425 | Running loss: 0.28725\n",
            "Epoch: 12 | Iteration: 569 | Classification loss: 0.09477 | Regression loss: 0.28730 | Running loss: 0.28724\n",
            "Epoch: 12 | Iteration: 570 | Classification loss: 0.07402 | Regression loss: 0.12185 | Running loss: 0.28734\n",
            "Epoch: 12 | Iteration: 571 | Classification loss: 0.02791 | Regression loss: 0.15238 | Running loss: 0.28703\n",
            "Epoch: 12 | Iteration: 572 | Classification loss: 0.12174 | Regression loss: 0.24783 | Running loss: 0.28726\n",
            "Epoch: 12 | Iteration: 573 | Classification loss: 0.02593 | Regression loss: 0.07273 | Running loss: 0.28680\n",
            "Epoch: 12 | Iteration: 574 | Classification loss: 0.09028 | Regression loss: 0.31862 | Running loss: 0.28704\n",
            "Epoch: 12 | Iteration: 575 | Classification loss: 0.06824 | Regression loss: 0.13297 | Running loss: 0.28692\n",
            "Epoch: 12 | Iteration: 576 | Classification loss: 0.13250 | Regression loss: 0.22035 | Running loss: 0.28708\n",
            "Epoch: 12 | Iteration: 577 | Classification loss: 0.03583 | Regression loss: 0.13812 | Running loss: 0.28668\n",
            "Epoch: 12 | Iteration: 578 | Classification loss: 0.11695 | Regression loss: 0.15252 | Running loss: 0.28674\n",
            "Epoch: 12 | Iteration: 579 | Classification loss: 0.15702 | Regression loss: 0.30827 | Running loss: 0.28710\n",
            "Epoch: 12 | Iteration: 580 | Classification loss: 0.05282 | Regression loss: 0.19313 | Running loss: 0.28706\n",
            "Epoch: 12 | Iteration: 581 | Classification loss: 0.27069 | Regression loss: 0.49526 | Running loss: 0.28779\n",
            "Epoch: 12 | Iteration: 582 | Classification loss: 0.05093 | Regression loss: 0.08577 | Running loss: 0.28744\n",
            "Epoch: 12 | Iteration: 583 | Classification loss: 0.09563 | Regression loss: 0.18412 | Running loss: 0.28760\n",
            "Epoch: 12 | Iteration: 584 | Classification loss: 0.06288 | Regression loss: 0.19259 | Running loss: 0.28749\n",
            "Epoch: 12 | Iteration: 585 | Classification loss: 0.14192 | Regression loss: 0.24937 | Running loss: 0.28764\n",
            "Epoch: 12 | Iteration: 586 | Classification loss: 0.05832 | Regression loss: 0.10846 | Running loss: 0.28755\n",
            "Epoch: 12 | Iteration: 587 | Classification loss: 0.08792 | Regression loss: 0.15781 | Running loss: 0.28771\n",
            "Epoch: 12 | Iteration: 588 | Classification loss: 0.11764 | Regression loss: 0.26842 | Running loss: 0.28801\n",
            "Epoch: 12 | Iteration: 589 | Classification loss: 0.07652 | Regression loss: 0.16230 | Running loss: 0.28799\n",
            "Epoch: 12 | Iteration: 590 | Classification loss: 0.08387 | Regression loss: 0.21030 | Running loss: 0.28794\n",
            "Epoch: 12 | Iteration: 591 | Classification loss: 0.02187 | Regression loss: 0.12005 | Running loss: 0.28772\n",
            "Epoch: 12 | Iteration: 592 | Classification loss: 0.01952 | Regression loss: 0.13265 | Running loss: 0.28729\n",
            "Epoch: 12 | Iteration: 593 | Classification loss: 0.07827 | Regression loss: 0.20532 | Running loss: 0.28750\n",
            "Epoch: 12 | Iteration: 594 | Classification loss: 0.10741 | Regression loss: 0.26886 | Running loss: 0.28745\n",
            "Epoch: 12 | Iteration: 595 | Classification loss: 0.08722 | Regression loss: 0.22968 | Running loss: 0.28721\n",
            "Epoch: 12 | Iteration: 596 | Classification loss: 0.13402 | Regression loss: 0.23925 | Running loss: 0.28708\n",
            "Epoch: 12 | Iteration: 597 | Classification loss: 0.18223 | Regression loss: 0.34483 | Running loss: 0.28778\n",
            "Epoch: 12 | Iteration: 598 | Classification loss: 0.03489 | Regression loss: 0.13194 | Running loss: 0.28740\n",
            "Epoch: 12 | Iteration: 599 | Classification loss: 0.04700 | Regression loss: 0.24848 | Running loss: 0.28717\n",
            "Epoch: 12 | Iteration: 600 | Classification loss: 0.03224 | Regression loss: 0.14513 | Running loss: 0.28710\n",
            "Epoch: 12 | Iteration: 601 | Classification loss: 0.10619 | Regression loss: 0.21182 | Running loss: 0.28738\n",
            "Epoch: 12 | Iteration: 602 | Classification loss: 0.08806 | Regression loss: 0.27086 | Running loss: 0.28768\n",
            "Epoch: 12 | Iteration: 603 | Classification loss: 0.06321 | Regression loss: 0.17496 | Running loss: 0.28781\n",
            "Epoch: 12 | Iteration: 604 | Classification loss: 0.02857 | Regression loss: 0.13679 | Running loss: 0.28753\n",
            "Epoch: 12 | Iteration: 605 | Classification loss: 0.07641 | Regression loss: 0.14446 | Running loss: 0.28741\n",
            "Epoch: 12 | Iteration: 606 | Classification loss: 0.07366 | Regression loss: 0.18277 | Running loss: 0.28697\n",
            "Epoch: 12 | Iteration: 607 | Classification loss: 0.09839 | Regression loss: 0.20660 | Running loss: 0.28649\n",
            "Epoch: 12 | Iteration: 608 | Classification loss: 0.08694 | Regression loss: 0.19610 | Running loss: 0.28647\n",
            "Epoch: 12 | Iteration: 609 | Classification loss: 0.11418 | Regression loss: 0.20613 | Running loss: 0.28633\n",
            "Epoch: 12 | Iteration: 610 | Classification loss: 0.10090 | Regression loss: 0.26011 | Running loss: 0.28647\n",
            "Epoch: 12 | Iteration: 611 | Classification loss: 0.03498 | Regression loss: 0.21104 | Running loss: 0.28656\n",
            "Epoch: 12 | Iteration: 612 | Classification loss: 0.11600 | Regression loss: 0.24295 | Running loss: 0.28673\n",
            "Epoch: 12 | Iteration: 613 | Classification loss: 0.07502 | Regression loss: 0.23224 | Running loss: 0.28697\n",
            "Epoch: 12 | Iteration: 614 | Classification loss: 0.21502 | Regression loss: 0.40266 | Running loss: 0.28728\n",
            "Epoch: 12 | Iteration: 615 | Classification loss: 0.04731 | Regression loss: 0.22596 | Running loss: 0.28701\n",
            "Epoch: 12 | Iteration: 616 | Classification loss: 0.09055 | Regression loss: 0.21759 | Running loss: 0.28745\n",
            "Epoch: 12 | Iteration: 617 | Classification loss: 0.09851 | Regression loss: 0.13977 | Running loss: 0.28714\n",
            "Epoch: 12 | Iteration: 618 | Classification loss: 0.04487 | Regression loss: 0.17701 | Running loss: 0.28712\n",
            "Epoch: 12 | Iteration: 619 | Classification loss: 0.07859 | Regression loss: 0.12202 | Running loss: 0.28707\n",
            "Epoch: 12 | Iteration: 620 | Classification loss: 0.07634 | Regression loss: 0.18764 | Running loss: 0.28700\n",
            "Epoch: 12 | Iteration: 621 | Classification loss: 0.09458 | Regression loss: 0.20932 | Running loss: 0.28716\n",
            "Epoch: 12 | Iteration: 622 | Classification loss: 0.12621 | Regression loss: 0.29141 | Running loss: 0.28737\n",
            "Epoch: 12 | Iteration: 623 | Classification loss: 0.03076 | Regression loss: 0.13830 | Running loss: 0.28736\n",
            "Epoch: 12 | Iteration: 624 | Classification loss: 0.02523 | Regression loss: 0.12916 | Running loss: 0.28742\n",
            "Epoch: 12 | Iteration: 625 | Classification loss: 0.03061 | Regression loss: 0.10292 | Running loss: 0.28731\n",
            "Epoch: 12 | Iteration: 626 | Classification loss: 0.05683 | Regression loss: 0.14489 | Running loss: 0.28712\n",
            "Epoch: 12 | Iteration: 627 | Classification loss: 0.07686 | Regression loss: 0.16720 | Running loss: 0.28676\n",
            "Epoch: 12 | Iteration: 628 | Classification loss: 0.05525 | Regression loss: 0.15468 | Running loss: 0.28664\n",
            "Epoch: 12 | Iteration: 629 | Classification loss: 0.08881 | Regression loss: 0.21916 | Running loss: 0.28611\n",
            "Epoch: 12 | Iteration: 630 | Classification loss: 0.06589 | Regression loss: 0.13076 | Running loss: 0.28572\n",
            "Epoch: 12 | Iteration: 631 | Classification loss: 0.05788 | Regression loss: 0.11903 | Running loss: 0.28545\n",
            "Epoch: 12 | Iteration: 632 | Classification loss: 0.11242 | Regression loss: 0.22964 | Running loss: 0.28554\n",
            "Epoch: 12 | Iteration: 633 | Classification loss: 0.05156 | Regression loss: 0.15572 | Running loss: 0.28542\n",
            "Epoch: 12 | Iteration: 634 | Classification loss: 0.08787 | Regression loss: 0.20403 | Running loss: 0.28539\n",
            "Epoch: 12 | Iteration: 635 | Classification loss: 0.05372 | Regression loss: 0.12425 | Running loss: 0.28520\n",
            "Epoch: 12 | Iteration: 636 | Classification loss: 0.07259 | Regression loss: 0.15282 | Running loss: 0.28533\n",
            "Epoch: 12 | Iteration: 637 | Classification loss: 0.12866 | Regression loss: 0.19828 | Running loss: 0.28563\n",
            "Epoch: 12 | Iteration: 638 | Classification loss: 0.21326 | Regression loss: 0.33052 | Running loss: 0.28622\n",
            "Epoch: 12 | Iteration: 639 | Classification loss: 0.06644 | Regression loss: 0.28019 | Running loss: 0.28634\n",
            "Epoch: 12 | Iteration: 640 | Classification loss: 0.24013 | Regression loss: 0.38403 | Running loss: 0.28729\n",
            "Epoch: 12 | Iteration: 641 | Classification loss: 0.22953 | Regression loss: 0.33959 | Running loss: 0.28793\n",
            "Epoch: 12 | Iteration: 642 | Classification loss: 0.10170 | Regression loss: 0.21811 | Running loss: 0.28798\n",
            "Epoch: 12 | Iteration: 643 | Classification loss: 0.03728 | Regression loss: 0.12557 | Running loss: 0.28702\n",
            "Epoch: 12 | Iteration: 644 | Classification loss: 0.09768 | Regression loss: 0.15280 | Running loss: 0.28684\n",
            "Epoch: 12 | Iteration: 645 | Classification loss: 0.15341 | Regression loss: 0.21046 | Running loss: 0.28710\n",
            "Epoch: 12 | Iteration: 646 | Classification loss: 0.10557 | Regression loss: 0.18441 | Running loss: 0.28714\n",
            "Epoch: 12 | Iteration: 647 | Classification loss: 0.09972 | Regression loss: 0.21745 | Running loss: 0.28709\n",
            "Epoch: 12 | Iteration: 648 | Classification loss: 0.13560 | Regression loss: 0.33795 | Running loss: 0.28757\n",
            "Epoch: 12 | Iteration: 649 | Classification loss: 0.04810 | Regression loss: 0.11714 | Running loss: 0.28737\n",
            "Epoch: 12 | Iteration: 650 | Classification loss: 0.01357 | Regression loss: 0.08816 | Running loss: 0.28718\n",
            "Epoch: 12 | Iteration: 651 | Classification loss: 0.06866 | Regression loss: 0.17873 | Running loss: 0.28708\n",
            "Epoch: 12 | Iteration: 652 | Classification loss: 0.10885 | Regression loss: 0.25078 | Running loss: 0.28718\n",
            "Epoch: 12 | Iteration: 653 | Classification loss: 0.10175 | Regression loss: 0.16305 | Running loss: 0.28714\n",
            "Epoch: 12 | Iteration: 654 | Classification loss: 0.06534 | Regression loss: 0.17671 | Running loss: 0.28743\n",
            "Epoch: 12 | Iteration: 655 | Classification loss: 0.05113 | Regression loss: 0.16936 | Running loss: 0.28727\n",
            "Epoch: 12 | Iteration: 656 | Classification loss: 0.08475 | Regression loss: 0.11350 | Running loss: 0.28732\n",
            "Epoch: 12 | Iteration: 657 | Classification loss: 0.10699 | Regression loss: 0.16827 | Running loss: 0.28686\n",
            "Epoch: 12 | Iteration: 658 | Classification loss: 0.03033 | Regression loss: 0.05687 | Running loss: 0.28651\n",
            "Epoch: 12 | Iteration: 659 | Classification loss: 0.09590 | Regression loss: 0.16968 | Running loss: 0.28654\n",
            "Epoch: 12 | Iteration: 660 | Classification loss: 0.03658 | Regression loss: 0.06662 | Running loss: 0.28598\n",
            "Epoch: 12 | Iteration: 661 | Classification loss: 0.10583 | Regression loss: 0.20108 | Running loss: 0.28599\n",
            "Epoch: 12 | Iteration: 662 | Classification loss: 0.05845 | Regression loss: 0.20787 | Running loss: 0.28592\n",
            "Epoch: 12 | Iteration: 663 | Classification loss: 0.06669 | Regression loss: 0.18871 | Running loss: 0.28614\n",
            "Epoch: 12 | Iteration: 664 | Classification loss: 0.06586 | Regression loss: 0.21813 | Running loss: 0.28624\n",
            "Epoch: 12 | Iteration: 665 | Classification loss: 0.04342 | Regression loss: 0.15794 | Running loss: 0.28630\n",
            "Epoch: 12 | Iteration: 666 | Classification loss: 0.02410 | Regression loss: 0.08644 | Running loss: 0.28611\n",
            "Epoch: 12 | Iteration: 667 | Classification loss: 0.06993 | Regression loss: 0.26660 | Running loss: 0.28613\n",
            "Epoch: 12 | Iteration: 668 | Classification loss: 0.05794 | Regression loss: 0.19001 | Running loss: 0.28605\n",
            "Epoch: 12 | Iteration: 669 | Classification loss: 0.10018 | Regression loss: 0.20060 | Running loss: 0.28621\n",
            "Epoch: 12 | Iteration: 670 | Classification loss: 0.05759 | Regression loss: 0.19533 | Running loss: 0.28644\n",
            "Epoch: 12 | Iteration: 671 | Classification loss: 0.14566 | Regression loss: 0.12368 | Running loss: 0.28652\n",
            "Epoch: 12 | Iteration: 672 | Classification loss: 0.17383 | Regression loss: 0.24221 | Running loss: 0.28687\n",
            "Epoch: 12 | Iteration: 673 | Classification loss: 0.00942 | Regression loss: 0.06533 | Running loss: 0.28604\n",
            "Epoch: 12 | Iteration: 674 | Classification loss: 0.04702 | Regression loss: 0.12751 | Running loss: 0.28586\n",
            "Epoch: 12 | Iteration: 675 | Classification loss: 0.05558 | Regression loss: 0.14188 | Running loss: 0.28596\n",
            "Epoch: 12 | Iteration: 676 | Classification loss: 0.08190 | Regression loss: 0.18427 | Running loss: 0.28567\n",
            "Epoch: 12 | Iteration: 677 | Classification loss: 0.05770 | Regression loss: 0.18384 | Running loss: 0.28508\n",
            "Epoch: 12 | Iteration: 678 | Classification loss: 0.10574 | Regression loss: 0.27034 | Running loss: 0.28556\n",
            "Epoch: 12 | Iteration: 679 | Classification loss: 0.09177 | Regression loss: 0.17328 | Running loss: 0.28578\n",
            "Epoch: 12 | Iteration: 680 | Classification loss: 0.02371 | Regression loss: 0.07961 | Running loss: 0.28537\n",
            "Epoch: 12 | Iteration: 681 | Classification loss: 0.17482 | Regression loss: 0.32318 | Running loss: 0.28612\n",
            "Epoch: 12 | Iteration: 682 | Classification loss: 0.10888 | Regression loss: 0.22573 | Running loss: 0.28602\n",
            "Epoch: 12 | Iteration: 683 | Classification loss: 0.17993 | Regression loss: 0.21440 | Running loss: 0.28655\n",
            "Epoch: 12 | Iteration: 684 | Classification loss: 0.07876 | Regression loss: 0.26054 | Running loss: 0.28656\n",
            "Epoch: 12 | Iteration: 685 | Classification loss: 0.10692 | Regression loss: 0.24689 | Running loss: 0.28667\n",
            "Epoch: 12 | Iteration: 686 | Classification loss: 0.06984 | Regression loss: 0.12666 | Running loss: 0.28644\n",
            "Epoch: 12 | Iteration: 687 | Classification loss: 0.07575 | Regression loss: 0.17598 | Running loss: 0.28649\n",
            "Epoch: 12 | Iteration: 688 | Classification loss: 0.02796 | Regression loss: 0.08412 | Running loss: 0.28597\n",
            "Epoch: 12 | Iteration: 689 | Classification loss: 0.07582 | Regression loss: 0.18828 | Running loss: 0.28605\n",
            "Epoch: 12 | Iteration: 690 | Classification loss: 0.04953 | Regression loss: 0.15375 | Running loss: 0.28619\n",
            "Epoch: 12 | Iteration: 691 | Classification loss: 0.09009 | Regression loss: 0.16614 | Running loss: 0.28654\n",
            "Epoch: 12 | Iteration: 692 | Classification loss: 0.02461 | Regression loss: 0.10212 | Running loss: 0.28640\n",
            "Epoch: 12 | Iteration: 693 | Classification loss: 0.07732 | Regression loss: 0.22480 | Running loss: 0.28660\n",
            "Epoch: 12 | Iteration: 694 | Classification loss: 0.19935 | Regression loss: 0.39508 | Running loss: 0.28745\n",
            "Epoch: 12 | Iteration: 695 | Classification loss: 0.04725 | Regression loss: 0.13286 | Running loss: 0.28747\n",
            "Epoch: 12 | Iteration: 696 | Classification loss: 0.03018 | Regression loss: 0.19722 | Running loss: 0.28752\n",
            "Epoch: 12 | Iteration: 697 | Classification loss: 0.13516 | Regression loss: 0.22719 | Running loss: 0.28721\n",
            "Epoch: 12 | Iteration: 698 | Classification loss: 0.04288 | Regression loss: 0.19512 | Running loss: 0.28712\n",
            "Epoch: 12 | Iteration: 699 | Classification loss: 0.08878 | Regression loss: 0.16580 | Running loss: 0.28706\n",
            "Epoch: 12 | Iteration: 700 | Classification loss: 0.17107 | Regression loss: 0.16159 | Running loss: 0.28678\n",
            "Epoch: 12 | Iteration: 701 | Classification loss: 0.02791 | Regression loss: 0.11536 | Running loss: 0.28659\n",
            "Epoch: 12 | Iteration: 702 | Classification loss: 0.03834 | Regression loss: 0.16883 | Running loss: 0.28666\n",
            "Epoch: 12 | Iteration: 703 | Classification loss: 0.28608 | Regression loss: 0.33069 | Running loss: 0.28739\n",
            "Epoch: 12 | Iteration: 704 | Classification loss: 0.08439 | Regression loss: 0.20948 | Running loss: 0.28722\n",
            "Epoch: 12 | Iteration: 705 | Classification loss: 0.10507 | Regression loss: 0.28724 | Running loss: 0.28756\n",
            "Epoch: 12 | Iteration: 706 | Classification loss: 0.08104 | Regression loss: 0.17113 | Running loss: 0.28759\n",
            "Epoch: 12 | Iteration: 707 | Classification loss: 0.13253 | Regression loss: 0.26643 | Running loss: 0.28768\n",
            "Epoch: 12 | Iteration: 708 | Classification loss: 0.05777 | Regression loss: 0.11532 | Running loss: 0.28745\n",
            "Epoch: 12 | Iteration: 709 | Classification loss: 0.11499 | Regression loss: 0.25630 | Running loss: 0.28793\n",
            "Epoch: 12 | Iteration: 710 | Classification loss: 0.06119 | Regression loss: 0.18552 | Running loss: 0.28801\n",
            "Epoch: 12 | Iteration: 711 | Classification loss: 0.17915 | Regression loss: 0.32286 | Running loss: 0.28866\n",
            "Epoch: 12 | Iteration: 712 | Classification loss: 0.07036 | Regression loss: 0.18206 | Running loss: 0.28872\n",
            "Epoch: 12 | Iteration: 713 | Classification loss: 0.12870 | Regression loss: 0.30409 | Running loss: 0.28900\n",
            "Epoch: 12 | Iteration: 714 | Classification loss: 0.11391 | Regression loss: 0.16019 | Running loss: 0.28894\n",
            "Epoch: 12 | Iteration: 715 | Classification loss: 0.02615 | Regression loss: 0.12007 | Running loss: 0.28788\n",
            "Epoch: 12 | Iteration: 716 | Classification loss: 0.06335 | Regression loss: 0.17298 | Running loss: 0.28779\n",
            "Epoch: 12 | Iteration: 717 | Classification loss: 0.25194 | Regression loss: 0.27343 | Running loss: 0.28767\n",
            "Epoch: 12 | Iteration: 718 | Classification loss: 0.10759 | Regression loss: 0.25317 | Running loss: 0.28780\n",
            "Epoch: 12 | Iteration: 719 | Classification loss: 0.11120 | Regression loss: 0.13955 | Running loss: 0.28782\n",
            "Epoch: 12 | Iteration: 720 | Classification loss: 0.14090 | Regression loss: 0.21624 | Running loss: 0.28810\n",
            "Epoch: 12 | Iteration: 721 | Classification loss: 0.05393 | Regression loss: 0.19975 | Running loss: 0.28828\n",
            "Epoch: 12 | Iteration: 722 | Classification loss: 0.04687 | Regression loss: 0.10495 | Running loss: 0.28732\n",
            "Epoch: 12 | Iteration: 723 | Classification loss: 0.09471 | Regression loss: 0.20023 | Running loss: 0.28740\n",
            "Epoch: 12 | Iteration: 724 | Classification loss: 0.04194 | Regression loss: 0.07790 | Running loss: 0.28684\n",
            "Epoch: 12 | Iteration: 725 | Classification loss: 0.19528 | Regression loss: 0.28878 | Running loss: 0.28736\n",
            "Epoch: 12 | Iteration: 726 | Classification loss: 0.07874 | Regression loss: 0.10274 | Running loss: 0.28697\n",
            "Epoch: 12 | Iteration: 727 | Classification loss: 0.06475 | Regression loss: 0.12420 | Running loss: 0.28655\n",
            "Epoch: 12 | Iteration: 728 | Classification loss: 0.08047 | Regression loss: 0.14054 | Running loss: 0.28630\n",
            "Epoch: 12 | Iteration: 729 | Classification loss: 0.10486 | Regression loss: 0.17756 | Running loss: 0.28625\n",
            "Epoch: 12 | Iteration: 730 | Classification loss: 0.12458 | Regression loss: 0.19451 | Running loss: 0.28656\n",
            "Epoch: 12 | Iteration: 731 | Classification loss: 0.12771 | Regression loss: 0.27949 | Running loss: 0.28686\n",
            "Epoch: 12 | Iteration: 732 | Classification loss: 0.07274 | Regression loss: 0.12265 | Running loss: 0.28687\n",
            "Epoch: 12 | Iteration: 733 | Classification loss: 0.04211 | Regression loss: 0.17729 | Running loss: 0.28654\n",
            "Epoch: 12 | Iteration: 734 | Classification loss: 0.05179 | Regression loss: 0.15833 | Running loss: 0.28616\n",
            "Epoch: 12 | Iteration: 735 | Classification loss: 0.13938 | Regression loss: 0.31016 | Running loss: 0.28639\n",
            "Epoch: 12 | Iteration: 736 | Classification loss: 0.08721 | Regression loss: 0.21354 | Running loss: 0.28638\n",
            "Epoch: 12 | Iteration: 737 | Classification loss: 0.06049 | Regression loss: 0.13902 | Running loss: 0.28627\n",
            "Epoch: 12 | Iteration: 738 | Classification loss: 0.05381 | Regression loss: 0.11729 | Running loss: 0.28574\n",
            "Epoch: 12 | Iteration: 739 | Classification loss: 0.14401 | Regression loss: 0.27119 | Running loss: 0.28626\n",
            "Epoch: 12 | Iteration: 740 | Classification loss: 0.17275 | Regression loss: 0.15008 | Running loss: 0.28642\n",
            "Epoch: 12 | Iteration: 741 | Classification loss: 0.09333 | Regression loss: 0.09293 | Running loss: 0.28581\n",
            "Epoch: 12 | Iteration: 742 | Classification loss: 0.04664 | Regression loss: 0.10852 | Running loss: 0.28532\n",
            "Epoch: 12 | Iteration: 743 | Classification loss: 0.04596 | Regression loss: 0.09229 | Running loss: 0.28507\n",
            "Epoch: 12 | Iteration: 744 | Classification loss: 0.08077 | Regression loss: 0.22804 | Running loss: 0.28516\n",
            "Epoch: 12 | Iteration: 745 | Classification loss: 0.04459 | Regression loss: 0.05710 | Running loss: 0.28481\n",
            "Epoch: 12 | Iteration: 746 | Classification loss: 0.11837 | Regression loss: 0.25500 | Running loss: 0.28481\n",
            "Epoch: 12 | Iteration: 747 | Classification loss: 0.08662 | Regression loss: 0.19549 | Running loss: 0.28492\n",
            "Epoch: 12 | Iteration: 748 | Classification loss: 0.04434 | Regression loss: 0.11893 | Running loss: 0.28489\n",
            "Epoch: 12 | Iteration: 749 | Classification loss: 0.05474 | Regression loss: 0.19186 | Running loss: 0.28488\n",
            "Epoch: 12 | Iteration: 750 | Classification loss: 0.10796 | Regression loss: 0.14333 | Running loss: 0.28504\n",
            "Epoch: 12 | Iteration: 751 | Classification loss: 0.11067 | Regression loss: 0.29238 | Running loss: 0.28552\n",
            "Epoch: 12 | Iteration: 752 | Classification loss: 0.04563 | Regression loss: 0.13002 | Running loss: 0.28553\n",
            "Epoch: 12 | Iteration: 753 | Classification loss: 0.06301 | Regression loss: 0.15989 | Running loss: 0.28540\n",
            "Epoch: 12 | Iteration: 754 | Classification loss: 0.08281 | Regression loss: 0.18982 | Running loss: 0.28514\n",
            "Epoch: 12 | Iteration: 755 | Classification loss: 0.03647 | Regression loss: 0.12935 | Running loss: 0.28510\n",
            "Epoch: 12 | Iteration: 756 | Classification loss: 0.05276 | Regression loss: 0.18879 | Running loss: 0.28392\n",
            "Epoch: 12 | Iteration: 757 | Classification loss: 0.05816 | Regression loss: 0.21983 | Running loss: 0.28404\n",
            "Epoch: 12 | Iteration: 758 | Classification loss: 0.07996 | Regression loss: 0.18091 | Running loss: 0.28422\n",
            "Epoch: 12 | Iteration: 759 | Classification loss: 0.02633 | Regression loss: 0.10000 | Running loss: 0.28381\n",
            "Epoch: 12 | Iteration: 760 | Classification loss: 0.08338 | Regression loss: 0.20769 | Running loss: 0.28391\n",
            "Epoch: 12 | Iteration: 761 | Classification loss: 0.02981 | Regression loss: 0.11055 | Running loss: 0.28388\n",
            "Epoch: 12 | Iteration: 762 | Classification loss: 0.06655 | Regression loss: 0.23062 | Running loss: 0.28396\n",
            "Epoch: 12 | Iteration: 763 | Classification loss: 0.05599 | Regression loss: 0.10936 | Running loss: 0.28380\n",
            "Epoch: 12 | Iteration: 764 | Classification loss: 0.04876 | Regression loss: 0.19056 | Running loss: 0.28372\n",
            "Epoch: 12 | Iteration: 765 | Classification loss: 0.18216 | Regression loss: 0.26179 | Running loss: 0.28410\n",
            "Epoch: 12 | Iteration: 766 | Classification loss: 0.13863 | Regression loss: 0.27886 | Running loss: 0.28439\n",
            "Epoch: 12 | Iteration: 767 | Classification loss: 0.03394 | Regression loss: 0.15109 | Running loss: 0.28370\n",
            "Epoch: 12 | Iteration: 768 | Classification loss: 0.04670 | Regression loss: 0.11343 | Running loss: 0.28366\n",
            "Epoch: 12 | Iteration: 769 | Classification loss: 0.09996 | Regression loss: 0.31366 | Running loss: 0.28417\n",
            "Epoch: 12 | Iteration: 770 | Classification loss: 0.09047 | Regression loss: 0.18302 | Running loss: 0.28401\n",
            "Epoch: 12 | Iteration: 771 | Classification loss: 0.02053 | Regression loss: 0.15176 | Running loss: 0.28320\n",
            "Epoch: 12 | Iteration: 772 | Classification loss: 0.23360 | Regression loss: 0.38173 | Running loss: 0.28416\n",
            "Epoch: 12 | Iteration: 773 | Classification loss: 0.04257 | Regression loss: 0.13960 | Running loss: 0.28414\n",
            "Epoch: 12 | Iteration: 774 | Classification loss: 0.04547 | Regression loss: 0.13613 | Running loss: 0.28401\n",
            "Epoch: 12 | Iteration: 775 | Classification loss: 0.11050 | Regression loss: 0.22905 | Running loss: 0.28421\n",
            "Epoch: 12 | Iteration: 776 | Classification loss: 0.03545 | Regression loss: 0.08987 | Running loss: 0.28367\n",
            "Epoch: 12 | Iteration: 777 | Classification loss: 0.05200 | Regression loss: 0.09634 | Running loss: 0.28354\n",
            "Epoch: 12 | Iteration: 778 | Classification loss: 0.13833 | Regression loss: 0.31326 | Running loss: 0.28379\n",
            "Epoch: 12 | Iteration: 779 | Classification loss: 0.20081 | Regression loss: 0.26706 | Running loss: 0.28428\n",
            "Epoch: 12 | Iteration: 780 | Classification loss: 0.14553 | Regression loss: 0.30317 | Running loss: 0.28443\n",
            "Epoch: 12 | Iteration: 781 | Classification loss: 0.05594 | Regression loss: 0.08757 | Running loss: 0.28411\n",
            "Epoch: 12 | Iteration: 782 | Classification loss: 0.13147 | Regression loss: 0.12594 | Running loss: 0.28431\n",
            "Epoch: 12 | Iteration: 783 | Classification loss: 0.10140 | Regression loss: 0.14859 | Running loss: 0.28463\n",
            "Epoch: 12 | Iteration: 784 | Classification loss: 0.09377 | Regression loss: 0.18465 | Running loss: 0.28461\n",
            "Epoch: 12 | Iteration: 785 | Classification loss: 0.10368 | Regression loss: 0.13946 | Running loss: 0.28475\n",
            "Epoch: 12 | Iteration: 786 | Classification loss: 0.11095 | Regression loss: 0.26628 | Running loss: 0.28478\n",
            "Epoch: 12 | Iteration: 787 | Classification loss: 0.08680 | Regression loss: 0.20546 | Running loss: 0.28480\n",
            "Epoch: 12 | Iteration: 788 | Classification loss: 0.11845 | Regression loss: 0.25207 | Running loss: 0.28497\n",
            "Epoch: 12 | Iteration: 789 | Classification loss: 0.06657 | Regression loss: 0.15898 | Running loss: 0.28480\n",
            "Epoch: 12 | Iteration: 790 | Classification loss: 0.24743 | Regression loss: 0.49004 | Running loss: 0.28536\n",
            "Epoch: 12 | Iteration: 791 | Classification loss: 0.10621 | Regression loss: 0.25436 | Running loss: 0.28568\n",
            "Epoch: 12 | Iteration: 792 | Classification loss: 0.12269 | Regression loss: 0.30887 | Running loss: 0.28618\n",
            "Epoch: 12 | Iteration: 793 | Classification loss: 0.12967 | Regression loss: 0.24830 | Running loss: 0.28651\n",
            "Epoch: 12 | Iteration: 794 | Classification loss: 0.06238 | Regression loss: 0.14211 | Running loss: 0.28613\n",
            "Epoch: 12 | Iteration: 795 | Classification loss: 0.05436 | Regression loss: 0.20823 | Running loss: 0.28622\n",
            "Epoch: 12 | Iteration: 796 | Classification loss: 0.05936 | Regression loss: 0.15566 | Running loss: 0.28611\n",
            "Epoch: 12 | Iteration: 797 | Classification loss: 0.06227 | Regression loss: 0.21954 | Running loss: 0.28617\n",
            "Epoch: 12 | Iteration: 798 | Classification loss: 0.13115 | Regression loss: 0.20848 | Running loss: 0.28604\n",
            "Epoch: 12 | Iteration: 799 | Classification loss: 0.03738 | Regression loss: 0.10958 | Running loss: 0.28590\n",
            "Epoch: 12 | Iteration: 800 | Classification loss: 0.06008 | Regression loss: 0.18497 | Running loss: 0.28545\n",
            "Epoch: 12 | Iteration: 801 | Classification loss: 0.08715 | Regression loss: 0.18947 | Running loss: 0.28555\n",
            "Epoch: 12 | Iteration: 802 | Classification loss: 0.17457 | Regression loss: 0.32210 | Running loss: 0.28584\n",
            "Epoch: 12 | Iteration: 803 | Classification loss: 0.04319 | Regression loss: 0.15633 | Running loss: 0.28556\n",
            "Epoch: 12 | Iteration: 804 | Classification loss: 0.09630 | Regression loss: 0.20311 | Running loss: 0.28493\n",
            "Epoch: 12 | Iteration: 805 | Classification loss: 0.11619 | Regression loss: 0.31974 | Running loss: 0.28523\n",
            "Epoch: 12 | Iteration: 806 | Classification loss: 0.12806 | Regression loss: 0.28237 | Running loss: 0.28548\n",
            "Epoch: 12 | Iteration: 807 | Classification loss: 0.13777 | Regression loss: 0.36703 | Running loss: 0.28591\n",
            "Epoch: 12 | Iteration: 808 | Classification loss: 0.08195 | Regression loss: 0.24617 | Running loss: 0.28614\n",
            "Epoch: 12 | Iteration: 809 | Classification loss: 0.05335 | Regression loss: 0.19180 | Running loss: 0.28600\n",
            "Epoch: 12 | Iteration: 810 | Classification loss: 0.07199 | Regression loss: 0.15187 | Running loss: 0.28528\n",
            "Epoch: 12 | Iteration: 811 | Classification loss: 0.11545 | Regression loss: 0.26749 | Running loss: 0.28574\n",
            "Epoch: 12 | Iteration: 812 | Classification loss: 0.03029 | Regression loss: 0.13055 | Running loss: 0.28556\n",
            "Epoch: 12 | Iteration: 813 | Classification loss: 0.10114 | Regression loss: 0.16954 | Running loss: 0.28518\n",
            "Epoch: 12 | Iteration: 814 | Classification loss: 0.20713 | Regression loss: 0.32235 | Running loss: 0.28549\n",
            "Epoch: 12 | Iteration: 815 | Classification loss: 0.14295 | Regression loss: 0.25119 | Running loss: 0.28523\n",
            "Epoch: 12 | Iteration: 816 | Classification loss: 0.03635 | Regression loss: 0.15863 | Running loss: 0.28504\n",
            "Epoch: 12 | Iteration: 817 | Classification loss: 0.05312 | Regression loss: 0.12777 | Running loss: 0.28489\n",
            "Epoch: 12 | Iteration: 818 | Classification loss: 0.04179 | Regression loss: 0.12934 | Running loss: 0.28471\n",
            "Epoch: 12 | Iteration: 819 | Classification loss: 0.11273 | Regression loss: 0.10830 | Running loss: 0.28492\n",
            "Epoch: 12 | Iteration: 820 | Classification loss: 0.10541 | Regression loss: 0.24165 | Running loss: 0.28503\n",
            "Epoch: 12 | Iteration: 821 | Classification loss: 0.04831 | Regression loss: 0.11571 | Running loss: 0.28515\n",
            "Epoch: 12 | Iteration: 822 | Classification loss: 0.05926 | Regression loss: 0.18365 | Running loss: 0.28488\n",
            "Epoch: 12 | Iteration: 823 | Classification loss: 0.06384 | Regression loss: 0.17422 | Running loss: 0.28466\n",
            "Epoch: 12 | Iteration: 824 | Classification loss: 0.06303 | Regression loss: 0.22303 | Running loss: 0.28487\n",
            "Epoch: 12 | Iteration: 825 | Classification loss: 0.06502 | Regression loss: 0.16472 | Running loss: 0.28501\n",
            "Epoch: 12 | Iteration: 826 | Classification loss: 0.05458 | Regression loss: 0.15630 | Running loss: 0.28510\n",
            "Epoch: 12 | Iteration: 827 | Classification loss: 0.07652 | Regression loss: 0.15214 | Running loss: 0.28492\n",
            "Epoch: 12 | Iteration: 828 | Classification loss: 0.13575 | Regression loss: 0.27218 | Running loss: 0.28528\n",
            "Epoch: 12 | Iteration: 829 | Classification loss: 0.05290 | Regression loss: 0.17931 | Running loss: 0.28491\n",
            "Epoch: 12 | Iteration: 830 | Classification loss: 0.15006 | Regression loss: 0.19079 | Running loss: 0.28481\n",
            "Epoch: 12 | Iteration: 831 | Classification loss: 0.05556 | Regression loss: 0.16690 | Running loss: 0.28458\n",
            "Epoch: 12 | Iteration: 832 | Classification loss: 0.09846 | Regression loss: 0.18136 | Running loss: 0.28480\n",
            "Epoch: 12 | Iteration: 833 | Classification loss: 0.06807 | Regression loss: 0.17859 | Running loss: 0.28489\n",
            "Epoch: 12 | Iteration: 834 | Classification loss: 0.06217 | Regression loss: 0.19268 | Running loss: 0.28509\n",
            "Epoch: 12 | Iteration: 835 | Classification loss: 0.06582 | Regression loss: 0.23173 | Running loss: 0.28517\n",
            "Epoch: 12 | Iteration: 836 | Classification loss: 0.10564 | Regression loss: 0.24776 | Running loss: 0.28541\n",
            "Epoch: 12 | Iteration: 837 | Classification loss: 0.04533 | Regression loss: 0.14944 | Running loss: 0.28521\n",
            "Epoch: 12 | Iteration: 838 | Classification loss: 0.05749 | Regression loss: 0.16092 | Running loss: 0.28499\n",
            "Epoch: 12 | Iteration: 839 | Classification loss: 0.04680 | Regression loss: 0.15003 | Running loss: 0.28500\n",
            "Epoch: 12 | Iteration: 840 | Classification loss: 0.07911 | Regression loss: 0.26390 | Running loss: 0.28544\n",
            "Epoch: 12 | Iteration: 841 | Classification loss: 0.15646 | Regression loss: 0.36120 | Running loss: 0.28587\n",
            "Epoch: 12 | Iteration: 842 | Classification loss: 0.16208 | Regression loss: 0.27672 | Running loss: 0.28589\n",
            "Epoch: 12 | Iteration: 843 | Classification loss: 0.09803 | Regression loss: 0.28209 | Running loss: 0.28623\n",
            "Epoch: 12 | Iteration: 844 | Classification loss: 0.13207 | Regression loss: 0.29678 | Running loss: 0.28656\n",
            "Epoch: 12 | Iteration: 845 | Classification loss: 0.10884 | Regression loss: 0.15843 | Running loss: 0.28668\n",
            "Epoch: 12 | Iteration: 846 | Classification loss: 0.14512 | Regression loss: 0.26775 | Running loss: 0.28674\n",
            "Epoch: 12 | Iteration: 847 | Classification loss: 0.15236 | Regression loss: 0.38787 | Running loss: 0.28717\n",
            "Epoch: 12 | Iteration: 848 | Classification loss: 0.17121 | Regression loss: 0.37245 | Running loss: 0.28786\n",
            "Epoch: 12 | Iteration: 849 | Classification loss: 0.11516 | Regression loss: 0.28063 | Running loss: 0.28750\n",
            "Epoch: 12 | Iteration: 850 | Classification loss: 0.12687 | Regression loss: 0.35151 | Running loss: 0.28777\n",
            "Epoch: 12 | Iteration: 851 | Classification loss: 0.10342 | Regression loss: 0.20314 | Running loss: 0.28786\n",
            "Epoch: 12 | Iteration: 852 | Classification loss: 0.06433 | Regression loss: 0.16792 | Running loss: 0.28769\n",
            "Epoch: 12 | Iteration: 853 | Classification loss: 0.15463 | Regression loss: 0.29758 | Running loss: 0.28827\n",
            "Epoch: 12 | Iteration: 854 | Classification loss: 0.04089 | Regression loss: 0.12829 | Running loss: 0.28783\n",
            "Epoch: 12 | Iteration: 855 | Classification loss: 0.11104 | Regression loss: 0.23089 | Running loss: 0.28818\n",
            "Epoch: 12 | Iteration: 856 | Classification loss: 0.06655 | Regression loss: 0.12654 | Running loss: 0.28796\n",
            "Epoch: 12 | Iteration: 857 | Classification loss: 0.15243 | Regression loss: 0.23358 | Running loss: 0.28841\n",
            "Epoch: 12 | Iteration: 858 | Classification loss: 0.02504 | Regression loss: 0.14478 | Running loss: 0.28787\n",
            "Epoch: 12 | Iteration: 859 | Classification loss: 0.02367 | Regression loss: 0.10725 | Running loss: 0.28767\n",
            "Epoch: 12 | Iteration: 860 | Classification loss: 0.07153 | Regression loss: 0.18310 | Running loss: 0.28787\n",
            "Epoch: 12 | Iteration: 861 | Classification loss: 0.14582 | Regression loss: 0.26624 | Running loss: 0.28803\n",
            "Epoch: 12 | Iteration: 862 | Classification loss: 0.12323 | Regression loss: 0.29715 | Running loss: 0.28820\n",
            "Epoch: 12 | Iteration: 863 | Classification loss: 0.05993 | Regression loss: 0.21336 | Running loss: 0.28796\n",
            "Epoch: 12 | Iteration: 864 | Classification loss: 0.09799 | Regression loss: 0.21366 | Running loss: 0.28819\n",
            "Epoch: 12 | Iteration: 865 | Classification loss: 0.09715 | Regression loss: 0.25256 | Running loss: 0.28837\n",
            "Epoch: 12 | Iteration: 866 | Classification loss: 0.12745 | Regression loss: 0.24218 | Running loss: 0.28814\n",
            "Epoch: 12 | Iteration: 867 | Classification loss: 0.10540 | Regression loss: 0.21129 | Running loss: 0.28833\n",
            "Epoch: 12 | Iteration: 868 | Classification loss: 0.09859 | Regression loss: 0.23398 | Running loss: 0.28790\n",
            "Epoch: 12 | Iteration: 869 | Classification loss: 0.05064 | Regression loss: 0.14327 | Running loss: 0.28798\n",
            "Epoch: 12 | Iteration: 870 | Classification loss: 0.09492 | Regression loss: 0.21713 | Running loss: 0.28773\n",
            "Epoch: 12 | Iteration: 871 | Classification loss: 0.12250 | Regression loss: 0.21875 | Running loss: 0.28799\n",
            "Epoch: 12 | Iteration: 872 | Classification loss: 0.16212 | Regression loss: 0.33602 | Running loss: 0.28870\n",
            "Epoch: 12 | Iteration: 873 | Classification loss: 0.06539 | Regression loss: 0.14422 | Running loss: 0.28856\n",
            "Epoch: 12 | Iteration: 874 | Classification loss: 0.04902 | Regression loss: 0.09812 | Running loss: 0.28820\n",
            "Epoch: 12 | Iteration: 875 | Classification loss: 0.05531 | Regression loss: 0.14915 | Running loss: 0.28789\n",
            "Epoch: 12 | Iteration: 876 | Classification loss: 0.18795 | Regression loss: 0.43360 | Running loss: 0.28867\n",
            "Epoch: 12 | Iteration: 877 | Classification loss: 0.06715 | Regression loss: 0.17186 | Running loss: 0.28846\n",
            "Epoch: 12 | Iteration: 878 | Classification loss: 0.03873 | Regression loss: 0.14943 | Running loss: 0.28758\n",
            "Epoch: 12 | Iteration: 879 | Classification loss: 0.14287 | Regression loss: 0.27559 | Running loss: 0.28773\n",
            "Epoch: 12 | Iteration: 880 | Classification loss: 0.02716 | Regression loss: 0.11137 | Running loss: 0.28733\n",
            "Epoch: 12 | Iteration: 881 | Classification loss: 0.04740 | Regression loss: 0.14936 | Running loss: 0.28678\n",
            "Epoch: 12 | Iteration: 882 | Classification loss: 0.09933 | Regression loss: 0.24544 | Running loss: 0.28671\n",
            "Epoch: 12 | Iteration: 883 | Classification loss: 0.10817 | Regression loss: 0.19813 | Running loss: 0.28660\n",
            "Epoch: 12 | Iteration: 884 | Classification loss: 0.14901 | Regression loss: 0.30231 | Running loss: 0.28689\n",
            "Epoch: 12 | Iteration: 885 | Classification loss: 0.24364 | Regression loss: 0.31614 | Running loss: 0.28755\n",
            "Epoch: 12 | Iteration: 886 | Classification loss: 0.07825 | Regression loss: 0.17400 | Running loss: 0.28754\n",
            "Epoch: 12 | Iteration: 887 | Classification loss: 0.06202 | Regression loss: 0.19258 | Running loss: 0.28757\n",
            "Epoch: 12 | Iteration: 888 | Classification loss: 0.06260 | Regression loss: 0.18355 | Running loss: 0.28719\n",
            "Epoch: 12 | Iteration: 889 | Classification loss: 0.04198 | Regression loss: 0.16186 | Running loss: 0.28676\n",
            "Epoch: 12 | Iteration: 890 | Classification loss: 0.03259 | Regression loss: 0.10206 | Running loss: 0.28640\n",
            "Epoch: 12 | Iteration: 891 | Classification loss: 0.03747 | Regression loss: 0.13507 | Running loss: 0.28613\n",
            "Epoch: 12 | Iteration: 892 | Classification loss: 0.08271 | Regression loss: 0.17365 | Running loss: 0.28625\n",
            "Epoch: 12 | Iteration: 893 | Classification loss: 0.03994 | Regression loss: 0.12495 | Running loss: 0.28595\n",
            "Epoch: 12 | Iteration: 894 | Classification loss: 0.06971 | Regression loss: 0.14276 | Running loss: 0.28573\n",
            "Epoch: 12 | Iteration: 895 | Classification loss: 0.19580 | Regression loss: 0.30017 | Running loss: 0.28599\n",
            "Epoch: 12 | Iteration: 896 | Classification loss: 0.14585 | Regression loss: 0.23737 | Running loss: 0.28636\n",
            "Epoch: 12 | Iteration: 897 | Classification loss: 0.07641 | Regression loss: 0.17472 | Running loss: 0.28635\n",
            "Epoch: 12 | Iteration: 898 | Classification loss: 0.08193 | Regression loss: 0.18354 | Running loss: 0.28643\n",
            "Epoch: 12 | Iteration: 899 | Classification loss: 0.04222 | Regression loss: 0.12133 | Running loss: 0.28568\n",
            "Epoch: 12 | Iteration: 900 | Classification loss: 0.10379 | Regression loss: 0.12216 | Running loss: 0.28567\n",
            "Epoch: 12 | Iteration: 901 | Classification loss: 0.03173 | Regression loss: 0.12885 | Running loss: 0.28554\n",
            "Epoch: 12 | Iteration: 902 | Classification loss: 0.16022 | Regression loss: 0.24889 | Running loss: 0.28596\n",
            "Epoch: 12 | Iteration: 903 | Classification loss: 0.14449 | Regression loss: 0.32435 | Running loss: 0.28661\n",
            "Epoch: 12 | Iteration: 904 | Classification loss: 0.05713 | Regression loss: 0.13210 | Running loss: 0.28611\n",
            "Epoch: 12 | Iteration: 905 | Classification loss: 0.02424 | Regression loss: 0.10883 | Running loss: 0.28584\n",
            "Epoch: 12 | Iteration: 906 | Classification loss: 0.09184 | Regression loss: 0.13273 | Running loss: 0.28590\n",
            "Epoch: 12 | Iteration: 907 | Classification loss: 0.11010 | Regression loss: 0.20342 | Running loss: 0.28618\n",
            "Epoch: 12 | Iteration: 908 | Classification loss: 0.08366 | Regression loss: 0.18824 | Running loss: 0.28616\n",
            "Epoch: 12 | Iteration: 909 | Classification loss: 0.17442 | Regression loss: 0.32965 | Running loss: 0.28669\n",
            "Epoch: 12 | Iteration: 910 | Classification loss: 0.04925 | Regression loss: 0.15651 | Running loss: 0.28651\n",
            "Epoch: 12 | Iteration: 911 | Classification loss: 0.07796 | Regression loss: 0.19560 | Running loss: 0.28659\n",
            "Epoch: 12 | Iteration: 912 | Classification loss: 0.23782 | Regression loss: 0.36998 | Running loss: 0.28735\n",
            "Epoch: 12 | Iteration: 913 | Classification loss: 0.16061 | Regression loss: 0.36848 | Running loss: 0.28817\n",
            "Epoch: 12 | Iteration: 914 | Classification loss: 0.15332 | Regression loss: 0.27008 | Running loss: 0.28811\n",
            "Epoch: 12 | Iteration: 915 | Classification loss: 0.04998 | Regression loss: 0.09532 | Running loss: 0.28764\n",
            "Epoch: 12 | Iteration: 916 | Classification loss: 0.02165 | Regression loss: 0.08063 | Running loss: 0.28717\n",
            "Epoch: 12 | Iteration: 917 | Classification loss: 0.08596 | Regression loss: 0.13510 | Running loss: 0.28735\n",
            "Epoch: 12 | Iteration: 918 | Classification loss: 0.10572 | Regression loss: 0.25254 | Running loss: 0.28768\n",
            "Epoch: 12 | Iteration: 919 | Classification loss: 0.17815 | Regression loss: 0.25903 | Running loss: 0.28797\n",
            "Epoch: 12 | Iteration: 920 | Classification loss: 0.02690 | Regression loss: 0.14230 | Running loss: 0.28801\n",
            "Epoch: 12 | Iteration: 921 | Classification loss: 0.08510 | Regression loss: 0.18922 | Running loss: 0.28821\n",
            "Epoch: 12 | Iteration: 922 | Classification loss: 0.12620 | Regression loss: 0.20894 | Running loss: 0.28806\n",
            "Epoch: 12 | Iteration: 923 | Classification loss: 0.16420 | Regression loss: 0.35142 | Running loss: 0.28877\n",
            "Epoch: 12 | Iteration: 924 | Classification loss: 0.07616 | Regression loss: 0.19153 | Running loss: 0.28868\n",
            "Epoch: 12 | Iteration: 925 | Classification loss: 0.02936 | Regression loss: 0.15612 | Running loss: 0.28852\n",
            "Epoch: 12 | Iteration: 926 | Classification loss: 0.07090 | Regression loss: 0.13353 | Running loss: 0.28789\n",
            "Epoch: 12 | Iteration: 927 | Classification loss: 0.05509 | Regression loss: 0.10702 | Running loss: 0.28770\n",
            "Epoch: 12 | Iteration: 928 | Classification loss: 0.02528 | Regression loss: 0.12236 | Running loss: 0.28761\n",
            "Epoch: 12 | Iteration: 929 | Classification loss: 0.05090 | Regression loss: 0.11577 | Running loss: 0.28701\n",
            "Epoch: 12 | Iteration: 930 | Classification loss: 0.09689 | Regression loss: 0.19272 | Running loss: 0.28735\n",
            "Epoch: 12 | Iteration: 931 | Classification loss: 0.01646 | Regression loss: 0.09407 | Running loss: 0.28731\n",
            "Epoch: 12 | Iteration: 932 | Classification loss: 0.09004 | Regression loss: 0.24113 | Running loss: 0.28761\n",
            "Epoch: 12 | Iteration: 933 | Classification loss: 0.08601 | Regression loss: 0.18656 | Running loss: 0.28771\n",
            "Epoch: 12 | Iteration: 934 | Classification loss: 0.11507 | Regression loss: 0.28052 | Running loss: 0.28816\n",
            "Epoch: 12 | Iteration: 935 | Classification loss: 0.11806 | Regression loss: 0.20906 | Running loss: 0.28809\n",
            "Epoch: 12 | Iteration: 936 | Classification loss: 0.08967 | Regression loss: 0.18694 | Running loss: 0.28791\n",
            "Epoch: 12 | Iteration: 937 | Classification loss: 0.12546 | Regression loss: 0.15838 | Running loss: 0.28808\n",
            "Epoch: 12 | Iteration: 938 | Classification loss: 0.03708 | Regression loss: 0.13135 | Running loss: 0.28805\n",
            "Epoch: 12 | Iteration: 939 | Classification loss: 0.02387 | Regression loss: 0.17558 | Running loss: 0.28801\n",
            "Epoch: 12 | Iteration: 940 | Classification loss: 0.12942 | Regression loss: 0.27969 | Running loss: 0.28817\n",
            "Epoch: 12 | Iteration: 941 | Classification loss: 0.14875 | Regression loss: 0.33383 | Running loss: 0.28809\n",
            "Epoch: 12 | Iteration: 942 | Classification loss: 0.08720 | Regression loss: 0.19679 | Running loss: 0.28834\n",
            "Epoch: 12 | Iteration: 943 | Classification loss: 0.04146 | Regression loss: 0.09657 | Running loss: 0.28802\n",
            "Epoch: 12 | Iteration: 944 | Classification loss: 0.08118 | Regression loss: 0.08031 | Running loss: 0.28787\n",
            "Epoch: 12 | Iteration: 945 | Classification loss: 0.04869 | Regression loss: 0.08963 | Running loss: 0.28763\n",
            "Epoch: 12 | Iteration: 946 | Classification loss: 0.10076 | Regression loss: 0.26453 | Running loss: 0.28774\n",
            "Epoch: 12 | Iteration: 947 | Classification loss: 0.08274 | Regression loss: 0.23253 | Running loss: 0.28817\n",
            "Epoch: 12 | Iteration: 948 | Classification loss: 0.02447 | Regression loss: 0.05398 | Running loss: 0.28776\n",
            "Epoch: 12 | Iteration: 949 | Classification loss: 0.16872 | Regression loss: 0.24983 | Running loss: 0.28796\n",
            "Epoch: 12 | Iteration: 950 | Classification loss: 0.11273 | Regression loss: 0.06236 | Running loss: 0.28768\n",
            "Epoch: 12 | Iteration: 951 | Classification loss: 0.06550 | Regression loss: 0.16314 | Running loss: 0.28736\n",
            "Epoch: 12 | Iteration: 952 | Classification loss: 0.13329 | Regression loss: 0.21769 | Running loss: 0.28709\n",
            "Epoch: 12 | Iteration: 953 | Classification loss: 0.04824 | Regression loss: 0.17168 | Running loss: 0.28715\n",
            "Epoch: 12 | Iteration: 954 | Classification loss: 0.08743 | Regression loss: 0.25558 | Running loss: 0.28754\n",
            "Epoch: 12 | Iteration: 955 | Classification loss: 0.07375 | Regression loss: 0.19802 | Running loss: 0.28750\n",
            "Epoch: 12 | Iteration: 956 | Classification loss: 0.03133 | Regression loss: 0.11638 | Running loss: 0.28713\n",
            "Epoch: 12 | Iteration: 957 | Classification loss: 0.12343 | Regression loss: 0.17816 | Running loss: 0.28733\n",
            "Epoch: 12 | Iteration: 958 | Classification loss: 0.04414 | Regression loss: 0.15238 | Running loss: 0.28692\n",
            "Epoch: 12 | Iteration: 959 | Classification loss: 0.10477 | Regression loss: 0.29020 | Running loss: 0.28737\n",
            "Epoch: 12 | Iteration: 960 | Classification loss: 0.04627 | Regression loss: 0.18222 | Running loss: 0.28722\n",
            "Epoch: 12 | Iteration: 961 | Classification loss: 0.07373 | Regression loss: 0.26999 | Running loss: 0.28766\n",
            "Epoch: 12 | Iteration: 962 | Classification loss: 0.07906 | Regression loss: 0.18279 | Running loss: 0.28796\n",
            "Epoch: 12 | Iteration: 963 | Classification loss: 0.04201 | Regression loss: 0.13167 | Running loss: 0.28792\n",
            "Epoch: 12 | Iteration: 964 | Classification loss: 0.11125 | Regression loss: 0.20867 | Running loss: 0.28825\n",
            "Epoch: 12 | Iteration: 965 | Classification loss: 0.11128 | Regression loss: 0.24375 | Running loss: 0.28826\n",
            "Epoch: 12 | Iteration: 966 | Classification loss: 0.07646 | Regression loss: 0.19843 | Running loss: 0.28835\n",
            "Epoch: 12 | Iteration: 967 | Classification loss: 0.09709 | Regression loss: 0.19567 | Running loss: 0.28856\n",
            "Epoch: 12 | Iteration: 968 | Classification loss: 0.07197 | Regression loss: 0.18160 | Running loss: 0.28856\n",
            "Epoch: 12 | Iteration: 969 | Classification loss: 0.03310 | Regression loss: 0.16153 | Running loss: 0.28804\n",
            "Epoch: 12 | Iteration: 970 | Classification loss: 0.08635 | Regression loss: 0.12125 | Running loss: 0.28809\n",
            "Epoch: 12 | Iteration: 971 | Classification loss: 0.09153 | Regression loss: 0.25601 | Running loss: 0.28828\n",
            "Epoch: 12 | Iteration: 972 | Classification loss: 0.08174 | Regression loss: 0.19744 | Running loss: 0.28813\n",
            "Epoch: 12 | Iteration: 973 | Classification loss: 0.09969 | Regression loss: 0.22563 | Running loss: 0.28826\n",
            "Epoch: 12 | Iteration: 974 | Classification loss: 0.09192 | Regression loss: 0.16065 | Running loss: 0.28833\n",
            "Epoch: 12 | Iteration: 975 | Classification loss: 0.04694 | Regression loss: 0.23709 | Running loss: 0.28845\n",
            "Epoch: 12 | Iteration: 976 | Classification loss: 0.04905 | Regression loss: 0.10408 | Running loss: 0.28817\n",
            "Epoch: 12 | Iteration: 977 | Classification loss: 0.09213 | Regression loss: 0.20077 | Running loss: 0.28849\n",
            "Epoch: 12 | Iteration: 978 | Classification loss: 0.09441 | Regression loss: 0.16954 | Running loss: 0.28856\n",
            "Epoch: 12 | Iteration: 979 | Classification loss: 0.06361 | Regression loss: 0.15719 | Running loss: 0.28859\n",
            "Epoch: 12 | Iteration: 980 | Classification loss: 0.07092 | Regression loss: 0.22659 | Running loss: 0.28833\n",
            "Epoch: 12 | Iteration: 981 | Classification loss: 0.09746 | Regression loss: 0.24298 | Running loss: 0.28831\n",
            "Epoch: 12 | Iteration: 982 | Classification loss: 0.09456 | Regression loss: 0.24399 | Running loss: 0.28825\n",
            "Epoch: 12 | Iteration: 983 | Classification loss: 0.12913 | Regression loss: 0.30269 | Running loss: 0.28858\n",
            "Epoch: 12 | Iteration: 984 | Classification loss: 0.10894 | Regression loss: 0.21209 | Running loss: 0.28872\n",
            "Epoch: 12 | Iteration: 985 | Classification loss: 0.27333 | Regression loss: 0.42516 | Running loss: 0.28974\n",
            "Epoch: 12 | Iteration: 986 | Classification loss: 0.05788 | Regression loss: 0.12180 | Running loss: 0.28966\n",
            "Epoch: 12 | Iteration: 987 | Classification loss: 0.11868 | Regression loss: 0.23252 | Running loss: 0.28976\n",
            "Epoch: 12 | Iteration: 988 | Classification loss: 0.08595 | Regression loss: 0.15815 | Running loss: 0.28962\n",
            "Epoch: 12 | Iteration: 989 | Classification loss: 0.11550 | Regression loss: 0.23101 | Running loss: 0.28934\n",
            "Epoch: 12 | Iteration: 990 | Classification loss: 0.06640 | Regression loss: 0.14412 | Running loss: 0.28927\n",
            "Epoch: 12 | Iteration: 991 | Classification loss: 0.04842 | Regression loss: 0.15797 | Running loss: 0.28875\n",
            "Epoch: 12 | Iteration: 992 | Classification loss: 0.10917 | Regression loss: 0.16529 | Running loss: 0.28889\n",
            "Epoch: 12 | Iteration: 993 | Classification loss: 0.08743 | Regression loss: 0.21712 | Running loss: 0.28886\n",
            "Epoch: 12 | Iteration: 994 | Classification loss: 0.03574 | Regression loss: 0.18749 | Running loss: 0.28901\n",
            "Epoch: 12 | Iteration: 995 | Classification loss: 0.13268 | Regression loss: 0.22096 | Running loss: 0.28932\n",
            "Epoch: 12 | Iteration: 996 | Classification loss: 0.04563 | Regression loss: 0.13108 | Running loss: 0.28918\n",
            "Epoch: 12 | Iteration: 997 | Classification loss: 0.13570 | Regression loss: 0.33894 | Running loss: 0.28956\n",
            "Epoch: 12 | Iteration: 998 | Classification loss: 0.15719 | Regression loss: 0.34139 | Running loss: 0.28975\n",
            "Epoch: 12 | Iteration: 999 | Classification loss: 0.07328 | Regression loss: 0.34706 | Running loss: 0.29023\n",
            "Epoch: 12 | Iteration: 1000 | Classification loss: 0.03736 | Regression loss: 0.12990 | Running loss: 0.28981\n",
            "Epoch: 12 | Iteration: 1001 | Classification loss: 0.04876 | Regression loss: 0.17001 | Running loss: 0.28952\n",
            "Epoch: 12 | Iteration: 1002 | Classification loss: 0.12519 | Regression loss: 0.22544 | Running loss: 0.28945\n",
            "Epoch: 12 | Iteration: 1003 | Classification loss: 0.06466 | Regression loss: 0.19964 | Running loss: 0.28955\n",
            "Epoch: 12 | Iteration: 1004 | Classification loss: 0.13176 | Regression loss: 0.28578 | Running loss: 0.28947\n",
            "Epoch: 12 | Iteration: 1005 | Classification loss: 0.05514 | Regression loss: 0.04219 | Running loss: 0.28921\n",
            "Epoch: 12 | Iteration: 1006 | Classification loss: 0.16622 | Regression loss: 0.35963 | Running loss: 0.28979\n",
            "Epoch: 12 | Iteration: 1007 | Classification loss: 0.04691 | Regression loss: 0.15144 | Running loss: 0.28975\n",
            "Epoch: 12 | Iteration: 1008 | Classification loss: 0.18638 | Regression loss: 0.34234 | Running loss: 0.29042\n",
            "Epoch: 12 | Iteration: 1009 | Classification loss: 0.07560 | Regression loss: 0.16929 | Running loss: 0.29057\n",
            "Epoch: 12 | Iteration: 1010 | Classification loss: 0.07546 | Regression loss: 0.14787 | Running loss: 0.29081\n",
            "Epoch: 12 | Iteration: 1011 | Classification loss: 0.06920 | Regression loss: 0.14539 | Running loss: 0.29072\n",
            "Epoch: 12 | Iteration: 1012 | Classification loss: 0.12826 | Regression loss: 0.23372 | Running loss: 0.29113\n",
            "Epoch: 12 | Iteration: 1013 | Classification loss: 0.12982 | Regression loss: 0.20884 | Running loss: 0.29094\n",
            "Epoch: 12 | Iteration: 1014 | Classification loss: 0.14440 | Regression loss: 0.29660 | Running loss: 0.29106\n",
            "Epoch: 12 | Iteration: 1015 | Classification loss: 0.09960 | Regression loss: 0.23228 | Running loss: 0.29133\n",
            "Epoch: 12 | Iteration: 1016 | Classification loss: 0.10849 | Regression loss: 0.19034 | Running loss: 0.29171\n",
            "Epoch: 12 | Iteration: 1017 | Classification loss: 0.14388 | Regression loss: 0.25748 | Running loss: 0.29212\n",
            "Epoch: 12 | Iteration: 1018 | Classification loss: 0.05666 | Regression loss: 0.15922 | Running loss: 0.29214\n",
            "Epoch: 12 | Iteration: 1019 | Classification loss: 0.07579 | Regression loss: 0.18580 | Running loss: 0.29189\n",
            "Epoch: 12 | Iteration: 1020 | Classification loss: 0.12502 | Regression loss: 0.36472 | Running loss: 0.29226\n",
            "Epoch: 12 | Iteration: 1021 | Classification loss: 0.08501 | Regression loss: 0.12671 | Running loss: 0.29194\n",
            "Epoch: 12 | Iteration: 1022 | Classification loss: 0.01490 | Regression loss: 0.09548 | Running loss: 0.29173\n",
            "Epoch: 12 | Iteration: 1023 | Classification loss: 0.08741 | Regression loss: 0.20143 | Running loss: 0.29183\n",
            "Epoch: 12 | Iteration: 1024 | Classification loss: 0.06763 | Regression loss: 0.19005 | Running loss: 0.29165\n",
            "Epoch: 12 | Iteration: 1025 | Classification loss: 0.11091 | Regression loss: 0.28990 | Running loss: 0.29166\n",
            "Epoch: 12 | Iteration: 1026 | Classification loss: 0.05188 | Regression loss: 0.12168 | Running loss: 0.29156\n",
            "Epoch: 12 | Iteration: 1027 | Classification loss: 0.05972 | Regression loss: 0.20486 | Running loss: 0.29076\n",
            "Epoch: 12 | Iteration: 1028 | Classification loss: 0.16969 | Regression loss: 0.32737 | Running loss: 0.29152\n",
            "Epoch: 12 | Iteration: 1029 | Classification loss: 0.13399 | Regression loss: 0.29681 | Running loss: 0.29187\n",
            "Epoch: 12 | Iteration: 1030 | Classification loss: 0.14239 | Regression loss: 0.37123 | Running loss: 0.29226\n",
            "Epoch: 12 | Iteration: 1031 | Classification loss: 0.07859 | Regression loss: 0.21549 | Running loss: 0.29204\n",
            "Epoch: 12 | Iteration: 1032 | Classification loss: 0.30484 | Regression loss: 0.47079 | Running loss: 0.29289\n",
            "Epoch: 12 | Iteration: 1033 | Classification loss: 0.07465 | Regression loss: 0.24964 | Running loss: 0.29285\n",
            "Epoch: 12 | Iteration: 1034 | Classification loss: 0.07132 | Regression loss: 0.19518 | Running loss: 0.29300\n",
            "Epoch: 12 | Iteration: 1035 | Classification loss: 0.09236 | Regression loss: 0.19649 | Running loss: 0.29307\n",
            "Epoch: 12 | Iteration: 1036 | Classification loss: 0.04451 | Regression loss: 0.16833 | Running loss: 0.29293\n",
            "Epoch: 12 | Iteration: 1037 | Classification loss: 0.23173 | Regression loss: 0.35167 | Running loss: 0.29381\n",
            "Epoch: 12 | Iteration: 1038 | Classification loss: 0.09956 | Regression loss: 0.20726 | Running loss: 0.29371\n",
            "Epoch: 12 | Iteration: 1039 | Classification loss: 0.10601 | Regression loss: 0.24210 | Running loss: 0.29358\n",
            "Epoch: 12 | Iteration: 1040 | Classification loss: 0.06666 | Regression loss: 0.15008 | Running loss: 0.29345\n",
            "Epoch: 12 | Iteration: 1041 | Classification loss: 0.11930 | Regression loss: 0.25685 | Running loss: 0.29300\n",
            "Epoch: 12 | Iteration: 1042 | Classification loss: 0.14951 | Regression loss: 0.23264 | Running loss: 0.29319\n",
            "Epoch: 12 | Iteration: 1043 | Classification loss: 0.10733 | Regression loss: 0.19333 | Running loss: 0.29334\n",
            "Epoch: 12 | Iteration: 1044 | Classification loss: 0.05422 | Regression loss: 0.18024 | Running loss: 0.29337\n",
            "Epoch: 12 | Iteration: 1045 | Classification loss: 0.12474 | Regression loss: 0.28585 | Running loss: 0.29339\n",
            "Epoch: 12 | Iteration: 1046 | Classification loss: 0.12514 | Regression loss: 0.18240 | Running loss: 0.29315\n",
            "Epoch: 12 | Iteration: 1047 | Classification loss: 0.11676 | Regression loss: 0.34485 | Running loss: 0.29316\n",
            "Epoch: 12 | Iteration: 1048 | Classification loss: 0.03017 | Regression loss: 0.17305 | Running loss: 0.29304\n",
            "Epoch: 12 | Iteration: 1049 | Classification loss: 0.04061 | Regression loss: 0.11256 | Running loss: 0.29255\n",
            "Epoch: 12 | Iteration: 1050 | Classification loss: 0.03938 | Regression loss: 0.12943 | Running loss: 0.29254\n",
            "Epoch: 12 | Iteration: 1051 | Classification loss: 0.25239 | Regression loss: 0.29304 | Running loss: 0.29302\n",
            "Epoch: 12 | Iteration: 1052 | Classification loss: 0.10594 | Regression loss: 0.23725 | Running loss: 0.29321\n",
            "Epoch: 12 | Iteration: 1053 | Classification loss: 0.21666 | Regression loss: 0.30856 | Running loss: 0.29348\n",
            "Epoch: 12 | Iteration: 1054 | Classification loss: 0.05065 | Regression loss: 0.12857 | Running loss: 0.29321\n",
            "Epoch: 12 | Iteration: 1055 | Classification loss: 0.07554 | Regression loss: 0.16967 | Running loss: 0.29276\n",
            "Epoch: 12 | Iteration: 1056 | Classification loss: 0.12926 | Regression loss: 0.11315 | Running loss: 0.29228\n",
            "Epoch: 12 | Iteration: 1057 | Classification loss: 0.05849 | Regression loss: 0.12786 | Running loss: 0.29190\n",
            "Epoch: 12 | Iteration: 1058 | Classification loss: 0.09662 | Regression loss: 0.21068 | Running loss: 0.29132\n",
            "Epoch: 12 | Iteration: 1059 | Classification loss: 0.04843 | Regression loss: 0.14820 | Running loss: 0.29134\n",
            "Epoch: 12 | Iteration: 1060 | Classification loss: 0.07228 | Regression loss: 0.16049 | Running loss: 0.29122\n",
            "Epoch: 12 | Iteration: 1061 | Classification loss: 0.06445 | Regression loss: 0.20719 | Running loss: 0.29145\n",
            "Epoch: 12 | Iteration: 1062 | Classification loss: 0.21132 | Regression loss: 0.18697 | Running loss: 0.29178\n",
            "Epoch: 12 | Iteration: 1063 | Classification loss: 0.05321 | Regression loss: 0.09521 | Running loss: 0.29127\n",
            "Epoch: 12 | Iteration: 1064 | Classification loss: 0.22914 | Regression loss: 0.46164 | Running loss: 0.29203\n",
            "Epoch: 12 | Iteration: 1065 | Classification loss: 0.08600 | Regression loss: 0.20785 | Running loss: 0.29193\n",
            "Epoch: 12 | Iteration: 1066 | Classification loss: 0.09732 | Regression loss: 0.25320 | Running loss: 0.29222\n",
            "Epoch: 12 | Iteration: 1067 | Classification loss: 0.03029 | Regression loss: 0.12571 | Running loss: 0.29190\n",
            "Epoch: 12 | Iteration: 1068 | Classification loss: 0.08200 | Regression loss: 0.18485 | Running loss: 0.29197\n",
            "Epoch: 12 | Iteration: 1069 | Classification loss: 0.07694 | Regression loss: 0.20628 | Running loss: 0.29177\n",
            "Epoch: 12 | Iteration: 1070 | Classification loss: 0.02608 | Regression loss: 0.15110 | Running loss: 0.29174\n",
            "Epoch: 12 | Iteration: 1071 | Classification loss: 0.06684 | Regression loss: 0.25073 | Running loss: 0.29201\n",
            "Epoch: 12 | Iteration: 1072 | Classification loss: 0.09641 | Regression loss: 0.11123 | Running loss: 0.29169\n",
            "Epoch: 12 | Iteration: 1073 | Classification loss: 0.08770 | Regression loss: 0.26096 | Running loss: 0.29219\n",
            "Epoch: 12 | Iteration: 1074 | Classification loss: 0.07106 | Regression loss: 0.16493 | Running loss: 0.29184\n",
            "Epoch: 12 | Iteration: 1075 | Classification loss: 0.16722 | Regression loss: 0.33724 | Running loss: 0.29245\n",
            "Epoch: 12 | Iteration: 1076 | Classification loss: 0.05177 | Regression loss: 0.19203 | Running loss: 0.29223\n",
            "Epoch: 12 | Iteration: 1077 | Classification loss: 0.12542 | Regression loss: 0.26675 | Running loss: 0.29267\n",
            "Epoch: 12 | Iteration: 1078 | Classification loss: 0.02464 | Regression loss: 0.12200 | Running loss: 0.29242\n",
            "Epoch: 12 | Iteration: 1079 | Classification loss: 0.06585 | Regression loss: 0.18925 | Running loss: 0.29200\n",
            "Epoch: 12 | Iteration: 1080 | Classification loss: 0.08628 | Regression loss: 0.28935 | Running loss: 0.29226\n",
            "Epoch: 12 | Iteration: 1081 | Classification loss: 0.12942 | Regression loss: 0.24110 | Running loss: 0.29147\n",
            "Epoch: 12 | Iteration: 1082 | Classification loss: 0.05113 | Regression loss: 0.11443 | Running loss: 0.29153\n",
            "Epoch: 12 | Iteration: 1083 | Classification loss: 0.06659 | Regression loss: 0.17899 | Running loss: 0.29146\n",
            "Epoch: 12 | Iteration: 1084 | Classification loss: 0.18762 | Regression loss: 0.25373 | Running loss: 0.29183\n",
            "Epoch: 12 | Iteration: 1085 | Classification loss: 0.06706 | Regression loss: 0.14828 | Running loss: 0.29148\n",
            "Epoch: 12 | Iteration: 1086 | Classification loss: 0.01703 | Regression loss: 0.09679 | Running loss: 0.29137\n",
            "Epoch: 12 | Iteration: 1087 | Classification loss: 0.10795 | Regression loss: 0.26625 | Running loss: 0.29163\n",
            "Epoch: 12 | Iteration: 1088 | Classification loss: 0.15513 | Regression loss: 0.16816 | Running loss: 0.29150\n",
            "Epoch: 12 | Iteration: 1089 | Classification loss: 0.06511 | Regression loss: 0.19020 | Running loss: 0.29154\n",
            "Epoch: 12 | Iteration: 1090 | Classification loss: 0.07549 | Regression loss: 0.25095 | Running loss: 0.29160\n",
            "Epoch: 12 | Iteration: 1091 | Classification loss: 0.10110 | Regression loss: 0.25732 | Running loss: 0.29203\n",
            "Epoch: 12 | Iteration: 1092 | Classification loss: 0.05046 | Regression loss: 0.13218 | Running loss: 0.29209\n",
            "Epoch: 12 | Iteration: 1093 | Classification loss: 0.07025 | Regression loss: 0.15782 | Running loss: 0.29198\n",
            "Epoch: 12 | Iteration: 1094 | Classification loss: 0.06628 | Regression loss: 0.16390 | Running loss: 0.29169\n",
            "Epoch: 12 | Iteration: 1095 | Classification loss: 0.09473 | Regression loss: 0.20144 | Running loss: 0.29165\n",
            "Epoch: 12 | Iteration: 1096 | Classification loss: 0.16007 | Regression loss: 0.33579 | Running loss: 0.29189\n",
            "Epoch: 12 | Iteration: 1097 | Classification loss: 0.07091 | Regression loss: 0.16232 | Running loss: 0.29131\n",
            "Epoch: 12 | Iteration: 1098 | Classification loss: 0.05065 | Regression loss: 0.17257 | Running loss: 0.29142\n",
            "Epoch: 12 | Iteration: 1099 | Classification loss: 0.05764 | Regression loss: 0.23869 | Running loss: 0.29142\n",
            "Epoch: 12 | Iteration: 1100 | Classification loss: 0.07150 | Regression loss: 0.17305 | Running loss: 0.29156\n",
            "Epoch: 12 | Iteration: 1101 | Classification loss: 0.09705 | Regression loss: 0.21119 | Running loss: 0.29154\n",
            "Epoch: 12 | Iteration: 1102 | Classification loss: 0.04217 | Regression loss: 0.17812 | Running loss: 0.29126\n",
            "Epoch: 12 | Iteration: 1103 | Classification loss: 0.10254 | Regression loss: 0.28752 | Running loss: 0.29156\n",
            "Epoch: 12 | Iteration: 1104 | Classification loss: 0.17099 | Regression loss: 0.33151 | Running loss: 0.29224\n",
            "Epoch: 12 | Iteration: 1105 | Classification loss: 0.10982 | Regression loss: 0.31173 | Running loss: 0.29264\n",
            "Epoch: 12 | Iteration: 1106 | Classification loss: 0.17596 | Regression loss: 0.21085 | Running loss: 0.29290\n",
            "Epoch: 12 | Iteration: 1107 | Classification loss: 0.06369 | Regression loss: 0.20223 | Running loss: 0.29282\n",
            "Epoch: 12 | Iteration: 1108 | Classification loss: 0.13133 | Regression loss: 0.17493 | Running loss: 0.29287\n",
            "Epoch: 12 | Iteration: 1109 | Classification loss: 0.08381 | Regression loss: 0.19616 | Running loss: 0.29279\n",
            "Epoch: 12 | Iteration: 1110 | Classification loss: 0.12058 | Regression loss: 0.21177 | Running loss: 0.29273\n",
            "Epoch: 12 | Iteration: 1111 | Classification loss: 0.22042 | Regression loss: 0.34643 | Running loss: 0.29337\n",
            "Epoch: 12 | Iteration: 1112 | Classification loss: 0.08221 | Regression loss: 0.26064 | Running loss: 0.29334\n",
            "Epoch: 12 | Iteration: 1113 | Classification loss: 0.06331 | Regression loss: 0.20865 | Running loss: 0.29327\n",
            "Epoch: 12 | Iteration: 1114 | Classification loss: 0.06293 | Regression loss: 0.17597 | Running loss: 0.29251\n",
            "Epoch: 12 | Iteration: 1115 | Classification loss: 0.16432 | Regression loss: 0.13353 | Running loss: 0.29256\n",
            "Epoch: 12 | Iteration: 1116 | Classification loss: 0.10489 | Regression loss: 0.18292 | Running loss: 0.29252\n",
            "Epoch: 12 | Iteration: 1117 | Classification loss: 0.14824 | Regression loss: 0.24145 | Running loss: 0.29282\n",
            "Epoch: 12 | Iteration: 1118 | Classification loss: 0.07579 | Regression loss: 0.22262 | Running loss: 0.29298\n",
            "Epoch: 12 | Iteration: 1119 | Classification loss: 0.06340 | Regression loss: 0.19070 | Running loss: 0.29308\n",
            "Epoch: 12 | Iteration: 1120 | Classification loss: 0.05942 | Regression loss: 0.16628 | Running loss: 0.29301\n",
            "Epoch: 12 | Iteration: 1121 | Classification loss: 0.05848 | Regression loss: 0.15715 | Running loss: 0.29283\n",
            "Epoch: 12 | Iteration: 1122 | Classification loss: 0.06796 | Regression loss: 0.13271 | Running loss: 0.29240\n",
            "Epoch: 12 | Iteration: 1123 | Classification loss: 0.23748 | Regression loss: 0.33697 | Running loss: 0.29321\n",
            "Epoch: 12 | Iteration: 1124 | Classification loss: 0.11733 | Regression loss: 0.28044 | Running loss: 0.29369\n",
            "Epoch: 12 | Iteration: 1125 | Classification loss: 0.14076 | Regression loss: 0.27180 | Running loss: 0.29425\n",
            "Epoch: 12 | Iteration: 1126 | Classification loss: 0.04575 | Regression loss: 0.13644 | Running loss: 0.29421\n",
            "Epoch: 12 | Iteration: 1127 | Classification loss: 0.03624 | Regression loss: 0.12990 | Running loss: 0.29406\n",
            "Epoch: 12 | Iteration: 1128 | Classification loss: 0.13472 | Regression loss: 0.29157 | Running loss: 0.29449\n",
            "Epoch: 12 | Iteration: 1129 | Classification loss: 0.10245 | Regression loss: 0.25177 | Running loss: 0.29458\n",
            "Epoch: 12 | Iteration: 1130 | Classification loss: 0.13023 | Regression loss: 0.23045 | Running loss: 0.29491\n",
            "Epoch: 12 | Iteration: 1131 | Classification loss: 0.00075 | Regression loss: 0.02345 | Running loss: 0.29460\n",
            "Epoch: 12 | Iteration: 1132 | Classification loss: 0.11360 | Regression loss: 0.28039 | Running loss: 0.29471\n",
            "Epoch: 12 | Iteration: 1133 | Classification loss: 0.12296 | Regression loss: 0.20811 | Running loss: 0.29496\n",
            "Epoch: 12 | Iteration: 1134 | Classification loss: 0.07555 | Regression loss: 0.15567 | Running loss: 0.29483\n",
            "Epoch: 12 | Iteration: 1135 | Classification loss: 0.11717 | Regression loss: 0.18344 | Running loss: 0.29508\n",
            "Epoch: 12 | Iteration: 1136 | Classification loss: 0.16519 | Regression loss: 0.20213 | Running loss: 0.29536\n",
            "Epoch: 12 | Iteration: 1137 | Classification loss: 0.05306 | Regression loss: 0.13890 | Running loss: 0.29509\n",
            "Epoch: 12 | Iteration: 1138 | Classification loss: 0.17302 | Regression loss: 0.35980 | Running loss: 0.29507\n",
            "Epoch: 12 | Iteration: 1139 | Classification loss: 0.08728 | Regression loss: 0.14651 | Running loss: 0.29485\n",
            "Epoch: 12 | Iteration: 1140 | Classification loss: 0.03563 | Regression loss: 0.13296 | Running loss: 0.29393\n",
            "Epoch: 12 | Iteration: 1141 | Classification loss: 0.18611 | Regression loss: 0.36210 | Running loss: 0.29389\n",
            "Epoch: 12 | Iteration: 1142 | Classification loss: 0.17862 | Regression loss: 0.28601 | Running loss: 0.29418\n",
            "Epoch: 12 | Iteration: 1143 | Classification loss: 0.17058 | Regression loss: 0.25483 | Running loss: 0.29471\n",
            "Epoch: 12 | Iteration: 1144 | Classification loss: 0.07365 | Regression loss: 0.19499 | Running loss: 0.29474\n",
            "Epoch: 12 | Iteration: 1145 | Classification loss: 0.04040 | Regression loss: 0.16419 | Running loss: 0.29443\n",
            "Epoch: 12 | Iteration: 1146 | Classification loss: 0.22260 | Regression loss: 0.38309 | Running loss: 0.29506\n",
            "Epoch: 12 | Iteration: 1147 | Classification loss: 0.04927 | Regression loss: 0.19875 | Running loss: 0.29492\n",
            "Epoch: 12 | Iteration: 1148 | Classification loss: 0.03424 | Regression loss: 0.10646 | Running loss: 0.29425\n",
            "Epoch: 12 | Iteration: 1149 | Classification loss: 0.09928 | Regression loss: 0.26782 | Running loss: 0.29466\n",
            "Epoch: 12 | Iteration: 1150 | Classification loss: 0.16069 | Regression loss: 0.19901 | Running loss: 0.29517\n",
            "Epoch: 12 | Iteration: 1151 | Classification loss: 0.05768 | Regression loss: 0.18011 | Running loss: 0.29515\n",
            "Epoch: 12 | Iteration: 1152 | Classification loss: 0.08806 | Regression loss: 0.30001 | Running loss: 0.29521\n",
            "Epoch: 12 | Iteration: 1153 | Classification loss: 0.06745 | Regression loss: 0.19497 | Running loss: 0.29521\n",
            "Epoch: 12 | Iteration: 1154 | Classification loss: 0.09095 | Regression loss: 0.19813 | Running loss: 0.29530\n",
            "Epoch: 12 | Iteration: 1155 | Classification loss: 0.05403 | Regression loss: 0.14449 | Running loss: 0.29526\n",
            "Epoch: 12 | Iteration: 1156 | Classification loss: 0.10588 | Regression loss: 0.20768 | Running loss: 0.29549\n",
            "Epoch: 12 | Iteration: 1157 | Classification loss: 0.02618 | Regression loss: 0.15031 | Running loss: 0.29529\n",
            "Epoch: 12 | Iteration: 1158 | Classification loss: 0.06245 | Regression loss: 0.15549 | Running loss: 0.29555\n",
            "Epoch: 12 | Iteration: 1159 | Classification loss: 0.07802 | Regression loss: 0.15585 | Running loss: 0.29549\n",
            "Epoch: 12 | Iteration: 1160 | Classification loss: 0.08267 | Regression loss: 0.22424 | Running loss: 0.29589\n",
            "Epoch: 12 | Iteration: 1161 | Classification loss: 0.14373 | Regression loss: 0.24289 | Running loss: 0.29605\n",
            "Epoch: 12 | Iteration: 1162 | Classification loss: 0.05649 | Regression loss: 0.14969 | Running loss: 0.29593\n",
            "Epoch: 12 | Iteration: 1163 | Classification loss: 0.20248 | Regression loss: 0.37876 | Running loss: 0.29658\n",
            "Epoch: 12 | Iteration: 1164 | Classification loss: 0.04492 | Regression loss: 0.25449 | Running loss: 0.29662\n",
            "Epoch: 12 | Iteration: 1165 | Classification loss: 0.08896 | Regression loss: 0.32932 | Running loss: 0.29705\n",
            "Epoch: 12 | Iteration: 1166 | Classification loss: 0.09457 | Regression loss: 0.23727 | Running loss: 0.29749\n",
            "Epoch: 12 | Iteration: 1167 | Classification loss: 0.17607 | Regression loss: 0.28617 | Running loss: 0.29774\n",
            "Epoch: 12 | Iteration: 1168 | Classification loss: 0.18498 | Regression loss: 0.31544 | Running loss: 0.29825\n",
            "Epoch: 12 | Iteration: 1169 | Classification loss: 0.05560 | Regression loss: 0.21816 | Running loss: 0.29819\n",
            "Epoch: 12 | Iteration: 1170 | Classification loss: 0.13723 | Regression loss: 0.31018 | Running loss: 0.29858\n",
            "Epoch: 12 | Iteration: 1171 | Classification loss: 0.13845 | Regression loss: 0.26479 | Running loss: 0.29885\n",
            "Epoch: 12 | Iteration: 1172 | Classification loss: 0.10327 | Regression loss: 0.21905 | Running loss: 0.29866\n",
            "Epoch: 12 | Iteration: 1173 | Classification loss: 0.01315 | Regression loss: 0.09244 | Running loss: 0.29873\n",
            "Epoch: 12 | Iteration: 1174 | Classification loss: 0.05104 | Regression loss: 0.13156 | Running loss: 0.29874\n",
            "Epoch: 12 | Iteration: 1175 | Classification loss: 0.09932 | Regression loss: 0.22348 | Running loss: 0.29899\n",
            "Epoch: 12 | Iteration: 1176 | Classification loss: 0.04144 | Regression loss: 0.13691 | Running loss: 0.29882\n",
            "Epoch: 12 | Iteration: 1177 | Classification loss: 0.06190 | Regression loss: 0.14419 | Running loss: 0.29875\n",
            "Epoch: 12 | Iteration: 1178 | Classification loss: 0.09701 | Regression loss: 0.18857 | Running loss: 0.29856\n",
            "Epoch: 12 | Iteration: 1179 | Classification loss: 0.15981 | Regression loss: 0.31177 | Running loss: 0.29898\n",
            "Epoch: 12 | Iteration: 1180 | Classification loss: 0.13380 | Regression loss: 0.24222 | Running loss: 0.29952\n",
            "Epoch: 12 | Iteration: 1181 | Classification loss: 0.16002 | Regression loss: 0.27165 | Running loss: 0.29939\n",
            "Epoch: 12 | Iteration: 1182 | Classification loss: 0.02661 | Regression loss: 0.09830 | Running loss: 0.29897\n",
            "Epoch: 12 | Iteration: 1183 | Classification loss: 0.13564 | Regression loss: 0.21936 | Running loss: 0.29889\n",
            "Epoch: 12 | Iteration: 1184 | Classification loss: 0.07850 | Regression loss: 0.20733 | Running loss: 0.29879\n",
            "Epoch: 12 | Iteration: 1185 | Classification loss: 0.04909 | Regression loss: 0.11359 | Running loss: 0.29840\n",
            "Epoch: 12 | Iteration: 1186 | Classification loss: 0.14331 | Regression loss: 0.31100 | Running loss: 0.29892\n",
            "Epoch: 12 | Iteration: 1187 | Classification loss: 0.16571 | Regression loss: 0.26398 | Running loss: 0.29927\n",
            "Epoch: 12 | Iteration: 1188 | Classification loss: 0.09722 | Regression loss: 0.23013 | Running loss: 0.29971\n",
            "Epoch: 12 | Iteration: 1189 | Classification loss: 0.09551 | Regression loss: 0.26946 | Running loss: 0.29991\n",
            "Epoch: 12 | Iteration: 1190 | Classification loss: 0.09188 | Regression loss: 0.19805 | Running loss: 0.30008\n",
            "Epoch: 12 | Iteration: 1191 | Classification loss: 0.02165 | Regression loss: 0.18867 | Running loss: 0.29999\n",
            "Epoch: 12 | Iteration: 1192 | Classification loss: 0.07444 | Regression loss: 0.21132 | Running loss: 0.30031\n",
            "Epoch: 12 | Iteration: 1193 | Classification loss: 0.04778 | Regression loss: 0.15268 | Running loss: 0.30010\n",
            "Epoch: 12 | Iteration: 1194 | Classification loss: 0.11724 | Regression loss: 0.15296 | Running loss: 0.29945\n",
            "Epoch: 12 | Iteration: 1195 | Classification loss: 0.10811 | Regression loss: 0.19585 | Running loss: 0.29970\n",
            "Epoch: 12 | Iteration: 1196 | Classification loss: 0.04657 | Regression loss: 0.14233 | Running loss: 0.29963\n",
            "Epoch: 12 | Iteration: 1197 | Classification loss: 0.18103 | Regression loss: 0.33034 | Running loss: 0.29992\n",
            "Epoch: 12 | Iteration: 1198 | Classification loss: 0.10410 | Regression loss: 0.16156 | Running loss: 0.29998\n",
            "Epoch: 12 | Iteration: 1199 | Classification loss: 0.14525 | Regression loss: 0.19632 | Running loss: 0.30015\n",
            "Evaluating dataset\n",
            "\n",
            "mAP:\n",
            "ambulance: 0.003826805605461732\n",
            "auto rickshaw: 0.34553520142778127\n",
            "bicycle: 0.2929377884339607\n",
            "bus: 0.6551836613439395\n",
            "car: 0.6273403354450138\n",
            "garbage van: 0\n",
            "human hauler: 0.09532959108720719\n",
            "minibus: 0.02507793119691137\n",
            "minivan: 0.2719087926996011\n",
            "motorbike: 0.5499178690852573\n",
            "pickup: 0.35920182747362167\n",
            "army vehicle: 0.6306743789794638\n",
            "policecar: 0.004285714285714286\n",
            "rickshaw: 0.5085803052970885\n",
            "scooter: 0.16666666666666666\n",
            "suv: 0.20962879062954115\n",
            "taxi: 0.4461538461538462\n",
            "three wheelers (CNG): 0.585587061700446\n",
            "truck: 0.6423377730044342\n",
            "van: 0.20221451119462333\n",
            "wheelbarrow: 0.051648337255062696\n",
            "Epoch: 13 | Iteration: 0 | Classification loss: 0.10684 | Regression loss: 0.30178 | Running loss: 0.30030\n",
            "Epoch: 13 | Iteration: 1 | Classification loss: 0.03920 | Regression loss: 0.12538 | Running loss: 0.30035\n",
            "Epoch: 13 | Iteration: 2 | Classification loss: 0.02116 | Regression loss: 0.06775 | Running loss: 0.30011\n",
            "Epoch: 13 | Iteration: 3 | Classification loss: 0.06538 | Regression loss: 0.17518 | Running loss: 0.29936\n",
            "Epoch: 13 | Iteration: 4 | Classification loss: 0.04458 | Regression loss: 0.13778 | Running loss: 0.29914\n",
            "Epoch: 13 | Iteration: 5 | Classification loss: 0.12204 | Regression loss: 0.22440 | Running loss: 0.29904\n",
            "Epoch: 13 | Iteration: 6 | Classification loss: 0.10644 | Regression loss: 0.22959 | Running loss: 0.29921\n",
            "Epoch: 13 | Iteration: 7 | Classification loss: 0.04858 | Regression loss: 0.17994 | Running loss: 0.29887\n",
            "Epoch: 13 | Iteration: 8 | Classification loss: 0.09165 | Regression loss: 0.24960 | Running loss: 0.29921\n",
            "Epoch: 13 | Iteration: 9 | Classification loss: 0.07270 | Regression loss: 0.24967 | Running loss: 0.29911\n",
            "Epoch: 13 | Iteration: 10 | Classification loss: 0.06974 | Regression loss: 0.11204 | Running loss: 0.29898\n",
            "Epoch: 13 | Iteration: 11 | Classification loss: 0.12999 | Regression loss: 0.40216 | Running loss: 0.29904\n",
            "Epoch: 13 | Iteration: 12 | Classification loss: 0.04818 | Regression loss: 0.16880 | Running loss: 0.29897\n",
            "Epoch: 13 | Iteration: 13 | Classification loss: 0.08715 | Regression loss: 0.22324 | Running loss: 0.29872\n",
            "Epoch: 13 | Iteration: 14 | Classification loss: 0.04899 | Regression loss: 0.23313 | Running loss: 0.29874\n",
            "Epoch: 13 | Iteration: 15 | Classification loss: 0.09358 | Regression loss: 0.35222 | Running loss: 0.29934\n",
            "Epoch: 13 | Iteration: 16 | Classification loss: 0.04521 | Regression loss: 0.13754 | Running loss: 0.29923\n",
            "Epoch: 13 | Iteration: 17 | Classification loss: 0.03429 | Regression loss: 0.12824 | Running loss: 0.29851\n",
            "Epoch: 13 | Iteration: 18 | Classification loss: 0.09550 | Regression loss: 0.21576 | Running loss: 0.29841\n",
            "Epoch: 13 | Iteration: 19 | Classification loss: 0.11847 | Regression loss: 0.28357 | Running loss: 0.29871\n",
            "Epoch: 13 | Iteration: 20 | Classification loss: 0.02440 | Regression loss: 0.10795 | Running loss: 0.29826\n",
            "Epoch: 13 | Iteration: 21 | Classification loss: 0.05392 | Regression loss: 0.11597 | Running loss: 0.29809\n",
            "Epoch: 13 | Iteration: 22 | Classification loss: 0.12240 | Regression loss: 0.35910 | Running loss: 0.29875\n",
            "Epoch: 13 | Iteration: 23 | Classification loss: 0.06882 | Regression loss: 0.18167 | Running loss: 0.29866\n",
            "Epoch: 13 | Iteration: 24 | Classification loss: 0.04763 | Regression loss: 0.17693 | Running loss: 0.29887\n",
            "Epoch: 13 | Iteration: 25 | Classification loss: 0.03111 | Regression loss: 0.15592 | Running loss: 0.29828\n",
            "Epoch: 13 | Iteration: 26 | Classification loss: 0.05525 | Regression loss: 0.23267 | Running loss: 0.29849\n",
            "Epoch: 13 | Iteration: 27 | Classification loss: 0.11058 | Regression loss: 0.23711 | Running loss: 0.29881\n",
            "Epoch: 13 | Iteration: 28 | Classification loss: 0.12751 | Regression loss: 0.18206 | Running loss: 0.29899\n",
            "Epoch: 13 | Iteration: 29 | Classification loss: 0.07242 | Regression loss: 0.23486 | Running loss: 0.29904\n",
            "Epoch: 13 | Iteration: 30 | Classification loss: 0.08731 | Regression loss: 0.13242 | Running loss: 0.29884\n",
            "Epoch: 13 | Iteration: 31 | Classification loss: 0.04118 | Regression loss: 0.16737 | Running loss: 0.29844\n",
            "Epoch: 13 | Iteration: 32 | Classification loss: 0.19087 | Regression loss: 0.42697 | Running loss: 0.29928\n",
            "Epoch: 13 | Iteration: 33 | Classification loss: 0.01763 | Regression loss: 0.10621 | Running loss: 0.29909\n",
            "Epoch: 13 | Iteration: 34 | Classification loss: 0.02461 | Regression loss: 0.12798 | Running loss: 0.29898\n",
            "Epoch: 13 | Iteration: 35 | Classification loss: 0.08103 | Regression loss: 0.23877 | Running loss: 0.29872\n",
            "Epoch: 13 | Iteration: 36 | Classification loss: 0.09302 | Regression loss: 0.18435 | Running loss: 0.29867\n",
            "Epoch: 13 | Iteration: 37 | Classification loss: 0.03945 | Regression loss: 0.11767 | Running loss: 0.29859\n",
            "Epoch: 13 | Iteration: 38 | Classification loss: 0.03816 | Regression loss: 0.16849 | Running loss: 0.29866\n",
            "Epoch: 13 | Iteration: 39 | Classification loss: 0.03716 | Regression loss: 0.13629 | Running loss: 0.29817\n",
            "Epoch: 13 | Iteration: 40 | Classification loss: 0.03863 | Regression loss: 0.12340 | Running loss: 0.29785\n",
            "Epoch: 13 | Iteration: 41 | Classification loss: 0.05976 | Regression loss: 0.17367 | Running loss: 0.29795\n",
            "Epoch: 13 | Iteration: 42 | Classification loss: 0.07808 | Regression loss: 0.25424 | Running loss: 0.29830\n",
            "Epoch: 13 | Iteration: 43 | Classification loss: 0.10653 | Regression loss: 0.23764 | Running loss: 0.29871\n",
            "Epoch: 13 | Iteration: 44 | Classification loss: 0.06229 | Regression loss: 0.16169 | Running loss: 0.29854\n",
            "Epoch: 13 | Iteration: 45 | Classification loss: 0.06735 | Regression loss: 0.20824 | Running loss: 0.29889\n",
            "Epoch: 13 | Iteration: 46 | Classification loss: 0.06792 | Regression loss: 0.14909 | Running loss: 0.29858\n",
            "Epoch: 13 | Iteration: 47 | Classification loss: 0.17044 | Regression loss: 0.19043 | Running loss: 0.29874\n",
            "Epoch: 13 | Iteration: 48 | Classification loss: 0.02033 | Regression loss: 0.08792 | Running loss: 0.29863\n",
            "Epoch: 13 | Iteration: 49 | Classification loss: 0.07039 | Regression loss: 0.17055 | Running loss: 0.29862\n",
            "Epoch: 13 | Iteration: 50 | Classification loss: 0.08929 | Regression loss: 0.18894 | Running loss: 0.29867\n",
            "Epoch: 13 | Iteration: 51 | Classification loss: 0.26628 | Regression loss: 0.42153 | Running loss: 0.29924\n",
            "Epoch: 13 | Iteration: 52 | Classification loss: 0.05286 | Regression loss: 0.15289 | Running loss: 0.29930\n",
            "Epoch: 13 | Iteration: 53 | Classification loss: 0.01246 | Regression loss: 0.06407 | Running loss: 0.29901\n",
            "Epoch: 13 | Iteration: 54 | Classification loss: 0.08504 | Regression loss: 0.19731 | Running loss: 0.29903\n",
            "Epoch: 13 | Iteration: 55 | Classification loss: 0.05527 | Regression loss: 0.16840 | Running loss: 0.29914\n",
            "Epoch: 13 | Iteration: 56 | Classification loss: 0.15425 | Regression loss: 0.32226 | Running loss: 0.29961\n",
            "Epoch: 13 | Iteration: 57 | Classification loss: 0.05946 | Regression loss: 0.11610 | Running loss: 0.29941\n",
            "Epoch: 13 | Iteration: 58 | Classification loss: 0.08846 | Regression loss: 0.22053 | Running loss: 0.29950\n",
            "Epoch: 13 | Iteration: 59 | Classification loss: 0.09410 | Regression loss: 0.21492 | Running loss: 0.29987\n",
            "Epoch: 13 | Iteration: 60 | Classification loss: 0.15374 | Regression loss: 0.27228 | Running loss: 0.30014\n",
            "Epoch: 13 | Iteration: 61 | Classification loss: 0.08360 | Regression loss: 0.25950 | Running loss: 0.30054\n",
            "Epoch: 13 | Iteration: 62 | Classification loss: 0.04299 | Regression loss: 0.13555 | Running loss: 0.30031\n",
            "Epoch: 13 | Iteration: 63 | Classification loss: 0.03791 | Regression loss: 0.12991 | Running loss: 0.30031\n",
            "Epoch: 13 | Iteration: 64 | Classification loss: 0.05431 | Regression loss: 0.11803 | Running loss: 0.30018\n",
            "Epoch: 13 | Iteration: 65 | Classification loss: 0.07162 | Regression loss: 0.13622 | Running loss: 0.29970\n",
            "Epoch: 13 | Iteration: 66 | Classification loss: 0.02043 | Regression loss: 0.12596 | Running loss: 0.29916\n",
            "Epoch: 13 | Iteration: 67 | Classification loss: 0.09129 | Regression loss: 0.28087 | Running loss: 0.29954\n",
            "Epoch: 13 | Iteration: 68 | Classification loss: 0.03459 | Regression loss: 0.13016 | Running loss: 0.29955\n",
            "Epoch: 13 | Iteration: 69 | Classification loss: 0.17603 | Regression loss: 0.31312 | Running loss: 0.29970\n",
            "Epoch: 13 | Iteration: 70 | Classification loss: 0.03024 | Regression loss: 0.08226 | Running loss: 0.29938\n",
            "Epoch: 13 | Iteration: 71 | Classification loss: 0.07068 | Regression loss: 0.28794 | Running loss: 0.29975\n",
            "Epoch: 13 | Iteration: 72 | Classification loss: 0.04070 | Regression loss: 0.14563 | Running loss: 0.29889\n",
            "Epoch: 13 | Iteration: 73 | Classification loss: 0.08945 | Regression loss: 0.17802 | Running loss: 0.29906\n",
            "Epoch: 13 | Iteration: 74 | Classification loss: 0.07356 | Regression loss: 0.21717 | Running loss: 0.29928\n",
            "Epoch: 13 | Iteration: 75 | Classification loss: 0.05150 | Regression loss: 0.11506 | Running loss: 0.29893\n",
            "Epoch: 13 | Iteration: 76 | Classification loss: 0.01166 | Regression loss: 0.08651 | Running loss: 0.29888\n",
            "Epoch: 13 | Iteration: 77 | Classification loss: 0.03109 | Regression loss: 0.15122 | Running loss: 0.29895\n",
            "Epoch: 13 | Iteration: 78 | Classification loss: 0.09228 | Regression loss: 0.23769 | Running loss: 0.29870\n",
            "Epoch: 13 | Iteration: 79 | Classification loss: 0.09347 | Regression loss: 0.22923 | Running loss: 0.29841\n",
            "Epoch: 13 | Iteration: 80 | Classification loss: 0.19377 | Regression loss: 0.36546 | Running loss: 0.29863\n",
            "Epoch: 13 | Iteration: 81 | Classification loss: 0.06981 | Regression loss: 0.16459 | Running loss: 0.29882\n",
            "Epoch: 13 | Iteration: 82 | Classification loss: 0.13241 | Regression loss: 0.24309 | Running loss: 0.29905\n",
            "Epoch: 13 | Iteration: 83 | Classification loss: 0.09066 | Regression loss: 0.21054 | Running loss: 0.29915\n",
            "Epoch: 13 | Iteration: 84 | Classification loss: 0.10757 | Regression loss: 0.20501 | Running loss: 0.29922\n",
            "Epoch: 13 | Iteration: 85 | Classification loss: 0.09690 | Regression loss: 0.19762 | Running loss: 0.29933\n",
            "Epoch: 13 | Iteration: 86 | Classification loss: 0.07501 | Regression loss: 0.21129 | Running loss: 0.29914\n",
            "Epoch: 13 | Iteration: 87 | Classification loss: 0.14136 | Regression loss: 0.33335 | Running loss: 0.29951\n",
            "Epoch: 13 | Iteration: 88 | Classification loss: 0.03280 | Regression loss: 0.14306 | Running loss: 0.29912\n",
            "Epoch: 13 | Iteration: 89 | Classification loss: 0.02523 | Regression loss: 0.11533 | Running loss: 0.29895\n",
            "Epoch: 13 | Iteration: 90 | Classification loss: 0.06337 | Regression loss: 0.29718 | Running loss: 0.29820\n",
            "Epoch: 13 | Iteration: 91 | Classification loss: 0.05901 | Regression loss: 0.15951 | Running loss: 0.29791\n",
            "Epoch: 13 | Iteration: 92 | Classification loss: 0.05677 | Regression loss: 0.14579 | Running loss: 0.29745\n",
            "Epoch: 13 | Iteration: 93 | Classification loss: 0.19659 | Regression loss: 0.34460 | Running loss: 0.29778\n",
            "Epoch: 13 | Iteration: 94 | Classification loss: 0.03040 | Regression loss: 0.17693 | Running loss: 0.29779\n",
            "Epoch: 13 | Iteration: 95 | Classification loss: 0.08885 | Regression loss: 0.22805 | Running loss: 0.29789\n",
            "Epoch: 13 | Iteration: 96 | Classification loss: 0.05457 | Regression loss: 0.17069 | Running loss: 0.29791\n",
            "Epoch: 13 | Iteration: 97 | Classification loss: 0.08764 | Regression loss: 0.26347 | Running loss: 0.29805\n",
            "Epoch: 13 | Iteration: 98 | Classification loss: 0.01959 | Regression loss: 0.11743 | Running loss: 0.29765\n",
            "Epoch: 13 | Iteration: 99 | Classification loss: 0.04579 | Regression loss: 0.15272 | Running loss: 0.29775\n",
            "Epoch: 13 | Iteration: 100 | Classification loss: 0.03499 | Regression loss: 0.15912 | Running loss: 0.29765\n",
            "Epoch: 13 | Iteration: 101 | Classification loss: 0.19296 | Regression loss: 0.32658 | Running loss: 0.29813\n",
            "Epoch: 13 | Iteration: 102 | Classification loss: 0.02582 | Regression loss: 0.11895 | Running loss: 0.29743\n",
            "Epoch: 13 | Iteration: 103 | Classification loss: 0.07655 | Regression loss: 0.17974 | Running loss: 0.29754\n",
            "Epoch: 13 | Iteration: 104 | Classification loss: 0.05735 | Regression loss: 0.13374 | Running loss: 0.29733\n",
            "Epoch: 13 | Iteration: 105 | Classification loss: 0.03392 | Regression loss: 0.15421 | Running loss: 0.29683\n",
            "Epoch: 13 | Iteration: 106 | Classification loss: 0.13929 | Regression loss: 0.15254 | Running loss: 0.29659\n",
            "Epoch: 13 | Iteration: 107 | Classification loss: 0.04190 | Regression loss: 0.12013 | Running loss: 0.29591\n",
            "Epoch: 13 | Iteration: 108 | Classification loss: 0.02956 | Regression loss: 0.16227 | Running loss: 0.29564\n",
            "Epoch: 13 | Iteration: 109 | Classification loss: 0.12816 | Regression loss: 0.28045 | Running loss: 0.29596\n",
            "Epoch: 13 | Iteration: 110 | Classification loss: 0.03096 | Regression loss: 0.09208 | Running loss: 0.29576\n",
            "Epoch: 13 | Iteration: 111 | Classification loss: 0.05317 | Regression loss: 0.15377 | Running loss: 0.29541\n",
            "Epoch: 13 | Iteration: 112 | Classification loss: 0.06306 | Regression loss: 0.21144 | Running loss: 0.29564\n",
            "Epoch: 13 | Iteration: 113 | Classification loss: 0.08651 | Regression loss: 0.11300 | Running loss: 0.29550\n",
            "Epoch: 13 | Iteration: 114 | Classification loss: 0.08243 | Regression loss: 0.25962 | Running loss: 0.29512\n",
            "Epoch: 13 | Iteration: 115 | Classification loss: 0.06072 | Regression loss: 0.20459 | Running loss: 0.29486\n",
            "Epoch: 13 | Iteration: 116 | Classification loss: 0.08815 | Regression loss: 0.22195 | Running loss: 0.29509\n",
            "Epoch: 13 | Iteration: 117 | Classification loss: 0.04198 | Regression loss: 0.13278 | Running loss: 0.29508\n",
            "Epoch: 13 | Iteration: 118 | Classification loss: 0.04468 | Regression loss: 0.12366 | Running loss: 0.29508\n",
            "Epoch: 13 | Iteration: 119 | Classification loss: 0.05182 | Regression loss: 0.10867 | Running loss: 0.29495\n",
            "Epoch: 13 | Iteration: 120 | Classification loss: 0.03491 | Regression loss: 0.14074 | Running loss: 0.29461\n",
            "Epoch: 13 | Iteration: 121 | Classification loss: 0.07279 | Regression loss: 0.22158 | Running loss: 0.29487\n",
            "Epoch: 13 | Iteration: 122 | Classification loss: 0.09138 | Regression loss: 0.19361 | Running loss: 0.29496\n",
            "Epoch: 13 | Iteration: 123 | Classification loss: 0.05961 | Regression loss: 0.19285 | Running loss: 0.29498\n",
            "Epoch: 13 | Iteration: 124 | Classification loss: 0.08654 | Regression loss: 0.17084 | Running loss: 0.29493\n",
            "Epoch: 13 | Iteration: 125 | Classification loss: 0.07867 | Regression loss: 0.12397 | Running loss: 0.29487\n",
            "Epoch: 13 | Iteration: 126 | Classification loss: 0.05596 | Regression loss: 0.13063 | Running loss: 0.29482\n",
            "Epoch: 13 | Iteration: 127 | Classification loss: 0.06181 | Regression loss: 0.16098 | Running loss: 0.29481\n",
            "Epoch: 13 | Iteration: 128 | Classification loss: 0.03850 | Regression loss: 0.10612 | Running loss: 0.29429\n",
            "Epoch: 13 | Iteration: 129 | Classification loss: 0.13653 | Regression loss: 0.32224 | Running loss: 0.29474\n",
            "Epoch: 13 | Iteration: 130 | Classification loss: 0.04795 | Regression loss: 0.15682 | Running loss: 0.29447\n",
            "Epoch: 13 | Iteration: 131 | Classification loss: 0.08356 | Regression loss: 0.19570 | Running loss: 0.29458\n",
            "Epoch: 13 | Iteration: 132 | Classification loss: 0.15072 | Regression loss: 0.22397 | Running loss: 0.29477\n",
            "Epoch: 13 | Iteration: 133 | Classification loss: 0.03203 | Regression loss: 0.12566 | Running loss: 0.29459\n",
            "Epoch: 13 | Iteration: 134 | Classification loss: 0.05246 | Regression loss: 0.15435 | Running loss: 0.29450\n",
            "Epoch: 13 | Iteration: 135 | Classification loss: 0.27978 | Regression loss: 0.35157 | Running loss: 0.29516\n",
            "Epoch: 13 | Iteration: 136 | Classification loss: 0.05215 | Regression loss: 0.09938 | Running loss: 0.29476\n",
            "Epoch: 13 | Iteration: 137 | Classification loss: 0.18845 | Regression loss: 0.39295 | Running loss: 0.29553\n",
            "Epoch: 13 | Iteration: 138 | Classification loss: 0.12128 | Regression loss: 0.19035 | Running loss: 0.29572\n",
            "Epoch: 13 | Iteration: 139 | Classification loss: 0.05083 | Regression loss: 0.20006 | Running loss: 0.29583\n",
            "Epoch: 13 | Iteration: 140 | Classification loss: 0.06917 | Regression loss: 0.17883 | Running loss: 0.29564\n",
            "Epoch: 13 | Iteration: 141 | Classification loss: 0.10293 | Regression loss: 0.24398 | Running loss: 0.29530\n",
            "Epoch: 13 | Iteration: 142 | Classification loss: 0.14085 | Regression loss: 0.29903 | Running loss: 0.29530\n",
            "Epoch: 13 | Iteration: 143 | Classification loss: 0.04300 | Regression loss: 0.13506 | Running loss: 0.29489\n",
            "Epoch: 13 | Iteration: 144 | Classification loss: 0.11287 | Regression loss: 0.24233 | Running loss: 0.29475\n",
            "Epoch: 13 | Iteration: 145 | Classification loss: 0.03934 | Regression loss: 0.30471 | Running loss: 0.29490\n",
            "Epoch: 13 | Iteration: 146 | Classification loss: 0.05025 | Regression loss: 0.14703 | Running loss: 0.29447\n",
            "Epoch: 13 | Iteration: 147 | Classification loss: 0.01859 | Regression loss: 0.11928 | Running loss: 0.29367\n",
            "Epoch: 13 | Iteration: 148 | Classification loss: 0.06134 | Regression loss: 0.27514 | Running loss: 0.29325\n",
            "Epoch: 13 | Iteration: 149 | Classification loss: 0.16799 | Regression loss: 0.34468 | Running loss: 0.29348\n",
            "Epoch: 13 | Iteration: 150 | Classification loss: 0.04894 | Regression loss: 0.15206 | Running loss: 0.29293\n",
            "Epoch: 13 | Iteration: 151 | Classification loss: 0.13282 | Regression loss: 0.26815 | Running loss: 0.29312\n",
            "Epoch: 13 | Iteration: 152 | Classification loss: 0.05338 | Regression loss: 0.14985 | Running loss: 0.29306\n",
            "Epoch: 13 | Iteration: 153 | Classification loss: 0.03846 | Regression loss: 0.24110 | Running loss: 0.29272\n",
            "Epoch: 13 | Iteration: 154 | Classification loss: 0.00622 | Regression loss: 0.06671 | Running loss: 0.29252\n",
            "Epoch: 13 | Iteration: 155 | Classification loss: 0.03859 | Regression loss: 0.13859 | Running loss: 0.29219\n",
            "Epoch: 13 | Iteration: 156 | Classification loss: 0.05184 | Regression loss: 0.16811 | Running loss: 0.29225\n",
            "Epoch: 13 | Iteration: 157 | Classification loss: 0.08650 | Regression loss: 0.23054 | Running loss: 0.29211\n",
            "Epoch: 13 | Iteration: 158 | Classification loss: 0.08799 | Regression loss: 0.12587 | Running loss: 0.29220\n",
            "Epoch: 13 | Iteration: 159 | Classification loss: 0.09974 | Regression loss: 0.19255 | Running loss: 0.29252\n",
            "Epoch: 13 | Iteration: 160 | Classification loss: 0.04553 | Regression loss: 0.17150 | Running loss: 0.29244\n",
            "Epoch: 13 | Iteration: 161 | Classification loss: 0.05219 | Regression loss: 0.17194 | Running loss: 0.29207\n",
            "Epoch: 13 | Iteration: 162 | Classification loss: 0.04191 | Regression loss: 0.07809 | Running loss: 0.29147\n",
            "Epoch: 13 | Iteration: 163 | Classification loss: 0.06924 | Regression loss: 0.15835 | Running loss: 0.29138\n",
            "Epoch: 13 | Iteration: 164 | Classification loss: 0.10231 | Regression loss: 0.26797 | Running loss: 0.29149\n",
            "Epoch: 13 | Iteration: 165 | Classification loss: 0.16676 | Regression loss: 0.23664 | Running loss: 0.29160\n",
            "Epoch: 13 | Iteration: 166 | Classification loss: 0.09238 | Regression loss: 0.17365 | Running loss: 0.29139\n",
            "Epoch: 13 | Iteration: 167 | Classification loss: 0.04524 | Regression loss: 0.16013 | Running loss: 0.29117\n",
            "Epoch: 13 | Iteration: 168 | Classification loss: 0.06050 | Regression loss: 0.15007 | Running loss: 0.29093\n",
            "Epoch: 13 | Iteration: 169 | Classification loss: 0.05312 | Regression loss: 0.15193 | Running loss: 0.29095\n",
            "Epoch: 13 | Iteration: 170 | Classification loss: 0.05521 | Regression loss: 0.10091 | Running loss: 0.29064\n",
            "Epoch: 13 | Iteration: 171 | Classification loss: 0.02868 | Regression loss: 0.16071 | Running loss: 0.29033\n",
            "Epoch: 13 | Iteration: 172 | Classification loss: 0.06240 | Regression loss: 0.19239 | Running loss: 0.28985\n",
            "Epoch: 13 | Iteration: 173 | Classification loss: 0.15631 | Regression loss: 0.30485 | Running loss: 0.29035\n",
            "Epoch: 13 | Iteration: 174 | Classification loss: 0.06464 | Regression loss: 0.15743 | Running loss: 0.29050\n",
            "Epoch: 13 | Iteration: 175 | Classification loss: 0.05474 | Regression loss: 0.16849 | Running loss: 0.29054\n",
            "Epoch: 13 | Iteration: 176 | Classification loss: 0.22181 | Regression loss: 0.29581 | Running loss: 0.29033\n",
            "Epoch: 13 | Iteration: 177 | Classification loss: 0.10190 | Regression loss: 0.25825 | Running loss: 0.29057\n",
            "Epoch: 13 | Iteration: 178 | Classification loss: 0.10049 | Regression loss: 0.30755 | Running loss: 0.29101\n",
            "Epoch: 13 | Iteration: 179 | Classification loss: 0.06328 | Regression loss: 0.12747 | Running loss: 0.29056\n",
            "Epoch: 13 | Iteration: 180 | Classification loss: 0.02421 | Regression loss: 0.05987 | Running loss: 0.29045\n",
            "Epoch: 13 | Iteration: 181 | Classification loss: 0.02610 | Regression loss: 0.11278 | Running loss: 0.29033\n",
            "Epoch: 13 | Iteration: 182 | Classification loss: 0.03731 | Regression loss: 0.14683 | Running loss: 0.29001\n",
            "Epoch: 13 | Iteration: 183 | Classification loss: 0.09480 | Regression loss: 0.24028 | Running loss: 0.29007\n",
            "Epoch: 13 | Iteration: 184 | Classification loss: 0.03306 | Regression loss: 0.19085 | Running loss: 0.28961\n",
            "Epoch: 13 | Iteration: 185 | Classification loss: 0.09657 | Regression loss: 0.21757 | Running loss: 0.28912\n",
            "Epoch: 13 | Iteration: 186 | Classification loss: 0.07696 | Regression loss: 0.25440 | Running loss: 0.28928\n",
            "Epoch: 13 | Iteration: 187 | Classification loss: 0.10004 | Regression loss: 0.23745 | Running loss: 0.28945\n",
            "Epoch: 13 | Iteration: 188 | Classification loss: 0.05520 | Regression loss: 0.20848 | Running loss: 0.28948\n",
            "Epoch: 13 | Iteration: 189 | Classification loss: 0.03256 | Regression loss: 0.08843 | Running loss: 0.28932\n",
            "Epoch: 13 | Iteration: 190 | Classification loss: 0.04591 | Regression loss: 0.13400 | Running loss: 0.28941\n",
            "Epoch: 13 | Iteration: 191 | Classification loss: 0.06375 | Regression loss: 0.19591 | Running loss: 0.28958\n",
            "Epoch: 13 | Iteration: 192 | Classification loss: 0.15188 | Regression loss: 0.34280 | Running loss: 0.29006\n",
            "Epoch: 13 | Iteration: 193 | Classification loss: 0.03746 | Regression loss: 0.15294 | Running loss: 0.29011\n",
            "Epoch: 13 | Iteration: 194 | Classification loss: 0.04502 | Regression loss: 0.14696 | Running loss: 0.29007\n",
            "Epoch: 13 | Iteration: 195 | Classification loss: 0.01478 | Regression loss: 0.08160 | Running loss: 0.28927\n",
            "Epoch: 13 | Iteration: 196 | Classification loss: 0.14172 | Regression loss: 0.21841 | Running loss: 0.28922\n",
            "Epoch: 13 | Iteration: 197 | Classification loss: 0.08013 | Regression loss: 0.17881 | Running loss: 0.28924\n",
            "Epoch: 13 | Iteration: 198 | Classification loss: 0.08613 | Regression loss: 0.23345 | Running loss: 0.28935\n",
            "Epoch: 13 | Iteration: 199 | Classification loss: 0.04042 | Regression loss: 0.14720 | Running loss: 0.28939\n",
            "Epoch: 13 | Iteration: 200 | Classification loss: 0.00829 | Regression loss: 0.10020 | Running loss: 0.28916\n",
            "Epoch: 13 | Iteration: 201 | Classification loss: 0.21124 | Regression loss: 0.35653 | Running loss: 0.28997\n",
            "Epoch: 13 | Iteration: 202 | Classification loss: 0.02252 | Regression loss: 0.07859 | Running loss: 0.28936\n",
            "Epoch: 13 | Iteration: 203 | Classification loss: 0.10531 | Regression loss: 0.21525 | Running loss: 0.28906\n",
            "Epoch: 13 | Iteration: 204 | Classification loss: 0.10756 | Regression loss: 0.26880 | Running loss: 0.28943\n",
            "Epoch: 13 | Iteration: 205 | Classification loss: 0.05343 | Regression loss: 0.20092 | Running loss: 0.28968\n",
            "Epoch: 13 | Iteration: 206 | Classification loss: 0.07330 | Regression loss: 0.17216 | Running loss: 0.28972\n",
            "Epoch: 13 | Iteration: 207 | Classification loss: 0.05344 | Regression loss: 0.17643 | Running loss: 0.28955\n",
            "Epoch: 13 | Iteration: 208 | Classification loss: 0.11447 | Regression loss: 0.20954 | Running loss: 0.28966\n",
            "Epoch: 13 | Iteration: 209 | Classification loss: 0.10038 | Regression loss: 0.24660 | Running loss: 0.28934\n",
            "Epoch: 13 | Iteration: 210 | Classification loss: 0.06703 | Regression loss: 0.17359 | Running loss: 0.28941\n",
            "Epoch: 13 | Iteration: 211 | Classification loss: 0.19516 | Regression loss: 0.11092 | Running loss: 0.28948\n",
            "Epoch: 13 | Iteration: 212 | Classification loss: 0.10640 | Regression loss: 0.21352 | Running loss: 0.28890\n",
            "Epoch: 13 | Iteration: 213 | Classification loss: 0.03845 | Regression loss: 0.12153 | Running loss: 0.28816\n",
            "Epoch: 13 | Iteration: 214 | Classification loss: 0.15515 | Regression loss: 0.21803 | Running loss: 0.28806\n",
            "Epoch: 13 | Iteration: 215 | Classification loss: 0.19940 | Regression loss: 0.39978 | Running loss: 0.28897\n",
            "Epoch: 13 | Iteration: 216 | Classification loss: 0.06047 | Regression loss: 0.11166 | Running loss: 0.28911\n",
            "Epoch: 13 | Iteration: 217 | Classification loss: 0.02962 | Regression loss: 0.07105 | Running loss: 0.28887\n",
            "Epoch: 13 | Iteration: 218 | Classification loss: 0.08349 | Regression loss: 0.22156 | Running loss: 0.28876\n",
            "Epoch: 13 | Iteration: 219 | Classification loss: 0.10772 | Regression loss: 0.12852 | Running loss: 0.28836\n",
            "Epoch: 13 | Iteration: 220 | Classification loss: 0.08526 | Regression loss: 0.19608 | Running loss: 0.28858\n",
            "Epoch: 13 | Iteration: 221 | Classification loss: 0.09692 | Regression loss: 0.23368 | Running loss: 0.28870\n",
            "Epoch: 13 | Iteration: 222 | Classification loss: 0.21095 | Regression loss: 0.44112 | Running loss: 0.28933\n",
            "Epoch: 13 | Iteration: 223 | Classification loss: 0.07540 | Regression loss: 0.16978 | Running loss: 0.28879\n",
            "Epoch: 13 | Iteration: 224 | Classification loss: 0.05007 | Regression loss: 0.15436 | Running loss: 0.28866\n",
            "Epoch: 13 | Iteration: 225 | Classification loss: 0.04020 | Regression loss: 0.14275 | Running loss: 0.28866\n",
            "Epoch: 13 | Iteration: 226 | Classification loss: 0.05273 | Regression loss: 0.18435 | Running loss: 0.28872\n",
            "Epoch: 13 | Iteration: 227 | Classification loss: 0.07383 | Regression loss: 0.20495 | Running loss: 0.28896\n",
            "Epoch: 13 | Iteration: 228 | Classification loss: 0.05140 | Regression loss: 0.14756 | Running loss: 0.28906\n",
            "Epoch: 13 | Iteration: 229 | Classification loss: 0.05242 | Regression loss: 0.14664 | Running loss: 0.28912\n",
            "Epoch: 13 | Iteration: 230 | Classification loss: 0.06708 | Regression loss: 0.14671 | Running loss: 0.28897\n",
            "Epoch: 13 | Iteration: 231 | Classification loss: 0.08596 | Regression loss: 0.17926 | Running loss: 0.28928\n",
            "Epoch: 13 | Iteration: 232 | Classification loss: 0.04259 | Regression loss: 0.14165 | Running loss: 0.28899\n",
            "Epoch: 13 | Iteration: 233 | Classification loss: 0.11190 | Regression loss: 0.12185 | Running loss: 0.28891\n",
            "Epoch: 13 | Iteration: 234 | Classification loss: 0.09221 | Regression loss: 0.15849 | Running loss: 0.28862\n",
            "Epoch: 13 | Iteration: 235 | Classification loss: 0.05525 | Regression loss: 0.24155 | Running loss: 0.28856\n",
            "Epoch: 13 | Iteration: 236 | Classification loss: 0.03331 | Regression loss: 0.14524 | Running loss: 0.28836\n",
            "Epoch: 13 | Iteration: 237 | Classification loss: 0.07982 | Regression loss: 0.22442 | Running loss: 0.28841\n",
            "Epoch: 13 | Iteration: 238 | Classification loss: 0.02742 | Regression loss: 0.15478 | Running loss: 0.28843\n",
            "Epoch: 13 | Iteration: 239 | Classification loss: 0.05811 | Regression loss: 0.15504 | Running loss: 0.28846\n",
            "Epoch: 13 | Iteration: 240 | Classification loss: 0.02821 | Regression loss: 0.07095 | Running loss: 0.28784\n",
            "Epoch: 13 | Iteration: 241 | Classification loss: 0.07901 | Regression loss: 0.22761 | Running loss: 0.28749\n",
            "Epoch: 13 | Iteration: 242 | Classification loss: 0.11299 | Regression loss: 0.19612 | Running loss: 0.28754\n",
            "Epoch: 13 | Iteration: 243 | Classification loss: 0.22060 | Regression loss: 0.33151 | Running loss: 0.28837\n",
            "Epoch: 13 | Iteration: 244 | Classification loss: 0.08696 | Regression loss: 0.17919 | Running loss: 0.28858\n",
            "Epoch: 13 | Iteration: 245 | Classification loss: 0.07584 | Regression loss: 0.24230 | Running loss: 0.28894\n",
            "Epoch: 13 | Iteration: 246 | Classification loss: 0.11788 | Regression loss: 0.29798 | Running loss: 0.28904\n",
            "Epoch: 13 | Iteration: 247 | Classification loss: 0.10831 | Regression loss: 0.24860 | Running loss: 0.28912\n",
            "Epoch: 13 | Iteration: 248 | Classification loss: 0.09251 | Regression loss: 0.21952 | Running loss: 0.28959\n",
            "Epoch: 13 | Iteration: 249 | Classification loss: 0.02979 | Regression loss: 0.06080 | Running loss: 0.28893\n",
            "Epoch: 13 | Iteration: 250 | Classification loss: 0.07076 | Regression loss: 0.22213 | Running loss: 0.28917\n",
            "Epoch: 13 | Iteration: 251 | Classification loss: 0.01816 | Regression loss: 0.12687 | Running loss: 0.28900\n",
            "Epoch: 13 | Iteration: 252 | Classification loss: 0.06656 | Regression loss: 0.16879 | Running loss: 0.28877\n",
            "Epoch: 13 | Iteration: 253 | Classification loss: 0.03855 | Regression loss: 0.15561 | Running loss: 0.28872\n",
            "Epoch: 13 | Iteration: 254 | Classification loss: 0.10364 | Regression loss: 0.17737 | Running loss: 0.28859\n",
            "Epoch: 13 | Iteration: 255 | Classification loss: 0.10665 | Regression loss: 0.20999 | Running loss: 0.28868\n",
            "Epoch: 13 | Iteration: 256 | Classification loss: 0.03984 | Regression loss: 0.15696 | Running loss: 0.28878\n",
            "Epoch: 13 | Iteration: 257 | Classification loss: 0.05933 | Regression loss: 0.12525 | Running loss: 0.28855\n",
            "Epoch: 13 | Iteration: 258 | Classification loss: 0.07041 | Regression loss: 0.13323 | Running loss: 0.28856\n",
            "Epoch: 13 | Iteration: 259 | Classification loss: 0.12470 | Regression loss: 0.26881 | Running loss: 0.28856\n",
            "Epoch: 13 | Iteration: 260 | Classification loss: 0.06316 | Regression loss: 0.18952 | Running loss: 0.28861\n",
            "Epoch: 13 | Iteration: 261 | Classification loss: 0.06659 | Regression loss: 0.16122 | Running loss: 0.28837\n",
            "Epoch: 13 | Iteration: 262 | Classification loss: 0.07109 | Regression loss: 0.08915 | Running loss: 0.28817\n",
            "Epoch: 13 | Iteration: 263 | Classification loss: 0.14332 | Regression loss: 0.29153 | Running loss: 0.28869\n",
            "Epoch: 13 | Iteration: 264 | Classification loss: 0.04518 | Regression loss: 0.09456 | Running loss: 0.28833\n",
            "Epoch: 13 | Iteration: 265 | Classification loss: 0.03608 | Regression loss: 0.21834 | Running loss: 0.28813\n",
            "Epoch: 13 | Iteration: 266 | Classification loss: 0.15005 | Regression loss: 0.28353 | Running loss: 0.28845\n",
            "Epoch: 13 | Iteration: 267 | Classification loss: 0.07576 | Regression loss: 0.20153 | Running loss: 0.28842\n",
            "Epoch: 13 | Iteration: 268 | Classification loss: 0.14061 | Regression loss: 0.26198 | Running loss: 0.28872\n",
            "Epoch: 13 | Iteration: 269 | Classification loss: 0.11632 | Regression loss: 0.27701 | Running loss: 0.28911\n",
            "Epoch: 13 | Iteration: 270 | Classification loss: 0.11845 | Regression loss: 0.32131 | Running loss: 0.28958\n",
            "Epoch: 13 | Iteration: 271 | Classification loss: 0.06987 | Regression loss: 0.15269 | Running loss: 0.28933\n",
            "Epoch: 13 | Iteration: 272 | Classification loss: 0.03019 | Regression loss: 0.13098 | Running loss: 0.28909\n",
            "Epoch: 13 | Iteration: 273 | Classification loss: 0.08730 | Regression loss: 0.19532 | Running loss: 0.28901\n",
            "Epoch: 13 | Iteration: 274 | Classification loss: 0.10584 | Regression loss: 0.11862 | Running loss: 0.28895\n",
            "Epoch: 13 | Iteration: 275 | Classification loss: 0.02446 | Regression loss: 0.11460 | Running loss: 0.28866\n",
            "Epoch: 13 | Iteration: 276 | Classification loss: 0.06848 | Regression loss: 0.11603 | Running loss: 0.28872\n",
            "Epoch: 13 | Iteration: 277 | Classification loss: 0.07057 | Regression loss: 0.24725 | Running loss: 0.28877\n",
            "Epoch: 13 | Iteration: 278 | Classification loss: 0.05787 | Regression loss: 0.15736 | Running loss: 0.28868\n",
            "Epoch: 13 | Iteration: 279 | Classification loss: 0.10221 | Regression loss: 0.25745 | Running loss: 0.28895\n",
            "Epoch: 13 | Iteration: 280 | Classification loss: 0.04726 | Regression loss: 0.18508 | Running loss: 0.28882\n",
            "Epoch: 13 | Iteration: 281 | Classification loss: 0.12049 | Regression loss: 0.20436 | Running loss: 0.28879\n",
            "Epoch: 13 | Iteration: 282 | Classification loss: 0.07466 | Regression loss: 0.22738 | Running loss: 0.28872\n",
            "Epoch: 13 | Iteration: 283 | Classification loss: 0.04176 | Regression loss: 0.18073 | Running loss: 0.28830\n",
            "Epoch: 13 | Iteration: 284 | Classification loss: 0.06181 | Regression loss: 0.16703 | Running loss: 0.28812\n",
            "Epoch: 13 | Iteration: 285 | Classification loss: 0.09402 | Regression loss: 0.24109 | Running loss: 0.28739\n",
            "Epoch: 13 | Iteration: 286 | Classification loss: 0.03741 | Regression loss: 0.15908 | Running loss: 0.28742\n",
            "Epoch: 13 | Iteration: 287 | Classification loss: 0.02400 | Regression loss: 0.05891 | Running loss: 0.28689\n",
            "Epoch: 13 | Iteration: 288 | Classification loss: 0.09895 | Regression loss: 0.23960 | Running loss: 0.28708\n",
            "Epoch: 13 | Iteration: 289 | Classification loss: 0.08525 | Regression loss: 0.17033 | Running loss: 0.28689\n",
            "Epoch: 13 | Iteration: 290 | Classification loss: 0.06302 | Regression loss: 0.14562 | Running loss: 0.28689\n",
            "Epoch: 13 | Iteration: 291 | Classification loss: 0.06263 | Regression loss: 0.14399 | Running loss: 0.28689\n",
            "Epoch: 13 | Iteration: 292 | Classification loss: 0.07310 | Regression loss: 0.14422 | Running loss: 0.28678\n",
            "Epoch: 13 | Iteration: 293 | Classification loss: 0.13002 | Regression loss: 0.25666 | Running loss: 0.28694\n",
            "Epoch: 13 | Iteration: 294 | Classification loss: 0.09275 | Regression loss: 0.24500 | Running loss: 0.28717\n",
            "Epoch: 13 | Iteration: 295 | Classification loss: 0.12608 | Regression loss: 0.33739 | Running loss: 0.28739\n",
            "Epoch: 13 | Iteration: 296 | Classification loss: 0.08236 | Regression loss: 0.24025 | Running loss: 0.28768\n",
            "Epoch: 13 | Iteration: 297 | Classification loss: 0.02903 | Regression loss: 0.18975 | Running loss: 0.28717\n",
            "Epoch: 13 | Iteration: 298 | Classification loss: 0.03301 | Regression loss: 0.10817 | Running loss: 0.28645\n",
            "Epoch: 13 | Iteration: 299 | Classification loss: 0.01966 | Regression loss: 0.10534 | Running loss: 0.28586\n",
            "Epoch: 13 | Iteration: 300 | Classification loss: 0.08561 | Regression loss: 0.23650 | Running loss: 0.28617\n",
            "Epoch: 13 | Iteration: 301 | Classification loss: 0.11008 | Regression loss: 0.17971 | Running loss: 0.28632\n",
            "Epoch: 13 | Iteration: 302 | Classification loss: 0.15082 | Regression loss: 0.32971 | Running loss: 0.28658\n",
            "Epoch: 13 | Iteration: 303 | Classification loss: 0.11015 | Regression loss: 0.22728 | Running loss: 0.28672\n",
            "Epoch: 13 | Iteration: 304 | Classification loss: 0.02763 | Regression loss: 0.11886 | Running loss: 0.28618\n",
            "Epoch: 13 | Iteration: 305 | Classification loss: 0.08747 | Regression loss: 0.16197 | Running loss: 0.28648\n",
            "Epoch: 13 | Iteration: 306 | Classification loss: 0.02923 | Regression loss: 0.10589 | Running loss: 0.28570\n",
            "Epoch: 13 | Iteration: 307 | Classification loss: 0.11227 | Regression loss: 0.27571 | Running loss: 0.28608\n",
            "Epoch: 13 | Iteration: 308 | Classification loss: 0.01831 | Regression loss: 0.07720 | Running loss: 0.28521\n",
            "Epoch: 13 | Iteration: 309 | Classification loss: 0.06557 | Regression loss: 0.18216 | Running loss: 0.28522\n",
            "Epoch: 13 | Iteration: 310 | Classification loss: 0.10538 | Regression loss: 0.19472 | Running loss: 0.28537\n",
            "Epoch: 13 | Iteration: 311 | Classification loss: 0.03178 | Regression loss: 0.10810 | Running loss: 0.28522\n",
            "Epoch: 13 | Iteration: 312 | Classification loss: 0.03992 | Regression loss: 0.18375 | Running loss: 0.28495\n",
            "Epoch: 13 | Iteration: 313 | Classification loss: 0.10542 | Regression loss: 0.18086 | Running loss: 0.28484\n",
            "Epoch: 13 | Iteration: 314 | Classification loss: 0.09443 | Regression loss: 0.26153 | Running loss: 0.28467\n",
            "Epoch: 13 | Iteration: 315 | Classification loss: 0.12974 | Regression loss: 0.27842 | Running loss: 0.28483\n",
            "Epoch: 13 | Iteration: 316 | Classification loss: 0.11669 | Regression loss: 0.26281 | Running loss: 0.28499\n",
            "Epoch: 13 | Iteration: 317 | Classification loss: 0.11086 | Regression loss: 0.29823 | Running loss: 0.28500\n",
            "Epoch: 13 | Iteration: 318 | Classification loss: 0.07764 | Regression loss: 0.18471 | Running loss: 0.28510\n",
            "Epoch: 13 | Iteration: 319 | Classification loss: 0.11107 | Regression loss: 0.34294 | Running loss: 0.28548\n",
            "Epoch: 13 | Iteration: 320 | Classification loss: 0.21323 | Regression loss: 0.39240 | Running loss: 0.28571\n",
            "Epoch: 13 | Iteration: 321 | Classification loss: 0.02838 | Regression loss: 0.12891 | Running loss: 0.28560\n",
            "Epoch: 13 | Iteration: 322 | Classification loss: 0.10277 | Regression loss: 0.21367 | Running loss: 0.28602\n",
            "Epoch: 13 | Iteration: 323 | Classification loss: 0.15537 | Regression loss: 0.25559 | Running loss: 0.28626\n",
            "Epoch: 13 | Iteration: 324 | Classification loss: 0.04396 | Regression loss: 0.14787 | Running loss: 0.28613\n",
            "Epoch: 13 | Iteration: 325 | Classification loss: 0.09786 | Regression loss: 0.14797 | Running loss: 0.28582\n",
            "Epoch: 13 | Iteration: 326 | Classification loss: 0.04195 | Regression loss: 0.06064 | Running loss: 0.28568\n",
            "Epoch: 13 | Iteration: 327 | Classification loss: 0.08478 | Regression loss: 0.16039 | Running loss: 0.28564\n",
            "Epoch: 13 | Iteration: 328 | Classification loss: 0.05966 | Regression loss: 0.13050 | Running loss: 0.28502\n",
            "Epoch: 13 | Iteration: 329 | Classification loss: 0.17991 | Regression loss: 0.28907 | Running loss: 0.28510\n",
            "Epoch: 13 | Iteration: 330 | Classification loss: 0.12563 | Regression loss: 0.27707 | Running loss: 0.28488\n",
            "Epoch: 13 | Iteration: 331 | Classification loss: 0.03689 | Regression loss: 0.20024 | Running loss: 0.28476\n",
            "Epoch: 13 | Iteration: 332 | Classification loss: 0.04894 | Regression loss: 0.11517 | Running loss: 0.28354\n",
            "Epoch: 13 | Iteration: 333 | Classification loss: 0.05322 | Regression loss: 0.14623 | Running loss: 0.28329\n",
            "Epoch: 13 | Iteration: 334 | Classification loss: 0.13293 | Regression loss: 0.20518 | Running loss: 0.28343\n",
            "Epoch: 13 | Iteration: 335 | Classification loss: 0.14673 | Regression loss: 0.25622 | Running loss: 0.28366\n",
            "Epoch: 13 | Iteration: 336 | Classification loss: 0.03472 | Regression loss: 0.18820 | Running loss: 0.28368\n",
            "Epoch: 13 | Iteration: 337 | Classification loss: 0.11131 | Regression loss: 0.22393 | Running loss: 0.28319\n",
            "Epoch: 13 | Iteration: 338 | Classification loss: 0.10507 | Regression loss: 0.18041 | Running loss: 0.28314\n",
            "Epoch: 13 | Iteration: 339 | Classification loss: 0.11140 | Regression loss: 0.20206 | Running loss: 0.28307\n",
            "Epoch: 13 | Iteration: 340 | Classification loss: 0.05160 | Regression loss: 0.18743 | Running loss: 0.28312\n",
            "Epoch: 13 | Iteration: 341 | Classification loss: 0.06190 | Regression loss: 0.13426 | Running loss: 0.28276\n",
            "Epoch: 13 | Iteration: 342 | Classification loss: 0.04108 | Regression loss: 0.10779 | Running loss: 0.28229\n",
            "Epoch: 13 | Iteration: 343 | Classification loss: 0.03634 | Regression loss: 0.14617 | Running loss: 0.28206\n",
            "Epoch: 13 | Iteration: 344 | Classification loss: 0.02693 | Regression loss: 0.10183 | Running loss: 0.28185\n",
            "Epoch: 13 | Iteration: 345 | Classification loss: 0.02142 | Regression loss: 0.12491 | Running loss: 0.28132\n",
            "Epoch: 13 | Iteration: 346 | Classification loss: 0.05578 | Regression loss: 0.14818 | Running loss: 0.28111\n",
            "Epoch: 13 | Iteration: 347 | Classification loss: 0.07490 | Regression loss: 0.20926 | Running loss: 0.28075\n",
            "Epoch: 13 | Iteration: 348 | Classification loss: 0.07548 | Regression loss: 0.15647 | Running loss: 0.28081\n",
            "Epoch: 13 | Iteration: 349 | Classification loss: 0.03447 | Regression loss: 0.11981 | Running loss: 0.28081\n",
            "Epoch: 13 | Iteration: 350 | Classification loss: 0.09626 | Regression loss: 0.21486 | Running loss: 0.28110\n",
            "Epoch: 13 | Iteration: 351 | Classification loss: 0.09144 | Regression loss: 0.19019 | Running loss: 0.28057\n",
            "Epoch: 13 | Iteration: 352 | Classification loss: 0.04781 | Regression loss: 0.14625 | Running loss: 0.28027\n",
            "Epoch: 13 | Iteration: 353 | Classification loss: 0.04647 | Regression loss: 0.10664 | Running loss: 0.27953\n",
            "Epoch: 13 | Iteration: 354 | Classification loss: 0.04273 | Regression loss: 0.16498 | Running loss: 0.27959\n",
            "Epoch: 13 | Iteration: 355 | Classification loss: 0.03223 | Regression loss: 0.15855 | Running loss: 0.27948\n",
            "Epoch: 13 | Iteration: 356 | Classification loss: 0.10610 | Regression loss: 0.19552 | Running loss: 0.27960\n",
            "Epoch: 13 | Iteration: 357 | Classification loss: 0.03111 | Regression loss: 0.12363 | Running loss: 0.27953\n",
            "Epoch: 13 | Iteration: 358 | Classification loss: 0.04422 | Regression loss: 0.14738 | Running loss: 0.27930\n",
            "Epoch: 13 | Iteration: 359 | Classification loss: 0.08311 | Regression loss: 0.17797 | Running loss: 0.27943\n",
            "Epoch: 13 | Iteration: 360 | Classification loss: 0.06281 | Regression loss: 0.14235 | Running loss: 0.27937\n",
            "Epoch: 13 | Iteration: 361 | Classification loss: 0.01788 | Regression loss: 0.06668 | Running loss: 0.27900\n",
            "Epoch: 13 | Iteration: 362 | Classification loss: 0.13039 | Regression loss: 0.26566 | Running loss: 0.27900\n",
            "Epoch: 13 | Iteration: 363 | Classification loss: 0.05523 | Regression loss: 0.14293 | Running loss: 0.27910\n",
            "Epoch: 13 | Iteration: 364 | Classification loss: 0.11317 | Regression loss: 0.31988 | Running loss: 0.27858\n",
            "Epoch: 13 | Iteration: 365 | Classification loss: 0.04428 | Regression loss: 0.15592 | Running loss: 0.27839\n",
            "Epoch: 13 | Iteration: 366 | Classification loss: 0.05141 | Regression loss: 0.21153 | Running loss: 0.27822\n",
            "Epoch: 13 | Iteration: 367 | Classification loss: 0.13466 | Regression loss: 0.31500 | Running loss: 0.27880\n",
            "Epoch: 13 | Iteration: 368 | Classification loss: 0.11367 | Regression loss: 0.24496 | Running loss: 0.27899\n",
            "Epoch: 13 | Iteration: 369 | Classification loss: 0.03327 | Regression loss: 0.14859 | Running loss: 0.27879\n",
            "Epoch: 13 | Iteration: 370 | Classification loss: 0.12625 | Regression loss: 0.16021 | Running loss: 0.27900\n",
            "Epoch: 13 | Iteration: 371 | Classification loss: 0.10314 | Regression loss: 0.24712 | Running loss: 0.27907\n",
            "Epoch: 13 | Iteration: 372 | Classification loss: 0.05733 | Regression loss: 0.25901 | Running loss: 0.27929\n",
            "Epoch: 13 | Iteration: 373 | Classification loss: 0.12579 | Regression loss: 0.17440 | Running loss: 0.27919\n",
            "Epoch: 13 | Iteration: 374 | Classification loss: 0.08929 | Regression loss: 0.26730 | Running loss: 0.27943\n",
            "Epoch: 13 | Iteration: 375 | Classification loss: 0.02728 | Regression loss: 0.11615 | Running loss: 0.27871\n",
            "Epoch: 13 | Iteration: 376 | Classification loss: 0.08753 | Regression loss: 0.20446 | Running loss: 0.27881\n",
            "Epoch: 13 | Iteration: 377 | Classification loss: 0.03271 | Regression loss: 0.13012 | Running loss: 0.27835\n",
            "Epoch: 13 | Iteration: 378 | Classification loss: 0.05104 | Regression loss: 0.11908 | Running loss: 0.27839\n",
            "Epoch: 13 | Iteration: 379 | Classification loss: 0.03739 | Regression loss: 0.15494 | Running loss: 0.27827\n",
            "Epoch: 13 | Iteration: 380 | Classification loss: 0.09444 | Regression loss: 0.22397 | Running loss: 0.27815\n",
            "Epoch: 13 | Iteration: 381 | Classification loss: 0.15312 | Regression loss: 0.17188 | Running loss: 0.27806\n",
            "Epoch: 13 | Iteration: 382 | Classification loss: 0.03842 | Regression loss: 0.18109 | Running loss: 0.27817\n",
            "Epoch: 13 | Iteration: 383 | Classification loss: 0.06469 | Regression loss: 0.18397 | Running loss: 0.27818\n",
            "Epoch: 13 | Iteration: 384 | Classification loss: 0.04775 | Regression loss: 0.18156 | Running loss: 0.27775\n",
            "Epoch: 13 | Iteration: 385 | Classification loss: 0.11902 | Regression loss: 0.21370 | Running loss: 0.27799\n",
            "Epoch: 13 | Iteration: 386 | Classification loss: 0.13644 | Regression loss: 0.37443 | Running loss: 0.27878\n",
            "Epoch: 13 | Iteration: 387 | Classification loss: 0.10605 | Regression loss: 0.20272 | Running loss: 0.27865\n",
            "Epoch: 13 | Iteration: 388 | Classification loss: 0.07561 | Regression loss: 0.21872 | Running loss: 0.27859\n",
            "Epoch: 13 | Iteration: 389 | Classification loss: 0.10221 | Regression loss: 0.19515 | Running loss: 0.27868\n",
            "Epoch: 13 | Iteration: 390 | Classification loss: 0.08003 | Regression loss: 0.11393 | Running loss: 0.27841\n",
            "Epoch: 13 | Iteration: 391 | Classification loss: 0.05011 | Regression loss: 0.16071 | Running loss: 0.27812\n",
            "Epoch: 13 | Iteration: 392 | Classification loss: 0.06660 | Regression loss: 0.20865 | Running loss: 0.27830\n",
            "Epoch: 13 | Iteration: 393 | Classification loss: 0.15211 | Regression loss: 0.15144 | Running loss: 0.27845\n",
            "Epoch: 13 | Iteration: 394 | Classification loss: 0.08368 | Regression loss: 0.13068 | Running loss: 0.27842\n",
            "Epoch: 13 | Iteration: 395 | Classification loss: 0.08405 | Regression loss: 0.14170 | Running loss: 0.27828\n",
            "Epoch: 13 | Iteration: 396 | Classification loss: 0.08062 | Regression loss: 0.27569 | Running loss: 0.27800\n",
            "Epoch: 13 | Iteration: 397 | Classification loss: 0.07349 | Regression loss: 0.17343 | Running loss: 0.27803\n",
            "Epoch: 13 | Iteration: 398 | Classification loss: 0.21538 | Regression loss: 0.33952 | Running loss: 0.27869\n",
            "Epoch: 13 | Iteration: 399 | Classification loss: 0.09895 | Regression loss: 0.23384 | Running loss: 0.27876\n",
            "Epoch: 13 | Iteration: 400 | Classification loss: 0.06238 | Regression loss: 0.24051 | Running loss: 0.27888\n",
            "Epoch: 13 | Iteration: 401 | Classification loss: 0.03800 | Regression loss: 0.12564 | Running loss: 0.27859\n",
            "Epoch: 13 | Iteration: 402 | Classification loss: 0.13792 | Regression loss: 0.26886 | Running loss: 0.27897\n",
            "Epoch: 13 | Iteration: 403 | Classification loss: 0.04955 | Regression loss: 0.12637 | Running loss: 0.27854\n",
            "Epoch: 13 | Iteration: 404 | Classification loss: 0.14834 | Regression loss: 0.30705 | Running loss: 0.27844\n",
            "Epoch: 13 | Iteration: 405 | Classification loss: 0.05365 | Regression loss: 0.18667 | Running loss: 0.27808\n",
            "Epoch: 13 | Iteration: 406 | Classification loss: 0.16049 | Regression loss: 0.29153 | Running loss: 0.27821\n",
            "Epoch: 13 | Iteration: 407 | Classification loss: 0.05428 | Regression loss: 0.10541 | Running loss: 0.27800\n",
            "Epoch: 13 | Iteration: 408 | Classification loss: 0.10046 | Regression loss: 0.29792 | Running loss: 0.27818\n",
            "Epoch: 13 | Iteration: 409 | Classification loss: 0.09552 | Regression loss: 0.24111 | Running loss: 0.27830\n",
            "Epoch: 13 | Iteration: 410 | Classification loss: 0.11887 | Regression loss: 0.31619 | Running loss: 0.27850\n",
            "Epoch: 13 | Iteration: 411 | Classification loss: 0.01873 | Regression loss: 0.10972 | Running loss: 0.27762\n",
            "Epoch: 13 | Iteration: 412 | Classification loss: 0.04114 | Regression loss: 0.13702 | Running loss: 0.27729\n",
            "Epoch: 13 | Iteration: 413 | Classification loss: 0.04102 | Regression loss: 0.07653 | Running loss: 0.27699\n",
            "Epoch: 13 | Iteration: 414 | Classification loss: 0.08187 | Regression loss: 0.16793 | Running loss: 0.27701\n",
            "Epoch: 13 | Iteration: 415 | Classification loss: 0.03823 | Regression loss: 0.14046 | Running loss: 0.27677\n",
            "Epoch: 13 | Iteration: 416 | Classification loss: 0.03577 | Regression loss: 0.13821 | Running loss: 0.27654\n",
            "Epoch: 13 | Iteration: 417 | Classification loss: 0.22315 | Regression loss: 0.31400 | Running loss: 0.27684\n",
            "Epoch: 13 | Iteration: 418 | Classification loss: 0.05089 | Regression loss: 0.09770 | Running loss: 0.27654\n",
            "Epoch: 13 | Iteration: 419 | Classification loss: 0.16605 | Regression loss: 0.32801 | Running loss: 0.27702\n",
            "Epoch: 13 | Iteration: 420 | Classification loss: 0.10713 | Regression loss: 0.23229 | Running loss: 0.27724\n",
            "Epoch: 13 | Iteration: 421 | Classification loss: 0.04547 | Regression loss: 0.16066 | Running loss: 0.27723\n",
            "Epoch: 13 | Iteration: 422 | Classification loss: 0.04190 | Regression loss: 0.14043 | Running loss: 0.27719\n",
            "Epoch: 13 | Iteration: 423 | Classification loss: 0.09402 | Regression loss: 0.26547 | Running loss: 0.27676\n",
            "Epoch: 13 | Iteration: 424 | Classification loss: 0.07195 | Regression loss: 0.21668 | Running loss: 0.27654\n",
            "Epoch: 13 | Iteration: 425 | Classification loss: 0.07893 | Regression loss: 0.21197 | Running loss: 0.27630\n",
            "Epoch: 13 | Iteration: 426 | Classification loss: 0.00851 | Regression loss: 0.09316 | Running loss: 0.27614\n",
            "Epoch: 13 | Iteration: 427 | Classification loss: 0.07274 | Regression loss: 0.26468 | Running loss: 0.27648\n",
            "Epoch: 13 | Iteration: 428 | Classification loss: 0.07997 | Regression loss: 0.22979 | Running loss: 0.27625\n",
            "Epoch: 13 | Iteration: 429 | Classification loss: 0.08774 | Regression loss: 0.23949 | Running loss: 0.27619\n",
            "Epoch: 13 | Iteration: 430 | Classification loss: 0.06532 | Regression loss: 0.14869 | Running loss: 0.27590\n",
            "Epoch: 13 | Iteration: 431 | Classification loss: 0.09431 | Regression loss: 0.22346 | Running loss: 0.27649\n",
            "Epoch: 13 | Iteration: 432 | Classification loss: 0.11192 | Regression loss: 0.22361 | Running loss: 0.27637\n",
            "Epoch: 13 | Iteration: 433 | Classification loss: 0.04066 | Regression loss: 0.12578 | Running loss: 0.27604\n",
            "Epoch: 13 | Iteration: 434 | Classification loss: 0.10080 | Regression loss: 0.28483 | Running loss: 0.27635\n",
            "Epoch: 13 | Iteration: 435 | Classification loss: 0.18368 | Regression loss: 0.25407 | Running loss: 0.27662\n",
            "Epoch: 13 | Iteration: 436 | Classification loss: 0.07850 | Regression loss: 0.12913 | Running loss: 0.27630\n",
            "Epoch: 13 | Iteration: 437 | Classification loss: 0.08540 | Regression loss: 0.27032 | Running loss: 0.27663\n",
            "Epoch: 13 | Iteration: 438 | Classification loss: 0.15174 | Regression loss: 0.29480 | Running loss: 0.27646\n",
            "Epoch: 13 | Iteration: 439 | Classification loss: 0.06550 | Regression loss: 0.10764 | Running loss: 0.27634\n",
            "Epoch: 13 | Iteration: 440 | Classification loss: 0.12821 | Regression loss: 0.26894 | Running loss: 0.27679\n",
            "Epoch: 13 | Iteration: 441 | Classification loss: 0.05348 | Regression loss: 0.12223 | Running loss: 0.27605\n",
            "Epoch: 13 | Iteration: 442 | Classification loss: 0.01027 | Regression loss: 0.05079 | Running loss: 0.27524\n",
            "Epoch: 13 | Iteration: 443 | Classification loss: 0.14218 | Regression loss: 0.24638 | Running loss: 0.27517\n",
            "Epoch: 13 | Iteration: 444 | Classification loss: 0.03386 | Regression loss: 0.10149 | Running loss: 0.27490\n",
            "Epoch: 13 | Iteration: 445 | Classification loss: 0.02451 | Regression loss: 0.12777 | Running loss: 0.27480\n",
            "Epoch: 13 | Iteration: 446 | Classification loss: 0.13582 | Regression loss: 0.30982 | Running loss: 0.27448\n",
            "Epoch: 13 | Iteration: 447 | Classification loss: 0.10180 | Regression loss: 0.22974 | Running loss: 0.27464\n",
            "Epoch: 13 | Iteration: 448 | Classification loss: 0.09962 | Regression loss: 0.10739 | Running loss: 0.27478\n",
            "Epoch: 13 | Iteration: 449 | Classification loss: 0.20832 | Regression loss: 0.34917 | Running loss: 0.27516\n",
            "Epoch: 13 | Iteration: 450 | Classification loss: 0.41302 | Regression loss: 0.08452 | Running loss: 0.27543\n",
            "Epoch: 13 | Iteration: 451 | Classification loss: 0.14927 | Regression loss: 0.22477 | Running loss: 0.27571\n",
            "Epoch: 13 | Iteration: 452 | Classification loss: 0.14834 | Regression loss: 0.21194 | Running loss: 0.27565\n",
            "Epoch: 13 | Iteration: 453 | Classification loss: 0.07142 | Regression loss: 0.25745 | Running loss: 0.27578\n",
            "Epoch: 13 | Iteration: 454 | Classification loss: 0.11288 | Regression loss: 0.20309 | Running loss: 0.27584\n",
            "Epoch: 13 | Iteration: 455 | Classification loss: 0.07338 | Regression loss: 0.21264 | Running loss: 0.27601\n",
            "Epoch: 13 | Iteration: 456 | Classification loss: 0.11191 | Regression loss: 0.15409 | Running loss: 0.27592\n",
            "Epoch: 13 | Iteration: 457 | Classification loss: 0.09613 | Regression loss: 0.15058 | Running loss: 0.27606\n",
            "Epoch: 13 | Iteration: 458 | Classification loss: 0.04135 | Regression loss: 0.15117 | Running loss: 0.27601\n",
            "Epoch: 13 | Iteration: 459 | Classification loss: 0.07206 | Regression loss: 0.16592 | Running loss: 0.27601\n",
            "Epoch: 13 | Iteration: 460 | Classification loss: 0.05873 | Regression loss: 0.17625 | Running loss: 0.27587\n",
            "Epoch: 13 | Iteration: 461 | Classification loss: 0.06627 | Regression loss: 0.16863 | Running loss: 0.27557\n",
            "Epoch: 13 | Iteration: 462 | Classification loss: 0.15640 | Regression loss: 0.24344 | Running loss: 0.27595\n",
            "Epoch: 13 | Iteration: 463 | Classification loss: 0.05552 | Regression loss: 0.17795 | Running loss: 0.27526\n",
            "Epoch: 13 | Iteration: 464 | Classification loss: 0.08981 | Regression loss: 0.18517 | Running loss: 0.27521\n",
            "Epoch: 13 | Iteration: 465 | Classification loss: 0.13440 | Regression loss: 0.36851 | Running loss: 0.27538\n",
            "Epoch: 13 | Iteration: 466 | Classification loss: 0.06337 | Regression loss: 0.15926 | Running loss: 0.27516\n",
            "Epoch: 13 | Iteration: 467 | Classification loss: 0.08676 | Regression loss: 0.13145 | Running loss: 0.27467\n",
            "Epoch: 13 | Iteration: 468 | Classification loss: 0.10024 | Regression loss: 0.14530 | Running loss: 0.27416\n",
            "Epoch: 13 | Iteration: 469 | Classification loss: 0.03896 | Regression loss: 0.10193 | Running loss: 0.27390\n",
            "Epoch: 13 | Iteration: 470 | Classification loss: 0.05225 | Regression loss: 0.16165 | Running loss: 0.27343\n",
            "Epoch: 13 | Iteration: 471 | Classification loss: 0.10184 | Regression loss: 0.28248 | Running loss: 0.27339\n",
            "Epoch: 13 | Iteration: 472 | Classification loss: 0.12180 | Regression loss: 0.10389 | Running loss: 0.27320\n",
            "Epoch: 13 | Iteration: 473 | Classification loss: 0.01253 | Regression loss: 0.08913 | Running loss: 0.27319\n",
            "Epoch: 13 | Iteration: 474 | Classification loss: 0.00305 | Regression loss: 0.10952 | Running loss: 0.27305\n",
            "Epoch: 13 | Iteration: 475 | Classification loss: 0.17633 | Regression loss: 0.40854 | Running loss: 0.27358\n",
            "Epoch: 13 | Iteration: 476 | Classification loss: 0.12393 | Regression loss: 0.22296 | Running loss: 0.27391\n",
            "Epoch: 13 | Iteration: 477 | Classification loss: 0.10504 | Regression loss: 0.19016 | Running loss: 0.27409\n",
            "Epoch: 13 | Iteration: 478 | Classification loss: 0.03662 | Regression loss: 0.11466 | Running loss: 0.27382\n",
            "Epoch: 13 | Iteration: 479 | Classification loss: 0.08737 | Regression loss: 0.15939 | Running loss: 0.27337\n",
            "Epoch: 13 | Iteration: 480 | Classification loss: 0.06294 | Regression loss: 0.12631 | Running loss: 0.27300\n",
            "Epoch: 13 | Iteration: 481 | Classification loss: 0.03056 | Regression loss: 0.15029 | Running loss: 0.27250\n",
            "Epoch: 13 | Iteration: 482 | Classification loss: 0.08962 | Regression loss: 0.17831 | Running loss: 0.27278\n",
            "Epoch: 13 | Iteration: 483 | Classification loss: 0.04363 | Regression loss: 0.18099 | Running loss: 0.27252\n",
            "Epoch: 13 | Iteration: 484 | Classification loss: 0.01820 | Regression loss: 0.12907 | Running loss: 0.27225\n",
            "Epoch: 13 | Iteration: 485 | Classification loss: 0.02624 | Regression loss: 0.11780 | Running loss: 0.27221\n",
            "Epoch: 13 | Iteration: 486 | Classification loss: 0.06375 | Regression loss: 0.16162 | Running loss: 0.27175\n",
            "Epoch: 13 | Iteration: 487 | Classification loss: 0.09513 | Regression loss: 0.15559 | Running loss: 0.27139\n",
            "Epoch: 13 | Iteration: 488 | Classification loss: 0.06078 | Regression loss: 0.20864 | Running loss: 0.27128\n",
            "Epoch: 13 | Iteration: 489 | Classification loss: 0.05885 | Regression loss: 0.09820 | Running loss: 0.27086\n",
            "Epoch: 13 | Iteration: 490 | Classification loss: 0.02313 | Regression loss: 0.13778 | Running loss: 0.27060\n",
            "Epoch: 13 | Iteration: 491 | Classification loss: 0.07410 | Regression loss: 0.20335 | Running loss: 0.27074\n",
            "Epoch: 13 | Iteration: 492 | Classification loss: 0.04262 | Regression loss: 0.14779 | Running loss: 0.27055\n",
            "Epoch: 13 | Iteration: 493 | Classification loss: 0.07815 | Regression loss: 0.27917 | Running loss: 0.27086\n",
            "Epoch: 13 | Iteration: 494 | Classification loss: 0.02500 | Regression loss: 0.09406 | Running loss: 0.27056\n",
            "Epoch: 13 | Iteration: 495 | Classification loss: 0.10760 | Regression loss: 0.25053 | Running loss: 0.27067\n",
            "Epoch: 13 | Iteration: 496 | Classification loss: 0.17148 | Regression loss: 0.33047 | Running loss: 0.27129\n",
            "Epoch: 13 | Iteration: 497 | Classification loss: 0.02517 | Regression loss: 0.10510 | Running loss: 0.27053\n",
            "Epoch: 13 | Iteration: 498 | Classification loss: 0.18891 | Regression loss: 0.17785 | Running loss: 0.27073\n",
            "Epoch: 13 | Iteration: 499 | Classification loss: 0.06576 | Regression loss: 0.19471 | Running loss: 0.27057\n",
            "Epoch: 13 | Iteration: 500 | Classification loss: 0.13628 | Regression loss: 0.23451 | Running loss: 0.27049\n",
            "Epoch: 13 | Iteration: 501 | Classification loss: 0.10098 | Regression loss: 0.17459 | Running loss: 0.27072\n",
            "Epoch: 13 | Iteration: 502 | Classification loss: 0.07295 | Regression loss: 0.20333 | Running loss: 0.27109\n",
            "Epoch: 13 | Iteration: 503 | Classification loss: 0.06902 | Regression loss: 0.20241 | Running loss: 0.27115\n",
            "Epoch: 13 | Iteration: 504 | Classification loss: 0.03311 | Regression loss: 0.11417 | Running loss: 0.27108\n",
            "Epoch: 13 | Iteration: 505 | Classification loss: 0.06439 | Regression loss: 0.16384 | Running loss: 0.27085\n",
            "Epoch: 13 | Iteration: 506 | Classification loss: 0.12203 | Regression loss: 0.27361 | Running loss: 0.27097\n",
            "Epoch: 13 | Iteration: 507 | Classification loss: 0.05233 | Regression loss: 0.10027 | Running loss: 0.27081\n",
            "Epoch: 13 | Iteration: 508 | Classification loss: 0.06284 | Regression loss: 0.09063 | Running loss: 0.27044\n",
            "Epoch: 13 | Iteration: 509 | Classification loss: 0.18332 | Regression loss: 0.22709 | Running loss: 0.27061\n",
            "Epoch: 13 | Iteration: 510 | Classification loss: 0.04980 | Regression loss: 0.15869 | Running loss: 0.27067\n",
            "Epoch: 13 | Iteration: 511 | Classification loss: 0.09240 | Regression loss: 0.18055 | Running loss: 0.27015\n",
            "Epoch: 13 | Iteration: 512 | Classification loss: 0.11382 | Regression loss: 0.26399 | Running loss: 0.27047\n",
            "Epoch: 13 | Iteration: 513 | Classification loss: 0.07254 | Regression loss: 0.21918 | Running loss: 0.27043\n",
            "Epoch: 13 | Iteration: 514 | Classification loss: 0.11619 | Regression loss: 0.22101 | Running loss: 0.27054\n",
            "Epoch: 13 | Iteration: 515 | Classification loss: 0.07112 | Regression loss: 0.18779 | Running loss: 0.27017\n",
            "Epoch: 13 | Iteration: 516 | Classification loss: 0.15573 | Regression loss: 0.22734 | Running loss: 0.27057\n",
            "Epoch: 13 | Iteration: 517 | Classification loss: 0.05930 | Regression loss: 0.17814 | Running loss: 0.27072\n",
            "Epoch: 13 | Iteration: 518 | Classification loss: 0.10276 | Regression loss: 0.16997 | Running loss: 0.27064\n",
            "Epoch: 13 | Iteration: 519 | Classification loss: 0.03130 | Regression loss: 0.13460 | Running loss: 0.27017\n",
            "Epoch: 13 | Iteration: 520 | Classification loss: 0.06250 | Regression loss: 0.19190 | Running loss: 0.27041\n",
            "Epoch: 13 | Iteration: 521 | Classification loss: 0.06142 | Regression loss: 0.13728 | Running loss: 0.27047\n",
            "Epoch: 13 | Iteration: 522 | Classification loss: 0.04482 | Regression loss: 0.09638 | Running loss: 0.26979\n",
            "Epoch: 13 | Iteration: 523 | Classification loss: 0.05241 | Regression loss: 0.19249 | Running loss: 0.26978\n",
            "Epoch: 13 | Iteration: 524 | Classification loss: 0.02719 | Regression loss: 0.11736 | Running loss: 0.26962\n",
            "Epoch: 13 | Iteration: 525 | Classification loss: 0.08698 | Regression loss: 0.18058 | Running loss: 0.26978\n",
            "Epoch: 13 | Iteration: 526 | Classification loss: 0.02855 | Regression loss: 0.12188 | Running loss: 0.26951\n",
            "Epoch: 13 | Iteration: 527 | Classification loss: 0.05608 | Regression loss: 0.19886 | Running loss: 0.26932\n",
            "Epoch: 13 | Iteration: 528 | Classification loss: 0.17505 | Regression loss: 0.34192 | Running loss: 0.26974\n",
            "Epoch: 13 | Iteration: 529 | Classification loss: 0.05305 | Regression loss: 0.15074 | Running loss: 0.26953\n",
            "Epoch: 13 | Iteration: 530 | Classification loss: 0.04784 | Regression loss: 0.15921 | Running loss: 0.26950\n",
            "Epoch: 13 | Iteration: 531 | Classification loss: 0.15589 | Regression loss: 0.24230 | Running loss: 0.26988\n",
            "Epoch: 13 | Iteration: 532 | Classification loss: 0.08001 | Regression loss: 0.24138 | Running loss: 0.26929\n",
            "Epoch: 13 | Iteration: 533 | Classification loss: 0.03559 | Regression loss: 0.16903 | Running loss: 0.26945\n",
            "Epoch: 13 | Iteration: 534 | Classification loss: 0.09335 | Regression loss: 0.21979 | Running loss: 0.26977\n",
            "Epoch: 13 | Iteration: 535 | Classification loss: 0.05963 | Regression loss: 0.17760 | Running loss: 0.26961\n",
            "Epoch: 13 | Iteration: 536 | Classification loss: 0.16152 | Regression loss: 0.25761 | Running loss: 0.26989\n",
            "Epoch: 13 | Iteration: 537 | Classification loss: 0.03139 | Regression loss: 0.12944 | Running loss: 0.26990\n",
            "Epoch: 13 | Iteration: 538 | Classification loss: 0.04070 | Regression loss: 0.16440 | Running loss: 0.26990\n",
            "Epoch: 13 | Iteration: 539 | Classification loss: 0.05832 | Regression loss: 0.15708 | Running loss: 0.26998\n",
            "Epoch: 13 | Iteration: 540 | Classification loss: 0.06162 | Regression loss: 0.22903 | Running loss: 0.27024\n",
            "Epoch: 13 | Iteration: 541 | Classification loss: 0.08222 | Regression loss: 0.22340 | Running loss: 0.27038\n",
            "Epoch: 13 | Iteration: 542 | Classification loss: 0.17386 | Regression loss: 0.33372 | Running loss: 0.27073\n",
            "Epoch: 13 | Iteration: 543 | Classification loss: 0.06640 | Regression loss: 0.12671 | Running loss: 0.27043\n",
            "Epoch: 13 | Iteration: 544 | Classification loss: 0.09780 | Regression loss: 0.26989 | Running loss: 0.27072\n",
            "Epoch: 13 | Iteration: 545 | Classification loss: 0.03348 | Regression loss: 0.09779 | Running loss: 0.27043\n",
            "Epoch: 13 | Iteration: 546 | Classification loss: 0.11076 | Regression loss: 0.27530 | Running loss: 0.27077\n",
            "Epoch: 13 | Iteration: 547 | Classification loss: 0.02053 | Regression loss: 0.11773 | Running loss: 0.27032\n",
            "Epoch: 13 | Iteration: 548 | Classification loss: 0.11092 | Regression loss: 0.18177 | Running loss: 0.27069\n",
            "Epoch: 13 | Iteration: 549 | Classification loss: 0.06126 | Regression loss: 0.16436 | Running loss: 0.27066\n",
            "Epoch: 13 | Iteration: 550 | Classification loss: 0.10284 | Regression loss: 0.19744 | Running loss: 0.27070\n",
            "Epoch: 13 | Iteration: 551 | Classification loss: 0.05176 | Regression loss: 0.20904 | Running loss: 0.26985\n",
            "Epoch: 13 | Iteration: 552 | Classification loss: 0.13598 | Regression loss: 0.14745 | Running loss: 0.27000\n",
            "Epoch: 13 | Iteration: 553 | Classification loss: 0.05240 | Regression loss: 0.18169 | Running loss: 0.27032\n",
            "Epoch: 13 | Iteration: 554 | Classification loss: 0.09066 | Regression loss: 0.17053 | Running loss: 0.27028\n",
            "Epoch: 13 | Iteration: 555 | Classification loss: 0.02952 | Regression loss: 0.15476 | Running loss: 0.27020\n",
            "Epoch: 13 | Iteration: 556 | Classification loss: 0.16339 | Regression loss: 0.28496 | Running loss: 0.27014\n",
            "Epoch: 13 | Iteration: 557 | Classification loss: 0.13991 | Regression loss: 0.25743 | Running loss: 0.27059\n",
            "Epoch: 13 | Iteration: 558 | Classification loss: 0.20562 | Regression loss: 0.33829 | Running loss: 0.27106\n",
            "Epoch: 13 | Iteration: 559 | Classification loss: 0.07079 | Regression loss: 0.17421 | Running loss: 0.27093\n",
            "Epoch: 13 | Iteration: 560 | Classification loss: 0.02143 | Regression loss: 0.08770 | Running loss: 0.27029\n",
            "Epoch: 13 | Iteration: 561 | Classification loss: 0.03409 | Regression loss: 0.11547 | Running loss: 0.26991\n",
            "Epoch: 13 | Iteration: 562 | Classification loss: 0.06337 | Regression loss: 0.17423 | Running loss: 0.27002\n",
            "Epoch: 13 | Iteration: 563 | Classification loss: 0.07012 | Regression loss: 0.22822 | Running loss: 0.27029\n",
            "Epoch: 13 | Iteration: 564 | Classification loss: 0.11817 | Regression loss: 0.22290 | Running loss: 0.27062\n",
            "Epoch: 13 | Iteration: 565 | Classification loss: 0.03026 | Regression loss: 0.11254 | Running loss: 0.27049\n",
            "Epoch: 13 | Iteration: 566 | Classification loss: 0.05738 | Regression loss: 0.13683 | Running loss: 0.27059\n",
            "Epoch: 13 | Iteration: 567 | Classification loss: 0.21053 | Regression loss: 0.29608 | Running loss: 0.27086\n",
            "Epoch: 13 | Iteration: 568 | Classification loss: 0.04891 | Regression loss: 0.15598 | Running loss: 0.27094\n",
            "Epoch: 13 | Iteration: 569 | Classification loss: 0.03931 | Regression loss: 0.10117 | Running loss: 0.27024\n",
            "Epoch: 13 | Iteration: 570 | Classification loss: 0.12387 | Regression loss: 0.29562 | Running loss: 0.27085\n",
            "Epoch: 13 | Iteration: 571 | Classification loss: 0.17198 | Regression loss: 0.38317 | Running loss: 0.27125\n",
            "Epoch: 13 | Iteration: 572 | Classification loss: 0.06443 | Regression loss: 0.19730 | Running loss: 0.27140\n",
            "Epoch: 13 | Iteration: 573 | Classification loss: 0.04744 | Regression loss: 0.10138 | Running loss: 0.27116\n",
            "Epoch: 13 | Iteration: 574 | Classification loss: 0.04129 | Regression loss: 0.20317 | Running loss: 0.27107\n",
            "Epoch: 13 | Iteration: 575 | Classification loss: 0.03837 | Regression loss: 0.10431 | Running loss: 0.27102\n",
            "Epoch: 13 | Iteration: 576 | Classification loss: 0.10564 | Regression loss: 0.11505 | Running loss: 0.27127\n",
            "Epoch: 13 | Iteration: 577 | Classification loss: 0.08037 | Regression loss: 0.25284 | Running loss: 0.27157\n",
            "Epoch: 13 | Iteration: 578 | Classification loss: 0.02137 | Regression loss: 0.13636 | Running loss: 0.27122\n",
            "Epoch: 13 | Iteration: 579 | Classification loss: 0.12910 | Regression loss: 0.30772 | Running loss: 0.27145\n",
            "Epoch: 13 | Iteration: 580 | Classification loss: 0.06633 | Regression loss: 0.20166 | Running loss: 0.27087\n",
            "Epoch: 13 | Iteration: 581 | Classification loss: 0.08662 | Regression loss: 0.19207 | Running loss: 0.27096\n",
            "Epoch: 13 | Iteration: 582 | Classification loss: 0.04569 | Regression loss: 0.19412 | Running loss: 0.27069\n",
            "Epoch: 13 | Iteration: 583 | Classification loss: 0.04859 | Regression loss: 0.14065 | Running loss: 0.27046\n",
            "Epoch: 13 | Iteration: 584 | Classification loss: 0.10857 | Regression loss: 0.20981 | Running loss: 0.27047\n",
            "Epoch: 13 | Iteration: 585 | Classification loss: 0.04699 | Regression loss: 0.16435 | Running loss: 0.27031\n",
            "Epoch: 13 | Iteration: 586 | Classification loss: 0.11480 | Regression loss: 0.30438 | Running loss: 0.27057\n",
            "Epoch: 13 | Iteration: 587 | Classification loss: 0.16525 | Regression loss: 0.08529 | Running loss: 0.27013\n",
            "Epoch: 13 | Iteration: 588 | Classification loss: 0.02807 | Regression loss: 0.18931 | Running loss: 0.27021\n",
            "Epoch: 13 | Iteration: 589 | Classification loss: 0.04354 | Regression loss: 0.13788 | Running loss: 0.27029\n",
            "Epoch: 13 | Iteration: 590 | Classification loss: 0.03592 | Regression loss: 0.12464 | Running loss: 0.26989\n",
            "Epoch: 13 | Iteration: 591 | Classification loss: 0.05750 | Regression loss: 0.17942 | Running loss: 0.26993\n",
            "Epoch: 13 | Iteration: 592 | Classification loss: 0.15373 | Regression loss: 0.34951 | Running loss: 0.27053\n",
            "Epoch: 13 | Iteration: 593 | Classification loss: 0.01794 | Regression loss: 0.09877 | Running loss: 0.26968\n",
            "Epoch: 13 | Iteration: 594 | Classification loss: 0.11128 | Regression loss: 0.20713 | Running loss: 0.26990\n",
            "Epoch: 13 | Iteration: 595 | Classification loss: 0.03418 | Regression loss: 0.15317 | Running loss: 0.26964\n",
            "Epoch: 13 | Iteration: 596 | Classification loss: 0.05690 | Regression loss: 0.18266 | Running loss: 0.26967\n",
            "Epoch: 13 | Iteration: 597 | Classification loss: 0.02618 | Regression loss: 0.07385 | Running loss: 0.26917\n",
            "Epoch: 13 | Iteration: 598 | Classification loss: 0.10231 | Regression loss: 0.20437 | Running loss: 0.26951\n",
            "Epoch: 13 | Iteration: 599 | Classification loss: 0.04213 | Regression loss: 0.12982 | Running loss: 0.26945\n",
            "Epoch: 13 | Iteration: 600 | Classification loss: 0.08821 | Regression loss: 0.15492 | Running loss: 0.26955\n",
            "Epoch: 13 | Iteration: 601 | Classification loss: 0.17299 | Regression loss: 0.28757 | Running loss: 0.26943\n",
            "Epoch: 13 | Iteration: 602 | Classification loss: 0.06422 | Regression loss: 0.19043 | Running loss: 0.26965\n",
            "Epoch: 13 | Iteration: 603 | Classification loss: 0.04785 | Regression loss: 0.07478 | Running loss: 0.26939\n",
            "Epoch: 13 | Iteration: 604 | Classification loss: 0.08424 | Regression loss: 0.20326 | Running loss: 0.26958\n",
            "Epoch: 13 | Iteration: 605 | Classification loss: 0.08095 | Regression loss: 0.12133 | Running loss: 0.26961\n",
            "Epoch: 13 | Iteration: 606 | Classification loss: 0.03037 | Regression loss: 0.15038 | Running loss: 0.26939\n",
            "Epoch: 13 | Iteration: 607 | Classification loss: 0.05623 | Regression loss: 0.16760 | Running loss: 0.26951\n",
            "Epoch: 13 | Iteration: 608 | Classification loss: 0.02636 | Regression loss: 0.08170 | Running loss: 0.26934\n",
            "Epoch: 13 | Iteration: 609 | Classification loss: 0.05822 | Regression loss: 0.13511 | Running loss: 0.26891\n",
            "Epoch: 13 | Iteration: 610 | Classification loss: 0.11295 | Regression loss: 0.29861 | Running loss: 0.26949\n",
            "Epoch: 13 | Iteration: 611 | Classification loss: 0.11577 | Regression loss: 0.24107 | Running loss: 0.26979\n",
            "Epoch: 13 | Iteration: 612 | Classification loss: 0.04876 | Regression loss: 0.17117 | Running loss: 0.26968\n",
            "Epoch: 13 | Iteration: 613 | Classification loss: 0.08237 | Regression loss: 0.16192 | Running loss: 0.26977\n",
            "Epoch: 13 | Iteration: 614 | Classification loss: 0.06783 | Regression loss: 0.13729 | Running loss: 0.26950\n",
            "Epoch: 13 | Iteration: 615 | Classification loss: 0.03559 | Regression loss: 0.10286 | Running loss: 0.26924\n",
            "Epoch: 13 | Iteration: 616 | Classification loss: 0.03792 | Regression loss: 0.11540 | Running loss: 0.26893\n",
            "Epoch: 13 | Iteration: 617 | Classification loss: 0.08859 | Regression loss: 0.20684 | Running loss: 0.26917\n",
            "Epoch: 13 | Iteration: 618 | Classification loss: 0.10270 | Regression loss: 0.21862 | Running loss: 0.26948\n",
            "Epoch: 13 | Iteration: 619 | Classification loss: 0.14214 | Regression loss: 0.27865 | Running loss: 0.27000\n",
            "Epoch: 13 | Iteration: 620 | Classification loss: 0.05947 | Regression loss: 0.15552 | Running loss: 0.27007\n",
            "Epoch: 13 | Iteration: 621 | Classification loss: 0.05802 | Regression loss: 0.13493 | Running loss: 0.26987\n",
            "Epoch: 13 | Iteration: 622 | Classification loss: 0.04042 | Regression loss: 0.17307 | Running loss: 0.26973\n",
            "Epoch: 13 | Iteration: 623 | Classification loss: 0.07724 | Regression loss: 0.13046 | Running loss: 0.26964\n",
            "Epoch: 13 | Iteration: 624 | Classification loss: 0.02582 | Regression loss: 0.12247 | Running loss: 0.26942\n",
            "Epoch: 13 | Iteration: 625 | Classification loss: 0.04759 | Regression loss: 0.19015 | Running loss: 0.26949\n",
            "Epoch: 13 | Iteration: 626 | Classification loss: 0.06680 | Regression loss: 0.22115 | Running loss: 0.26969\n",
            "Epoch: 13 | Iteration: 627 | Classification loss: 0.05623 | Regression loss: 0.16449 | Running loss: 0.26969\n",
            "Epoch: 13 | Iteration: 628 | Classification loss: 0.07098 | Regression loss: 0.23287 | Running loss: 0.27001\n",
            "Epoch: 13 | Iteration: 629 | Classification loss: 0.19246 | Regression loss: 0.16977 | Running loss: 0.26982\n",
            "Epoch: 13 | Iteration: 630 | Classification loss: 0.09736 | Regression loss: 0.13353 | Running loss: 0.26987\n",
            "Epoch: 13 | Iteration: 631 | Classification loss: 0.05177 | Regression loss: 0.15122 | Running loss: 0.26971\n",
            "Epoch: 13 | Iteration: 632 | Classification loss: 0.03075 | Regression loss: 0.11022 | Running loss: 0.26925\n",
            "Epoch: 13 | Iteration: 633 | Classification loss: 0.07647 | Regression loss: 0.15386 | Running loss: 0.26939\n",
            "Epoch: 13 | Iteration: 634 | Classification loss: 0.13014 | Regression loss: 0.12409 | Running loss: 0.26949\n",
            "Epoch: 13 | Iteration: 635 | Classification loss: 0.29885 | Regression loss: 0.24601 | Running loss: 0.26931\n",
            "Epoch: 13 | Iteration: 636 | Classification loss: 0.09640 | Regression loss: 0.18161 | Running loss: 0.26957\n",
            "Epoch: 13 | Iteration: 637 | Classification loss: 0.05855 | Regression loss: 0.12517 | Running loss: 0.26877\n",
            "Epoch: 13 | Iteration: 638 | Classification loss: 0.02308 | Regression loss: 0.10006 | Running loss: 0.26840\n",
            "Epoch: 13 | Iteration: 639 | Classification loss: 0.06098 | Regression loss: 0.08169 | Running loss: 0.26818\n",
            "Epoch: 13 | Iteration: 640 | Classification loss: 0.07575 | Regression loss: 0.18097 | Running loss: 0.26820\n",
            "Epoch: 13 | Iteration: 641 | Classification loss: 0.09721 | Regression loss: 0.26322 | Running loss: 0.26822\n",
            "Epoch: 13 | Iteration: 642 | Classification loss: 0.03975 | Regression loss: 0.15227 | Running loss: 0.26773\n",
            "Epoch: 13 | Iteration: 643 | Classification loss: 0.06928 | Regression loss: 0.14732 | Running loss: 0.26780\n",
            "Epoch: 13 | Iteration: 644 | Classification loss: 0.09407 | Regression loss: 0.15869 | Running loss: 0.26760\n",
            "Epoch: 13 | Iteration: 645 | Classification loss: 0.04758 | Regression loss: 0.12504 | Running loss: 0.26726\n",
            "Epoch: 13 | Iteration: 646 | Classification loss: 0.12244 | Regression loss: 0.26483 | Running loss: 0.26764\n",
            "Epoch: 13 | Iteration: 647 | Classification loss: 0.07314 | Regression loss: 0.14136 | Running loss: 0.26779\n",
            "Epoch: 13 | Iteration: 648 | Classification loss: 0.07474 | Regression loss: 0.11163 | Running loss: 0.26749\n",
            "Epoch: 13 | Iteration: 649 | Classification loss: 0.06461 | Regression loss: 0.16415 | Running loss: 0.26692\n",
            "Epoch: 13 | Iteration: 650 | Classification loss: 0.10464 | Regression loss: 0.25697 | Running loss: 0.26724\n",
            "Epoch: 13 | Iteration: 651 | Classification loss: 0.02791 | Regression loss: 0.12813 | Running loss: 0.26675\n",
            "Epoch: 13 | Iteration: 652 | Classification loss: 0.03609 | Regression loss: 0.11715 | Running loss: 0.26665\n",
            "Epoch: 13 | Iteration: 653 | Classification loss: 0.03761 | Regression loss: 0.11687 | Running loss: 0.26640\n",
            "Epoch: 13 | Iteration: 654 | Classification loss: 0.03301 | Regression loss: 0.16175 | Running loss: 0.26665\n",
            "Epoch: 13 | Iteration: 655 | Classification loss: 0.11792 | Regression loss: 0.21359 | Running loss: 0.26696\n",
            "Epoch: 13 | Iteration: 656 | Classification loss: 0.14124 | Regression loss: 0.34438 | Running loss: 0.26749\n",
            "Epoch: 13 | Iteration: 657 | Classification loss: 0.08671 | Regression loss: 0.08574 | Running loss: 0.26720\n",
            "Epoch: 13 | Iteration: 658 | Classification loss: 0.11583 | Regression loss: 0.26551 | Running loss: 0.26753\n",
            "Epoch: 13 | Iteration: 659 | Classification loss: 0.02997 | Regression loss: 0.14611 | Running loss: 0.26730\n",
            "Epoch: 13 | Iteration: 660 | Classification loss: 0.06237 | Regression loss: 0.15983 | Running loss: 0.26731\n",
            "Epoch: 13 | Iteration: 661 | Classification loss: 0.05931 | Regression loss: 0.04852 | Running loss: 0.26708\n",
            "Epoch: 13 | Iteration: 662 | Classification loss: 0.01747 | Regression loss: 0.11759 | Running loss: 0.26711\n",
            "Epoch: 13 | Iteration: 663 | Classification loss: 0.05122 | Regression loss: 0.23679 | Running loss: 0.26723\n",
            "Epoch: 13 | Iteration: 664 | Classification loss: 0.05521 | Regression loss: 0.19137 | Running loss: 0.26698\n",
            "Epoch: 13 | Iteration: 665 | Classification loss: 0.04931 | Regression loss: 0.13783 | Running loss: 0.26655\n",
            "Epoch: 13 | Iteration: 666 | Classification loss: 0.09627 | Regression loss: 0.29894 | Running loss: 0.26681\n",
            "Epoch: 13 | Iteration: 667 | Classification loss: 0.05059 | Regression loss: 0.14644 | Running loss: 0.26679\n",
            "Epoch: 13 | Iteration: 668 | Classification loss: 0.07207 | Regression loss: 0.19359 | Running loss: 0.26690\n",
            "Epoch: 13 | Iteration: 669 | Classification loss: 0.09405 | Regression loss: 0.16339 | Running loss: 0.26701\n",
            "Epoch: 13 | Iteration: 670 | Classification loss: 0.09573 | Regression loss: 0.21367 | Running loss: 0.26731\n",
            "Epoch: 13 | Iteration: 671 | Classification loss: 0.04015 | Regression loss: 0.14535 | Running loss: 0.26730\n",
            "Epoch: 13 | Iteration: 672 | Classification loss: 0.15056 | Regression loss: 0.36584 | Running loss: 0.26783\n",
            "Epoch: 13 | Iteration: 673 | Classification loss: 0.08761 | Regression loss: 0.20802 | Running loss: 0.26750\n",
            "Epoch: 13 | Iteration: 674 | Classification loss: 0.12650 | Regression loss: 0.21238 | Running loss: 0.26773\n",
            "Epoch: 13 | Iteration: 675 | Classification loss: 0.03557 | Regression loss: 0.21918 | Running loss: 0.26779\n",
            "Epoch: 13 | Iteration: 676 | Classification loss: 0.03135 | Regression loss: 0.16524 | Running loss: 0.26715\n",
            "Epoch: 13 | Iteration: 677 | Classification loss: 0.06776 | Regression loss: 0.15649 | Running loss: 0.26688\n",
            "Epoch: 13 | Iteration: 678 | Classification loss: 0.20938 | Regression loss: 0.36336 | Running loss: 0.26721\n",
            "Epoch: 13 | Iteration: 679 | Classification loss: 0.07121 | Regression loss: 0.14575 | Running loss: 0.26726\n",
            "Epoch: 13 | Iteration: 680 | Classification loss: 0.07849 | Regression loss: 0.16117 | Running loss: 0.26757\n",
            "Epoch: 13 | Iteration: 681 | Classification loss: 0.13244 | Regression loss: 0.29575 | Running loss: 0.26815\n",
            "Epoch: 13 | Iteration: 682 | Classification loss: 0.02912 | Regression loss: 0.07983 | Running loss: 0.26800\n",
            "Epoch: 13 | Iteration: 683 | Classification loss: 0.03526 | Regression loss: 0.14692 | Running loss: 0.26769\n",
            "Epoch: 13 | Iteration: 684 | Classification loss: 0.01798 | Regression loss: 0.10911 | Running loss: 0.26750\n",
            "Epoch: 13 | Iteration: 685 | Classification loss: 0.03261 | Regression loss: 0.11821 | Running loss: 0.26717\n",
            "Epoch: 13 | Iteration: 686 | Classification loss: 0.19791 | Regression loss: 0.35229 | Running loss: 0.26761\n",
            "Epoch: 13 | Iteration: 687 | Classification loss: 0.05048 | Regression loss: 0.17563 | Running loss: 0.26739\n",
            "Epoch: 13 | Iteration: 688 | Classification loss: 0.16441 | Regression loss: 0.10445 | Running loss: 0.26740\n",
            "Epoch: 13 | Iteration: 689 | Classification loss: 0.11254 | Regression loss: 0.29584 | Running loss: 0.26797\n",
            "Epoch: 13 | Iteration: 690 | Classification loss: 0.05955 | Regression loss: 0.11916 | Running loss: 0.26797\n",
            "Epoch: 13 | Iteration: 691 | Classification loss: 0.06898 | Regression loss: 0.25761 | Running loss: 0.26811\n",
            "Epoch: 13 | Iteration: 692 | Classification loss: 0.04282 | Regression loss: 0.13179 | Running loss: 0.26747\n",
            "Epoch: 13 | Iteration: 693 | Classification loss: 0.04234 | Regression loss: 0.18014 | Running loss: 0.26753\n",
            "Epoch: 13 | Iteration: 694 | Classification loss: 0.07441 | Regression loss: 0.20157 | Running loss: 0.26770\n",
            "Epoch: 13 | Iteration: 695 | Classification loss: 0.01729 | Regression loss: 0.07266 | Running loss: 0.26769\n",
            "Epoch: 13 | Iteration: 696 | Classification loss: 0.14402 | Regression loss: 0.27133 | Running loss: 0.26780\n",
            "Epoch: 13 | Iteration: 697 | Classification loss: 0.21672 | Regression loss: 0.34810 | Running loss: 0.26841\n",
            "Epoch: 13 | Iteration: 698 | Classification loss: 0.05660 | Regression loss: 0.19270 | Running loss: 0.26827\n",
            "Epoch: 13 | Iteration: 699 | Classification loss: 0.09353 | Regression loss: 0.26796 | Running loss: 0.26861\n",
            "Epoch: 13 | Iteration: 700 | Classification loss: 0.18758 | Regression loss: 0.26684 | Running loss: 0.26931\n",
            "Epoch: 13 | Iteration: 701 | Classification loss: 0.07097 | Regression loss: 0.16074 | Running loss: 0.26863\n",
            "Epoch: 13 | Iteration: 702 | Classification loss: 0.03497 | Regression loss: 0.10102 | Running loss: 0.26870\n",
            "Epoch: 13 | Iteration: 703 | Classification loss: 0.03669 | Regression loss: 0.09656 | Running loss: 0.26833\n",
            "Epoch: 13 | Iteration: 704 | Classification loss: 0.07150 | Regression loss: 0.16905 | Running loss: 0.26806\n",
            "Epoch: 13 | Iteration: 705 | Classification loss: 0.15339 | Regression loss: 0.27146 | Running loss: 0.26840\n",
            "Epoch: 13 | Iteration: 706 | Classification loss: 0.02551 | Regression loss: 0.12679 | Running loss: 0.26821\n",
            "Epoch: 13 | Iteration: 707 | Classification loss: 0.19881 | Regression loss: 0.38093 | Running loss: 0.26891\n",
            "Epoch: 13 | Iteration: 708 | Classification loss: 0.06321 | Regression loss: 0.20520 | Running loss: 0.26880\n",
            "Epoch: 13 | Iteration: 709 | Classification loss: 0.02032 | Regression loss: 0.10854 | Running loss: 0.26836\n",
            "Epoch: 13 | Iteration: 710 | Classification loss: 0.08217 | Regression loss: 0.25573 | Running loss: 0.26856\n",
            "Epoch: 13 | Iteration: 711 | Classification loss: 0.06566 | Regression loss: 0.24639 | Running loss: 0.26857\n",
            "Epoch: 13 | Iteration: 712 | Classification loss: 0.06000 | Regression loss: 0.18413 | Running loss: 0.26842\n",
            "Epoch: 13 | Iteration: 713 | Classification loss: 0.12963 | Regression loss: 0.31218 | Running loss: 0.26898\n",
            "Epoch: 13 | Iteration: 714 | Classification loss: 0.01588 | Regression loss: 0.08856 | Running loss: 0.26845\n",
            "Epoch: 13 | Iteration: 715 | Classification loss: 0.07224 | Regression loss: 0.20746 | Running loss: 0.26781\n",
            "Epoch: 13 | Iteration: 716 | Classification loss: 0.16215 | Regression loss: 0.30481 | Running loss: 0.26840\n",
            "Epoch: 13 | Iteration: 717 | Classification loss: 0.05440 | Regression loss: 0.10666 | Running loss: 0.26852\n",
            "Epoch: 13 | Iteration: 718 | Classification loss: 0.04459 | Regression loss: 0.13758 | Running loss: 0.26827\n",
            "Epoch: 13 | Iteration: 719 | Classification loss: 0.21823 | Regression loss: 0.31435 | Running loss: 0.26886\n",
            "Epoch: 13 | Iteration: 720 | Classification loss: 0.04748 | Regression loss: 0.15798 | Running loss: 0.26871\n",
            "Epoch: 13 | Iteration: 721 | Classification loss: 0.01610 | Regression loss: 0.09736 | Running loss: 0.26828\n",
            "Epoch: 13 | Iteration: 722 | Classification loss: 0.05094 | Regression loss: 0.21041 | Running loss: 0.26750\n",
            "Epoch: 13 | Iteration: 723 | Classification loss: 0.09004 | Regression loss: 0.24332 | Running loss: 0.26767\n",
            "Epoch: 13 | Iteration: 724 | Classification loss: 0.36573 | Regression loss: 0.48833 | Running loss: 0.26897\n",
            "Epoch: 13 | Iteration: 725 | Classification loss: 0.06740 | Regression loss: 0.13662 | Running loss: 0.26901\n",
            "Epoch: 13 | Iteration: 726 | Classification loss: 0.01333 | Regression loss: 0.14964 | Running loss: 0.26887\n",
            "Epoch: 13 | Iteration: 727 | Classification loss: 0.02425 | Regression loss: 0.10395 | Running loss: 0.26857\n",
            "Epoch: 13 | Iteration: 728 | Classification loss: 0.07195 | Regression loss: 0.24145 | Running loss: 0.26879\n",
            "Epoch: 13 | Iteration: 729 | Classification loss: 0.07357 | Regression loss: 0.23390 | Running loss: 0.26901\n",
            "Epoch: 13 | Iteration: 730 | Classification loss: 0.04140 | Regression loss: 0.14409 | Running loss: 0.26895\n",
            "Epoch: 13 | Iteration: 731 | Classification loss: 0.03952 | Regression loss: 0.11444 | Running loss: 0.26873\n",
            "Epoch: 13 | Iteration: 732 | Classification loss: 0.06270 | Regression loss: 0.13529 | Running loss: 0.26876\n",
            "Epoch: 13 | Iteration: 733 | Classification loss: 0.10446 | Regression loss: 0.25046 | Running loss: 0.26900\n",
            "Epoch: 13 | Iteration: 734 | Classification loss: 0.06483 | Regression loss: 0.17133 | Running loss: 0.26897\n",
            "Epoch: 13 | Iteration: 735 | Classification loss: 0.06560 | Regression loss: 0.20707 | Running loss: 0.26892\n",
            "Epoch: 13 | Iteration: 736 | Classification loss: 0.02086 | Regression loss: 0.09552 | Running loss: 0.26880\n",
            "Epoch: 13 | Iteration: 737 | Classification loss: 0.03546 | Regression loss: 0.16434 | Running loss: 0.26859\n",
            "Epoch: 13 | Iteration: 738 | Classification loss: 0.07394 | Regression loss: 0.16518 | Running loss: 0.26870\n",
            "Epoch: 13 | Iteration: 739 | Classification loss: 0.09624 | Regression loss: 0.20372 | Running loss: 0.26888\n",
            "Epoch: 13 | Iteration: 740 | Classification loss: 0.08930 | Regression loss: 0.18540 | Running loss: 0.26923\n",
            "Epoch: 13 | Iteration: 741 | Classification loss: 0.03817 | Regression loss: 0.10616 | Running loss: 0.26891\n",
            "Epoch: 13 | Iteration: 742 | Classification loss: 0.07414 | Regression loss: 0.29503 | Running loss: 0.26903\n",
            "Epoch: 13 | Iteration: 743 | Classification loss: 0.07473 | Regression loss: 0.21551 | Running loss: 0.26850\n",
            "Epoch: 13 | Iteration: 744 | Classification loss: 0.04571 | Regression loss: 0.17432 | Running loss: 0.26841\n",
            "Epoch: 13 | Iteration: 745 | Classification loss: 0.04348 | Regression loss: 0.13063 | Running loss: 0.26812\n",
            "Epoch: 13 | Iteration: 746 | Classification loss: 0.24158 | Regression loss: 0.36034 | Running loss: 0.26849\n",
            "Epoch: 13 | Iteration: 747 | Classification loss: 0.25575 | Regression loss: 0.28406 | Running loss: 0.26886\n",
            "Epoch: 13 | Iteration: 748 | Classification loss: 0.03813 | Regression loss: 0.16826 | Running loss: 0.26865\n",
            "Epoch: 13 | Iteration: 749 | Classification loss: 0.03650 | Regression loss: 0.17912 | Running loss: 0.26890\n",
            "Epoch: 13 | Iteration: 750 | Classification loss: 0.07003 | Regression loss: 0.18485 | Running loss: 0.26882\n",
            "Epoch: 13 | Iteration: 751 | Classification loss: 0.02013 | Regression loss: 0.09746 | Running loss: 0.26877\n",
            "Epoch: 13 | Iteration: 752 | Classification loss: 0.09443 | Regression loss: 0.20434 | Running loss: 0.26889\n",
            "Epoch: 13 | Iteration: 753 | Classification loss: 0.15033 | Regression loss: 0.27521 | Running loss: 0.26936\n",
            "Epoch: 13 | Iteration: 754 | Classification loss: 0.26936 | Regression loss: 0.32636 | Running loss: 0.26999\n",
            "Epoch: 13 | Iteration: 755 | Classification loss: 0.03415 | Regression loss: 0.10632 | Running loss: 0.26963\n",
            "Epoch: 13 | Iteration: 756 | Classification loss: 0.11724 | Regression loss: 0.17112 | Running loss: 0.26982\n",
            "Epoch: 13 | Iteration: 757 | Classification loss: 0.05238 | Regression loss: 0.12238 | Running loss: 0.26980\n",
            "Epoch: 13 | Iteration: 758 | Classification loss: 0.10422 | Regression loss: 0.24381 | Running loss: 0.27009\n",
            "Epoch: 13 | Iteration: 759 | Classification loss: 0.09884 | Regression loss: 0.17797 | Running loss: 0.26985\n",
            "Epoch: 13 | Iteration: 760 | Classification loss: 0.06794 | Regression loss: 0.16635 | Running loss: 0.26982\n",
            "Epoch: 13 | Iteration: 761 | Classification loss: 0.08493 | Regression loss: 0.22257 | Running loss: 0.26998\n",
            "Epoch: 13 | Iteration: 762 | Classification loss: 0.02498 | Regression loss: 0.14202 | Running loss: 0.26999\n",
            "Epoch: 13 | Iteration: 763 | Classification loss: 0.09817 | Regression loss: 0.21169 | Running loss: 0.26974\n",
            "Epoch: 13 | Iteration: 764 | Classification loss: 0.07167 | Regression loss: 0.19165 | Running loss: 0.26999\n",
            "Epoch: 13 | Iteration: 765 | Classification loss: 0.10462 | Regression loss: 0.23443 | Running loss: 0.27016\n",
            "Epoch: 13 | Iteration: 766 | Classification loss: 0.03042 | Regression loss: 0.11761 | Running loss: 0.26958\n",
            "Epoch: 13 | Iteration: 767 | Classification loss: 0.07774 | Regression loss: 0.26812 | Running loss: 0.26972\n",
            "Epoch: 13 | Iteration: 768 | Classification loss: 0.05888 | Regression loss: 0.20978 | Running loss: 0.26945\n",
            "Epoch: 13 | Iteration: 769 | Classification loss: 0.01952 | Regression loss: 0.07983 | Running loss: 0.26887\n",
            "Epoch: 13 | Iteration: 770 | Classification loss: 0.06826 | Regression loss: 0.19671 | Running loss: 0.26852\n",
            "Epoch: 13 | Iteration: 771 | Classification loss: 0.07147 | Regression loss: 0.18422 | Running loss: 0.26858\n",
            "Epoch: 13 | Iteration: 772 | Classification loss: 0.13710 | Regression loss: 0.25543 | Running loss: 0.26904\n",
            "Epoch: 13 | Iteration: 773 | Classification loss: 0.16454 | Regression loss: 0.34841 | Running loss: 0.26951\n",
            "Epoch: 13 | Iteration: 774 | Classification loss: 0.03314 | Regression loss: 0.15750 | Running loss: 0.26944\n",
            "Epoch: 13 | Iteration: 775 | Classification loss: 0.07974 | Regression loss: 0.22451 | Running loss: 0.26977\n",
            "Epoch: 13 | Iteration: 776 | Classification loss: 0.05813 | Regression loss: 0.15451 | Running loss: 0.26982\n",
            "Epoch: 13 | Iteration: 777 | Classification loss: 0.05986 | Regression loss: 0.12556 | Running loss: 0.26956\n",
            "Epoch: 13 | Iteration: 778 | Classification loss: 0.13187 | Regression loss: 0.26247 | Running loss: 0.26992\n",
            "Epoch: 13 | Iteration: 779 | Classification loss: 0.06798 | Regression loss: 0.27788 | Running loss: 0.26989\n",
            "Epoch: 13 | Iteration: 780 | Classification loss: 0.04432 | Regression loss: 0.13138 | Running loss: 0.26978\n",
            "Epoch: 13 | Iteration: 781 | Classification loss: 0.01867 | Regression loss: 0.08091 | Running loss: 0.26933\n",
            "Epoch: 13 | Iteration: 782 | Classification loss: 0.03902 | Regression loss: 0.13888 | Running loss: 0.26908\n",
            "Epoch: 13 | Iteration: 783 | Classification loss: 0.14387 | Regression loss: 0.18658 | Running loss: 0.26929\n",
            "Epoch: 13 | Iteration: 784 | Classification loss: 0.06111 | Regression loss: 0.18662 | Running loss: 0.26933\n",
            "Epoch: 13 | Iteration: 785 | Classification loss: 0.06798 | Regression loss: 0.19063 | Running loss: 0.26918\n",
            "Epoch: 13 | Iteration: 786 | Classification loss: 0.07735 | Regression loss: 0.18712 | Running loss: 0.26931\n",
            "Epoch: 13 | Iteration: 787 | Classification loss: 0.11860 | Regression loss: 0.29321 | Running loss: 0.26997\n",
            "Epoch: 13 | Iteration: 788 | Classification loss: 0.03209 | Regression loss: 0.13940 | Running loss: 0.26964\n",
            "Epoch: 13 | Iteration: 789 | Classification loss: 0.12184 | Regression loss: 0.28046 | Running loss: 0.26993\n",
            "Epoch: 13 | Iteration: 790 | Classification loss: 0.07967 | Regression loss: 0.21084 | Running loss: 0.27010\n",
            "Epoch: 13 | Iteration: 791 | Classification loss: 0.06836 | Regression loss: 0.20480 | Running loss: 0.27023\n",
            "Epoch: 13 | Iteration: 792 | Classification loss: 0.06439 | Regression loss: 0.18840 | Running loss: 0.27030\n",
            "Epoch: 13 | Iteration: 793 | Classification loss: 0.05993 | Regression loss: 0.19473 | Running loss: 0.27004\n",
            "Epoch: 13 | Iteration: 794 | Classification loss: 0.07336 | Regression loss: 0.24307 | Running loss: 0.26999\n",
            "Epoch: 13 | Iteration: 795 | Classification loss: 0.12747 | Regression loss: 0.25989 | Running loss: 0.26984\n",
            "Epoch: 13 | Iteration: 796 | Classification loss: 0.03664 | Regression loss: 0.12499 | Running loss: 0.26952\n",
            "Epoch: 13 | Iteration: 797 | Classification loss: 0.23181 | Regression loss: 0.36750 | Running loss: 0.27028\n",
            "Epoch: 13 | Iteration: 798 | Classification loss: 0.07788 | Regression loss: 0.14856 | Running loss: 0.27045\n",
            "Epoch: 13 | Iteration: 799 | Classification loss: 0.03409 | Regression loss: 0.13437 | Running loss: 0.27054\n",
            "Epoch: 13 | Iteration: 800 | Classification loss: 0.09057 | Regression loss: 0.14820 | Running loss: 0.27037\n",
            "Epoch: 13 | Iteration: 801 | Classification loss: 0.06160 | Regression loss: 0.18379 | Running loss: 0.27028\n",
            "Epoch: 13 | Iteration: 802 | Classification loss: 0.02582 | Regression loss: 0.08525 | Running loss: 0.26954\n",
            "Epoch: 13 | Iteration: 803 | Classification loss: 0.07074 | Regression loss: 0.12123 | Running loss: 0.26925\n",
            "Epoch: 13 | Iteration: 804 | Classification loss: 0.06054 | Regression loss: 0.12262 | Running loss: 0.26933\n",
            "Epoch: 13 | Iteration: 805 | Classification loss: 0.11904 | Regression loss: 0.26791 | Running loss: 0.26960\n",
            "Epoch: 13 | Iteration: 806 | Classification loss: 0.11290 | Regression loss: 0.15814 | Running loss: 0.26987\n",
            "Epoch: 13 | Iteration: 807 | Classification loss: 0.03879 | Regression loss: 0.10642 | Running loss: 0.26939\n",
            "Epoch: 13 | Iteration: 808 | Classification loss: 0.03206 | Regression loss: 0.15320 | Running loss: 0.26957\n",
            "Epoch: 13 | Iteration: 809 | Classification loss: 0.06305 | Regression loss: 0.14044 | Running loss: 0.26948\n",
            "Epoch: 13 | Iteration: 810 | Classification loss: 0.08748 | Regression loss: 0.34825 | Running loss: 0.26975\n",
            "Epoch: 13 | Iteration: 811 | Classification loss: 0.03259 | Regression loss: 0.15426 | Running loss: 0.26984\n",
            "Epoch: 13 | Iteration: 812 | Classification loss: 0.09309 | Regression loss: 0.20329 | Running loss: 0.26999\n",
            "Epoch: 13 | Iteration: 813 | Classification loss: 0.07298 | Regression loss: 0.15315 | Running loss: 0.26987\n",
            "Epoch: 13 | Iteration: 814 | Classification loss: 0.13667 | Regression loss: 0.21556 | Running loss: 0.26986\n",
            "Epoch: 13 | Iteration: 815 | Classification loss: 0.02406 | Regression loss: 0.11254 | Running loss: 0.26932\n",
            "Epoch: 13 | Iteration: 816 | Classification loss: 0.10563 | Regression loss: 0.19815 | Running loss: 0.26917\n",
            "Epoch: 13 | Iteration: 817 | Classification loss: 0.10146 | Regression loss: 0.22464 | Running loss: 0.26900\n",
            "Epoch: 13 | Iteration: 818 | Classification loss: 0.03035 | Regression loss: 0.10931 | Running loss: 0.26875\n",
            "Epoch: 13 | Iteration: 819 | Classification loss: 0.07594 | Regression loss: 0.23951 | Running loss: 0.26848\n",
            "Epoch: 13 | Iteration: 820 | Classification loss: 0.05158 | Regression loss: 0.17641 | Running loss: 0.26772\n",
            "Epoch: 13 | Iteration: 821 | Classification loss: 0.03908 | Regression loss: 0.15039 | Running loss: 0.26779\n",
            "Epoch: 13 | Iteration: 822 | Classification loss: 0.12725 | Regression loss: 0.23323 | Running loss: 0.26787\n",
            "Epoch: 13 | Iteration: 823 | Classification loss: 0.08145 | Regression loss: 0.24122 | Running loss: 0.26770\n",
            "Epoch: 13 | Iteration: 824 | Classification loss: 0.04558 | Regression loss: 0.11281 | Running loss: 0.26763\n",
            "Epoch: 13 | Iteration: 825 | Classification loss: 0.05433 | Regression loss: 0.11078 | Running loss: 0.26747\n",
            "Epoch: 13 | Iteration: 826 | Classification loss: 0.00554 | Regression loss: 0.10971 | Running loss: 0.26750\n",
            "Epoch: 13 | Iteration: 827 | Classification loss: 0.10471 | Regression loss: 0.23364 | Running loss: 0.26768\n",
            "Epoch: 13 | Iteration: 828 | Classification loss: 0.07010 | Regression loss: 0.20156 | Running loss: 0.26784\n",
            "Epoch: 13 | Iteration: 829 | Classification loss: 0.07584 | Regression loss: 0.15034 | Running loss: 0.26736\n",
            "Epoch: 13 | Iteration: 830 | Classification loss: 0.04324 | Regression loss: 0.11401 | Running loss: 0.26687\n",
            "Epoch: 13 | Iteration: 831 | Classification loss: 0.01882 | Regression loss: 0.09914 | Running loss: 0.26663\n",
            "Epoch: 13 | Iteration: 832 | Classification loss: 0.05552 | Regression loss: 0.17801 | Running loss: 0.26677\n",
            "Epoch: 13 | Iteration: 833 | Classification loss: 0.03885 | Regression loss: 0.15609 | Running loss: 0.26676\n",
            "Epoch: 13 | Iteration: 834 | Classification loss: 0.14769 | Regression loss: 0.36316 | Running loss: 0.26710\n",
            "Epoch: 13 | Iteration: 835 | Classification loss: 0.03466 | Regression loss: 0.16279 | Running loss: 0.26669\n",
            "Epoch: 13 | Iteration: 836 | Classification loss: 0.04390 | Regression loss: 0.14595 | Running loss: 0.26663\n",
            "Epoch: 13 | Iteration: 837 | Classification loss: 0.10119 | Regression loss: 0.19545 | Running loss: 0.26655\n",
            "Epoch: 13 | Iteration: 838 | Classification loss: 0.00836 | Regression loss: 0.04470 | Running loss: 0.26609\n",
            "Epoch: 13 | Iteration: 839 | Classification loss: 0.08874 | Regression loss: 0.20701 | Running loss: 0.26605\n",
            "Epoch: 13 | Iteration: 840 | Classification loss: 0.03919 | Regression loss: 0.17242 | Running loss: 0.26600\n",
            "Epoch: 13 | Iteration: 841 | Classification loss: 0.02113 | Regression loss: 0.12727 | Running loss: 0.26590\n",
            "Epoch: 13 | Iteration: 842 | Classification loss: 0.08658 | Regression loss: 0.20649 | Running loss: 0.26619\n",
            "Epoch: 13 | Iteration: 843 | Classification loss: 0.20229 | Regression loss: 0.14606 | Running loss: 0.26652\n",
            "Epoch: 13 | Iteration: 844 | Classification loss: 0.09218 | Regression loss: 0.26360 | Running loss: 0.26697\n",
            "Epoch: 13 | Iteration: 845 | Classification loss: 0.03360 | Regression loss: 0.17144 | Running loss: 0.26709\n",
            "Epoch: 13 | Iteration: 846 | Classification loss: 0.01384 | Regression loss: 0.08463 | Running loss: 0.26688\n",
            "Epoch: 13 | Iteration: 847 | Classification loss: 0.17328 | Regression loss: 0.28101 | Running loss: 0.26722\n",
            "Epoch: 13 | Iteration: 848 | Classification loss: 0.13548 | Regression loss: 0.23966 | Running loss: 0.26751\n",
            "Epoch: 13 | Iteration: 849 | Classification loss: 0.04571 | Regression loss: 0.12722 | Running loss: 0.26754\n",
            "Epoch: 13 | Iteration: 850 | Classification loss: 0.03545 | Regression loss: 0.08974 | Running loss: 0.26717\n",
            "Epoch: 13 | Iteration: 851 | Classification loss: 0.08089 | Regression loss: 0.36430 | Running loss: 0.26750\n",
            "Epoch: 13 | Iteration: 852 | Classification loss: 0.04551 | Regression loss: 0.19441 | Running loss: 0.26759\n",
            "Epoch: 13 | Iteration: 853 | Classification loss: 0.10612 | Regression loss: 0.22782 | Running loss: 0.26795\n",
            "Epoch: 13 | Iteration: 854 | Classification loss: 0.13920 | Regression loss: 0.34669 | Running loss: 0.26851\n",
            "Epoch: 13 | Iteration: 855 | Classification loss: 0.06687 | Regression loss: 0.16110 | Running loss: 0.26858\n",
            "Epoch: 13 | Iteration: 856 | Classification loss: 0.03823 | Regression loss: 0.12250 | Running loss: 0.26830\n",
            "Epoch: 13 | Iteration: 857 | Classification loss: 0.05671 | Regression loss: 0.16132 | Running loss: 0.26843\n",
            "Epoch: 13 | Iteration: 858 | Classification loss: 0.09743 | Regression loss: 0.19532 | Running loss: 0.26863\n",
            "Epoch: 13 | Iteration: 859 | Classification loss: 0.06022 | Regression loss: 0.15313 | Running loss: 0.26854\n",
            "Epoch: 13 | Iteration: 860 | Classification loss: 0.02371 | Regression loss: 0.07627 | Running loss: 0.26833\n",
            "Epoch: 13 | Iteration: 861 | Classification loss: 0.04635 | Regression loss: 0.17896 | Running loss: 0.26861\n",
            "Epoch: 13 | Iteration: 862 | Classification loss: 0.07078 | Regression loss: 0.22644 | Running loss: 0.26841\n",
            "Epoch: 13 | Iteration: 863 | Classification loss: 0.03460 | Regression loss: 0.09432 | Running loss: 0.26827\n",
            "Epoch: 13 | Iteration: 864 | Classification loss: 0.08487 | Regression loss: 0.25390 | Running loss: 0.26808\n",
            "Epoch: 13 | Iteration: 865 | Classification loss: 0.06315 | Regression loss: 0.12207 | Running loss: 0.26805\n",
            "Epoch: 13 | Iteration: 866 | Classification loss: 0.06770 | Regression loss: 0.14533 | Running loss: 0.26795\n",
            "Epoch: 13 | Iteration: 867 | Classification loss: 0.12253 | Regression loss: 0.23774 | Running loss: 0.26777\n",
            "Epoch: 13 | Iteration: 868 | Classification loss: 0.05069 | Regression loss: 0.14050 | Running loss: 0.26744\n",
            "Epoch: 13 | Iteration: 869 | Classification loss: 0.21061 | Regression loss: 0.37370 | Running loss: 0.26824\n",
            "Epoch: 13 | Iteration: 870 | Classification loss: 0.03413 | Regression loss: 0.11875 | Running loss: 0.26798\n",
            "Epoch: 13 | Iteration: 871 | Classification loss: 0.03533 | Regression loss: 0.13483 | Running loss: 0.26762\n",
            "Epoch: 13 | Iteration: 872 | Classification loss: 0.06362 | Regression loss: 0.18376 | Running loss: 0.26748\n",
            "Epoch: 13 | Iteration: 873 | Classification loss: 0.05491 | Regression loss: 0.16435 | Running loss: 0.26732\n",
            "Epoch: 13 | Iteration: 874 | Classification loss: 0.07575 | Regression loss: 0.21274 | Running loss: 0.26718\n",
            "Epoch: 13 | Iteration: 875 | Classification loss: 0.03088 | Regression loss: 0.10451 | Running loss: 0.26716\n",
            "Epoch: 13 | Iteration: 876 | Classification loss: 0.09930 | Regression loss: 0.23891 | Running loss: 0.26726\n",
            "Epoch: 13 | Iteration: 877 | Classification loss: 0.02995 | Regression loss: 0.13240 | Running loss: 0.26726\n",
            "Epoch: 13 | Iteration: 878 | Classification loss: 0.09834 | Regression loss: 0.20343 | Running loss: 0.26752\n",
            "Epoch: 13 | Iteration: 879 | Classification loss: 0.05874 | Regression loss: 0.19721 | Running loss: 0.26765\n",
            "Epoch: 13 | Iteration: 880 | Classification loss: 0.10746 | Regression loss: 0.29857 | Running loss: 0.26782\n",
            "Epoch: 13 | Iteration: 881 | Classification loss: 0.17389 | Regression loss: 0.34560 | Running loss: 0.26821\n",
            "Epoch: 13 | Iteration: 882 | Classification loss: 0.02981 | Regression loss: 0.09614 | Running loss: 0.26802\n",
            "Epoch: 13 | Iteration: 883 | Classification loss: 0.09474 | Regression loss: 0.19840 | Running loss: 0.26811\n",
            "Epoch: 13 | Iteration: 884 | Classification loss: 0.03914 | Regression loss: 0.10833 | Running loss: 0.26795\n",
            "Epoch: 13 | Iteration: 885 | Classification loss: 0.10953 | Regression loss: 0.27766 | Running loss: 0.26806\n",
            "Epoch: 13 | Iteration: 886 | Classification loss: 0.11965 | Regression loss: 0.29951 | Running loss: 0.26787\n",
            "Epoch: 13 | Iteration: 887 | Classification loss: 0.14225 | Regression loss: 0.24115 | Running loss: 0.26802\n",
            "Epoch: 13 | Iteration: 888 | Classification loss: 0.04143 | Regression loss: 0.12745 | Running loss: 0.26777\n",
            "Epoch: 13 | Iteration: 889 | Classification loss: 0.11429 | Regression loss: 0.16470 | Running loss: 0.26774\n",
            "Epoch: 13 | Iteration: 890 | Classification loss: 0.08812 | Regression loss: 0.17470 | Running loss: 0.26787\n",
            "Epoch: 13 | Iteration: 891 | Classification loss: 0.04833 | Regression loss: 0.17707 | Running loss: 0.26790\n",
            "Epoch: 13 | Iteration: 892 | Classification loss: 0.10533 | Regression loss: 0.21858 | Running loss: 0.26800\n",
            "Epoch: 13 | Iteration: 893 | Classification loss: 0.01638 | Regression loss: 0.08847 | Running loss: 0.26760\n",
            "Epoch: 13 | Iteration: 894 | Classification loss: 0.17831 | Regression loss: 0.11624 | Running loss: 0.26776\n",
            "Epoch: 13 | Iteration: 895 | Classification loss: 0.07454 | Regression loss: 0.33716 | Running loss: 0.26813\n",
            "Epoch: 13 | Iteration: 896 | Classification loss: 0.17007 | Regression loss: 0.16371 | Running loss: 0.26809\n",
            "Epoch: 13 | Iteration: 897 | Classification loss: 0.09265 | Regression loss: 0.22846 | Running loss: 0.26824\n",
            "Epoch: 13 | Iteration: 898 | Classification loss: 0.08651 | Regression loss: 0.13315 | Running loss: 0.26757\n",
            "Epoch: 13 | Iteration: 899 | Classification loss: 0.09155 | Regression loss: 0.22504 | Running loss: 0.26753\n",
            "Epoch: 13 | Iteration: 900 | Classification loss: 0.07710 | Regression loss: 0.20224 | Running loss: 0.26749\n",
            "Epoch: 13 | Iteration: 901 | Classification loss: 0.10193 | Regression loss: 0.22113 | Running loss: 0.26781\n",
            "Epoch: 13 | Iteration: 902 | Classification loss: 0.03562 | Regression loss: 0.13598 | Running loss: 0.26734\n",
            "Epoch: 13 | Iteration: 903 | Classification loss: 0.08698 | Regression loss: 0.20117 | Running loss: 0.26756\n",
            "Epoch: 13 | Iteration: 904 | Classification loss: 0.07401 | Regression loss: 0.22291 | Running loss: 0.26724\n",
            "Epoch: 13 | Iteration: 905 | Classification loss: 0.17032 | Regression loss: 0.31793 | Running loss: 0.26774\n",
            "Epoch: 13 | Iteration: 906 | Classification loss: 0.04029 | Regression loss: 0.11078 | Running loss: 0.26714\n",
            "Epoch: 13 | Iteration: 907 | Classification loss: 0.13274 | Regression loss: 0.19448 | Running loss: 0.26747\n",
            "Epoch: 13 | Iteration: 908 | Classification loss: 0.20680 | Regression loss: 0.38735 | Running loss: 0.26786\n",
            "Epoch: 13 | Iteration: 909 | Classification loss: 0.05570 | Regression loss: 0.16006 | Running loss: 0.26762\n",
            "Epoch: 13 | Iteration: 910 | Classification loss: 0.12568 | Regression loss: 0.26913 | Running loss: 0.26754\n",
            "Epoch: 13 | Iteration: 911 | Classification loss: 0.09652 | Regression loss: 0.23678 | Running loss: 0.26795\n",
            "Epoch: 13 | Iteration: 912 | Classification loss: 0.06862 | Regression loss: 0.21709 | Running loss: 0.26817\n",
            "Epoch: 13 | Iteration: 913 | Classification loss: 0.05800 | Regression loss: 0.19804 | Running loss: 0.26844\n",
            "Epoch: 13 | Iteration: 914 | Classification loss: 0.14678 | Regression loss: 0.22464 | Running loss: 0.26869\n",
            "Epoch: 13 | Iteration: 915 | Classification loss: 0.09688 | Regression loss: 0.18353 | Running loss: 0.26889\n",
            "Epoch: 13 | Iteration: 916 | Classification loss: 0.07365 | Regression loss: 0.15321 | Running loss: 0.26900\n",
            "Epoch: 13 | Iteration: 917 | Classification loss: 0.06714 | Regression loss: 0.13767 | Running loss: 0.26833\n",
            "Epoch: 13 | Iteration: 918 | Classification loss: 0.08974 | Regression loss: 0.18777 | Running loss: 0.26859\n",
            "Epoch: 13 | Iteration: 919 | Classification loss: 0.09188 | Regression loss: 0.19547 | Running loss: 0.26818\n",
            "Epoch: 13 | Iteration: 920 | Classification loss: 0.02723 | Regression loss: 0.11219 | Running loss: 0.26778\n",
            "Epoch: 13 | Iteration: 921 | Classification loss: 0.02771 | Regression loss: 0.11165 | Running loss: 0.26764\n",
            "Epoch: 13 | Iteration: 922 | Classification loss: 0.02363 | Regression loss: 0.14343 | Running loss: 0.26761\n",
            "Epoch: 13 | Iteration: 923 | Classification loss: 0.10994 | Regression loss: 0.16358 | Running loss: 0.26744\n",
            "Epoch: 13 | Iteration: 924 | Classification loss: 0.09469 | Regression loss: 0.22148 | Running loss: 0.26750\n",
            "Epoch: 13 | Iteration: 925 | Classification loss: 0.01209 | Regression loss: 0.12665 | Running loss: 0.26719\n",
            "Epoch: 13 | Iteration: 926 | Classification loss: 0.06738 | Regression loss: 0.22167 | Running loss: 0.26757\n",
            "Epoch: 13 | Iteration: 927 | Classification loss: 0.12207 | Regression loss: 0.18975 | Running loss: 0.26751\n",
            "Epoch: 13 | Iteration: 928 | Classification loss: 0.05370 | Regression loss: 0.17015 | Running loss: 0.26734\n",
            "Epoch: 13 | Iteration: 929 | Classification loss: 0.07269 | Regression loss: 0.17370 | Running loss: 0.26718\n",
            "Epoch: 13 | Iteration: 930 | Classification loss: 0.03766 | Regression loss: 0.17095 | Running loss: 0.26717\n",
            "Epoch: 13 | Iteration: 931 | Classification loss: 0.12462 | Regression loss: 0.26453 | Running loss: 0.26731\n",
            "Epoch: 13 | Iteration: 932 | Classification loss: 0.07186 | Regression loss: 0.15799 | Running loss: 0.26710\n",
            "Epoch: 13 | Iteration: 933 | Classification loss: 0.04629 | Regression loss: 0.14355 | Running loss: 0.26715\n",
            "Epoch: 13 | Iteration: 934 | Classification loss: 0.11445 | Regression loss: 0.14149 | Running loss: 0.26689\n",
            "Epoch: 13 | Iteration: 935 | Classification loss: 0.16344 | Regression loss: 0.25786 | Running loss: 0.26686\n",
            "Epoch: 13 | Iteration: 936 | Classification loss: 0.14598 | Regression loss: 0.22505 | Running loss: 0.26718\n",
            "Epoch: 13 | Iteration: 937 | Classification loss: 0.10336 | Regression loss: 0.14021 | Running loss: 0.26696\n",
            "Epoch: 13 | Iteration: 938 | Classification loss: 0.08742 | Regression loss: 0.21184 | Running loss: 0.26666\n",
            "Epoch: 13 | Iteration: 939 | Classification loss: 0.12658 | Regression loss: 0.28479 | Running loss: 0.26714\n",
            "Epoch: 13 | Iteration: 940 | Classification loss: 0.03973 | Regression loss: 0.16333 | Running loss: 0.26675\n",
            "Epoch: 13 | Iteration: 941 | Classification loss: 0.15026 | Regression loss: 0.17274 | Running loss: 0.26705\n",
            "Epoch: 13 | Iteration: 942 | Classification loss: 0.08516 | Regression loss: 0.15952 | Running loss: 0.26741\n",
            "Epoch: 13 | Iteration: 943 | Classification loss: 0.10279 | Regression loss: 0.22618 | Running loss: 0.26729\n",
            "Epoch: 13 | Iteration: 944 | Classification loss: 0.09900 | Regression loss: 0.09932 | Running loss: 0.26742\n",
            "Epoch: 13 | Iteration: 945 | Classification loss: 0.06064 | Regression loss: 0.16055 | Running loss: 0.26756\n",
            "Epoch: 13 | Iteration: 946 | Classification loss: 0.07234 | Regression loss: 0.14591 | Running loss: 0.26710\n",
            "Epoch: 13 | Iteration: 947 | Classification loss: 0.15098 | Regression loss: 0.30666 | Running loss: 0.26736\n",
            "Epoch: 13 | Iteration: 948 | Classification loss: 0.02524 | Regression loss: 0.15266 | Running loss: 0.26730\n",
            "Epoch: 13 | Iteration: 949 | Classification loss: 0.10140 | Regression loss: 0.21623 | Running loss: 0.26682\n",
            "Epoch: 13 | Iteration: 950 | Classification loss: 0.07358 | Regression loss: 0.17529 | Running loss: 0.26632\n",
            "Epoch: 13 | Iteration: 951 | Classification loss: 0.07110 | Regression loss: 0.17390 | Running loss: 0.26606\n",
            "Epoch: 13 | Iteration: 952 | Classification loss: 0.01459 | Regression loss: 0.09080 | Running loss: 0.26555\n",
            "Epoch: 13 | Iteration: 953 | Classification loss: 0.03275 | Regression loss: 0.12520 | Running loss: 0.26521\n",
            "Epoch: 13 | Iteration: 954 | Classification loss: 0.06011 | Regression loss: 0.16118 | Running loss: 0.26502\n",
            "Epoch: 13 | Iteration: 955 | Classification loss: 0.10446 | Regression loss: 0.18764 | Running loss: 0.26503\n",
            "Epoch: 13 | Iteration: 956 | Classification loss: 0.05865 | Regression loss: 0.12715 | Running loss: 0.26487\n",
            "Epoch: 13 | Iteration: 957 | Classification loss: 0.07182 | Regression loss: 0.16092 | Running loss: 0.26485\n",
            "Epoch: 13 | Iteration: 958 | Classification loss: 0.13468 | Regression loss: 0.27411 | Running loss: 0.26528\n",
            "Epoch: 13 | Iteration: 959 | Classification loss: 0.06744 | Regression loss: 0.20490 | Running loss: 0.26535\n",
            "Epoch: 13 | Iteration: 960 | Classification loss: 0.28640 | Regression loss: 0.30238 | Running loss: 0.26605\n",
            "Epoch: 13 | Iteration: 961 | Classification loss: 0.15866 | Regression loss: 0.31286 | Running loss: 0.26653\n",
            "Epoch: 13 | Iteration: 962 | Classification loss: 0.05608 | Regression loss: 0.12367 | Running loss: 0.26609\n",
            "Epoch: 13 | Iteration: 963 | Classification loss: 0.12814 | Regression loss: 0.24305 | Running loss: 0.26636\n",
            "Epoch: 13 | Iteration: 964 | Classification loss: 0.02945 | Regression loss: 0.12609 | Running loss: 0.26612\n",
            "Epoch: 13 | Iteration: 965 | Classification loss: 0.08268 | Regression loss: 0.18648 | Running loss: 0.26566\n",
            "Epoch: 13 | Iteration: 966 | Classification loss: 0.08252 | Regression loss: 0.24246 | Running loss: 0.26586\n",
            "Epoch: 13 | Iteration: 967 | Classification loss: 0.18714 | Regression loss: 0.33553 | Running loss: 0.26647\n",
            "Epoch: 13 | Iteration: 968 | Classification loss: 0.08178 | Regression loss: 0.18076 | Running loss: 0.26650\n",
            "Epoch: 13 | Iteration: 969 | Classification loss: 0.15712 | Regression loss: 0.28503 | Running loss: 0.26711\n",
            "Epoch: 13 | Iteration: 970 | Classification loss: 0.09033 | Regression loss: 0.23990 | Running loss: 0.26734\n",
            "Epoch: 13 | Iteration: 971 | Classification loss: 0.05426 | Regression loss: 0.17498 | Running loss: 0.26703\n",
            "Epoch: 13 | Iteration: 972 | Classification loss: 0.05607 | Regression loss: 0.16253 | Running loss: 0.26701\n",
            "Epoch: 13 | Iteration: 973 | Classification loss: 0.10633 | Regression loss: 0.27444 | Running loss: 0.26757\n",
            "Epoch: 13 | Iteration: 974 | Classification loss: 0.07052 | Regression loss: 0.18920 | Running loss: 0.26787\n",
            "Epoch: 13 | Iteration: 975 | Classification loss: 0.17639 | Regression loss: 0.35797 | Running loss: 0.26777\n",
            "Epoch: 13 | Iteration: 976 | Classification loss: 0.07439 | Regression loss: 0.16098 | Running loss: 0.26754\n",
            "Epoch: 13 | Iteration: 977 | Classification loss: 0.02110 | Regression loss: 0.17277 | Running loss: 0.26734\n",
            "Epoch: 13 | Iteration: 978 | Classification loss: 0.04912 | Regression loss: 0.13435 | Running loss: 0.26741\n",
            "Epoch: 13 | Iteration: 979 | Classification loss: 0.08979 | Regression loss: 0.17483 | Running loss: 0.26744\n",
            "Epoch: 13 | Iteration: 980 | Classification loss: 0.13417 | Regression loss: 0.28208 | Running loss: 0.26789\n",
            "Epoch: 13 | Iteration: 981 | Classification loss: 0.18454 | Regression loss: 0.35157 | Running loss: 0.26861\n",
            "Epoch: 13 | Iteration: 982 | Classification loss: 0.05388 | Regression loss: 0.16315 | Running loss: 0.26850\n",
            "Epoch: 13 | Iteration: 983 | Classification loss: 0.02698 | Regression loss: 0.10684 | Running loss: 0.26832\n",
            "Epoch: 13 | Iteration: 984 | Classification loss: 0.08735 | Regression loss: 0.22888 | Running loss: 0.26866\n",
            "Epoch: 13 | Iteration: 985 | Classification loss: 0.03763 | Regression loss: 0.12955 | Running loss: 0.26871\n",
            "Epoch: 13 | Iteration: 986 | Classification loss: 0.12580 | Regression loss: 0.22400 | Running loss: 0.26895\n",
            "Epoch: 13 | Iteration: 987 | Classification loss: 0.14570 | Regression loss: 0.24279 | Running loss: 0.26923\n",
            "Epoch: 13 | Iteration: 988 | Classification loss: 0.08290 | Regression loss: 0.17021 | Running loss: 0.26920\n",
            "Epoch: 13 | Iteration: 989 | Classification loss: 0.07765 | Regression loss: 0.16444 | Running loss: 0.26937\n",
            "Epoch: 13 | Iteration: 990 | Classification loss: 0.12280 | Regression loss: 0.25114 | Running loss: 0.26979\n",
            "Epoch: 13 | Iteration: 991 | Classification loss: 0.16257 | Regression loss: 0.36547 | Running loss: 0.27030\n",
            "Epoch: 13 | Iteration: 992 | Classification loss: 0.08643 | Regression loss: 0.14884 | Running loss: 0.27038\n",
            "Epoch: 13 | Iteration: 993 | Classification loss: 0.04693 | Regression loss: 0.11948 | Running loss: 0.27000\n",
            "Epoch: 13 | Iteration: 994 | Classification loss: 0.11989 | Regression loss: 0.33352 | Running loss: 0.27067\n",
            "Epoch: 13 | Iteration: 995 | Classification loss: 0.27536 | Regression loss: 0.39950 | Running loss: 0.27131\n",
            "Epoch: 13 | Iteration: 996 | Classification loss: 0.11716 | Regression loss: 0.16575 | Running loss: 0.27087\n",
            "Epoch: 13 | Iteration: 997 | Classification loss: 0.15713 | Regression loss: 0.37043 | Running loss: 0.27166\n",
            "Epoch: 13 | Iteration: 998 | Classification loss: 0.11262 | Regression loss: 0.29082 | Running loss: 0.27173\n",
            "Epoch: 13 | Iteration: 999 | Classification loss: 0.10059 | Regression loss: 0.19393 | Running loss: 0.27180\n",
            "Epoch: 13 | Iteration: 1000 | Classification loss: 0.10562 | Regression loss: 0.20631 | Running loss: 0.27169\n",
            "Epoch: 13 | Iteration: 1001 | Classification loss: 0.06970 | Regression loss: 0.06589 | Running loss: 0.27141\n",
            "Epoch: 13 | Iteration: 1002 | Classification loss: 0.04728 | Regression loss: 0.14011 | Running loss: 0.27123\n",
            "Epoch: 13 | Iteration: 1003 | Classification loss: 0.03752 | Regression loss: 0.10624 | Running loss: 0.27097\n",
            "Epoch: 13 | Iteration: 1004 | Classification loss: 0.07916 | Regression loss: 0.23913 | Running loss: 0.27131\n",
            "Epoch: 13 | Iteration: 1005 | Classification loss: 0.09102 | Regression loss: 0.17892 | Running loss: 0.27140\n",
            "Epoch: 13 | Iteration: 1006 | Classification loss: 0.13778 | Regression loss: 0.09344 | Running loss: 0.27107\n",
            "Epoch: 13 | Iteration: 1007 | Classification loss: 0.04221 | Regression loss: 0.12150 | Running loss: 0.27109\n",
            "Epoch: 13 | Iteration: 1008 | Classification loss: 0.02687 | Regression loss: 0.06316 | Running loss: 0.27096\n",
            "Epoch: 13 | Iteration: 1009 | Classification loss: 0.14942 | Regression loss: 0.21749 | Running loss: 0.27088\n",
            "Epoch: 13 | Iteration: 1010 | Classification loss: 0.07994 | Regression loss: 0.18081 | Running loss: 0.27098\n",
            "Epoch: 13 | Iteration: 1011 | Classification loss: 0.05762 | Regression loss: 0.17530 | Running loss: 0.27090\n",
            "Epoch: 13 | Iteration: 1012 | Classification loss: 0.10062 | Regression loss: 0.11261 | Running loss: 0.27057\n",
            "Epoch: 13 | Iteration: 1013 | Classification loss: 0.08976 | Regression loss: 0.25634 | Running loss: 0.27068\n",
            "Epoch: 13 | Iteration: 1014 | Classification loss: 0.04078 | Regression loss: 0.14473 | Running loss: 0.27038\n",
            "Epoch: 13 | Iteration: 1015 | Classification loss: 0.20594 | Regression loss: 0.34962 | Running loss: 0.27097\n",
            "Epoch: 13 | Iteration: 1016 | Classification loss: 0.08319 | Regression loss: 0.16075 | Running loss: 0.27069\n",
            "Epoch: 13 | Iteration: 1017 | Classification loss: 0.05523 | Regression loss: 0.13843 | Running loss: 0.27061\n",
            "Epoch: 13 | Iteration: 1018 | Classification loss: 0.03838 | Regression loss: 0.16413 | Running loss: 0.27046\n",
            "Epoch: 13 | Iteration: 1019 | Classification loss: 0.06606 | Regression loss: 0.12363 | Running loss: 0.27051\n",
            "Epoch: 13 | Iteration: 1020 | Classification loss: 0.12962 | Regression loss: 0.22114 | Running loss: 0.27071\n",
            "Epoch: 13 | Iteration: 1021 | Classification loss: 0.04316 | Regression loss: 0.08938 | Running loss: 0.27057\n",
            "Epoch: 13 | Iteration: 1022 | Classification loss: 0.10915 | Regression loss: 0.12827 | Running loss: 0.27077\n",
            "Epoch: 13 | Iteration: 1023 | Classification loss: 0.09846 | Regression loss: 0.28317 | Running loss: 0.27104\n",
            "Epoch: 13 | Iteration: 1024 | Classification loss: 0.07259 | Regression loss: 0.19520 | Running loss: 0.27129\n",
            "Epoch: 13 | Iteration: 1025 | Classification loss: 0.10745 | Regression loss: 0.25687 | Running loss: 0.27148\n",
            "Epoch: 13 | Iteration: 1026 | Classification loss: 0.03555 | Regression loss: 0.13050 | Running loss: 0.27151\n",
            "Epoch: 13 | Iteration: 1027 | Classification loss: 0.09682 | Regression loss: 0.10419 | Running loss: 0.27140\n",
            "Epoch: 13 | Iteration: 1028 | Classification loss: 0.11547 | Regression loss: 0.13534 | Running loss: 0.27087\n",
            "Epoch: 13 | Iteration: 1029 | Classification loss: 0.15042 | Regression loss: 0.26097 | Running loss: 0.27129\n",
            "Epoch: 13 | Iteration: 1030 | Classification loss: 0.11413 | Regression loss: 0.14005 | Running loss: 0.27138\n",
            "Epoch: 13 | Iteration: 1031 | Classification loss: 0.12967 | Regression loss: 0.24713 | Running loss: 0.27134\n",
            "Epoch: 13 | Iteration: 1032 | Classification loss: 0.11346 | Regression loss: 0.19151 | Running loss: 0.27130\n",
            "Epoch: 13 | Iteration: 1033 | Classification loss: 0.08148 | Regression loss: 0.20828 | Running loss: 0.27147\n",
            "Epoch: 13 | Iteration: 1034 | Classification loss: 0.13729 | Regression loss: 0.30045 | Running loss: 0.27172\n",
            "Epoch: 13 | Iteration: 1035 | Classification loss: 0.09087 | Regression loss: 0.21270 | Running loss: 0.27186\n",
            "Epoch: 13 | Iteration: 1036 | Classification loss: 0.05068 | Regression loss: 0.13794 | Running loss: 0.27139\n",
            "Epoch: 13 | Iteration: 1037 | Classification loss: 0.13510 | Regression loss: 0.21575 | Running loss: 0.27177\n",
            "Epoch: 13 | Iteration: 1038 | Classification loss: 0.08664 | Regression loss: 0.27213 | Running loss: 0.27208\n",
            "Epoch: 13 | Iteration: 1039 | Classification loss: 0.09927 | Regression loss: 0.26158 | Running loss: 0.27237\n",
            "Epoch: 13 | Iteration: 1040 | Classification loss: 0.07743 | Regression loss: 0.10990 | Running loss: 0.27217\n",
            "Epoch: 13 | Iteration: 1041 | Classification loss: 0.17624 | Regression loss: 0.29137 | Running loss: 0.27249\n",
            "Epoch: 13 | Iteration: 1042 | Classification loss: 0.15440 | Regression loss: 0.28687 | Running loss: 0.27236\n",
            "Epoch: 13 | Iteration: 1043 | Classification loss: 0.06985 | Regression loss: 0.23489 | Running loss: 0.27258\n",
            "Epoch: 13 | Iteration: 1044 | Classification loss: 0.17960 | Regression loss: 0.31009 | Running loss: 0.27283\n",
            "Epoch: 13 | Iteration: 1045 | Classification loss: 0.10938 | Regression loss: 0.23191 | Running loss: 0.27325\n",
            "Epoch: 13 | Iteration: 1046 | Classification loss: 0.11681 | Regression loss: 0.23948 | Running loss: 0.27319\n",
            "Epoch: 13 | Iteration: 1047 | Classification loss: 0.09096 | Regression loss: 0.29427 | Running loss: 0.27368\n",
            "Epoch: 13 | Iteration: 1048 | Classification loss: 0.03104 | Regression loss: 0.09819 | Running loss: 0.27335\n",
            "Epoch: 13 | Iteration: 1049 | Classification loss: 0.10348 | Regression loss: 0.17975 | Running loss: 0.27347\n",
            "Epoch: 13 | Iteration: 1050 | Classification loss: 0.09263 | Regression loss: 0.23385 | Running loss: 0.27352\n",
            "Epoch: 13 | Iteration: 1051 | Classification loss: 0.07837 | Regression loss: 0.14936 | Running loss: 0.27345\n",
            "Epoch: 13 | Iteration: 1052 | Classification loss: 0.08519 | Regression loss: 0.16087 | Running loss: 0.27338\n",
            "Epoch: 13 | Iteration: 1053 | Classification loss: 0.02937 | Regression loss: 0.13736 | Running loss: 0.27324\n",
            "Epoch: 13 | Iteration: 1054 | Classification loss: 0.06465 | Regression loss: 0.18457 | Running loss: 0.27322\n",
            "Epoch: 13 | Iteration: 1055 | Classification loss: 0.09259 | Regression loss: 0.27121 | Running loss: 0.27358\n",
            "Epoch: 13 | Iteration: 1056 | Classification loss: 0.09165 | Regression loss: 0.23353 | Running loss: 0.27333\n",
            "Epoch: 13 | Iteration: 1057 | Classification loss: 0.05751 | Regression loss: 0.20142 | Running loss: 0.27306\n",
            "Epoch: 13 | Iteration: 1058 | Classification loss: 0.09678 | Regression loss: 0.17304 | Running loss: 0.27251\n",
            "Epoch: 13 | Iteration: 1059 | Classification loss: 0.02541 | Regression loss: 0.14313 | Running loss: 0.27236\n",
            "Epoch: 13 | Iteration: 1060 | Classification loss: 0.06678 | Regression loss: 0.19841 | Running loss: 0.27267\n",
            "Epoch: 13 | Iteration: 1061 | Classification loss: 0.18606 | Regression loss: 0.29478 | Running loss: 0.27333\n",
            "Epoch: 13 | Iteration: 1062 | Classification loss: 0.06988 | Regression loss: 0.18970 | Running loss: 0.27337\n",
            "Epoch: 13 | Iteration: 1063 | Classification loss: 0.10839 | Regression loss: 0.19850 | Running loss: 0.27339\n",
            "Epoch: 13 | Iteration: 1064 | Classification loss: 0.01988 | Regression loss: 0.14056 | Running loss: 0.27303\n",
            "Epoch: 13 | Iteration: 1065 | Classification loss: 0.08959 | Regression loss: 0.21529 | Running loss: 0.27335\n",
            "Epoch: 13 | Iteration: 1066 | Classification loss: 0.12216 | Regression loss: 0.34359 | Running loss: 0.27390\n",
            "Epoch: 13 | Iteration: 1067 | Classification loss: 0.09035 | Regression loss: 0.24823 | Running loss: 0.27356\n",
            "Epoch: 13 | Iteration: 1068 | Classification loss: 0.10821 | Regression loss: 0.24437 | Running loss: 0.27386\n",
            "Epoch: 13 | Iteration: 1069 | Classification loss: 0.13682 | Regression loss: 0.18276 | Running loss: 0.27421\n",
            "Epoch: 13 | Iteration: 1070 | Classification loss: 0.04008 | Regression loss: 0.07503 | Running loss: 0.27361\n",
            "Epoch: 13 | Iteration: 1071 | Classification loss: 0.08156 | Regression loss: 0.19343 | Running loss: 0.27305\n",
            "Epoch: 13 | Iteration: 1072 | Classification loss: 0.08229 | Regression loss: 0.21896 | Running loss: 0.27312\n",
            "Epoch: 13 | Iteration: 1073 | Classification loss: 0.06534 | Regression loss: 0.20799 | Running loss: 0.27337\n",
            "Epoch: 13 | Iteration: 1074 | Classification loss: 0.08733 | Regression loss: 0.19423 | Running loss: 0.27345\n",
            "Epoch: 13 | Iteration: 1075 | Classification loss: 0.08617 | Regression loss: 0.25542 | Running loss: 0.27385\n",
            "Epoch: 13 | Iteration: 1076 | Classification loss: 0.20581 | Regression loss: 0.29429 | Running loss: 0.27440\n",
            "Epoch: 13 | Iteration: 1077 | Classification loss: 0.16206 | Regression loss: 0.33548 | Running loss: 0.27473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShLq4i3rQagZ"
      },
      "source": [
        "!cp \"/content/classes.csv\" -d \"/content/drive/My Drive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Uf7pAcUumn"
      },
      "source": [
        "!cp \"/content/train_df_fold_1.csv\" -d \"/content/drive/My Drive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Oj8-SCMCU80J",
        "outputId": "6f03e89b-5882-4d84-97a4-6973d7ab194a"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/drive/MyDrive/val_df_fold_1.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_72ab6ab1-760a-4e15-864c-557927328d9e\", \"val_df_fold_1.csv\", 415212)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}